import os
import urllib.request

import numpy as np
import pytest
import scanpy as sc
import torch
from scdataloader import Preprocessor
from scdataloader.utils import populate_my_ontology

from scprint import scPrint
from scprint.base import NAME
from scprint.tasks import Denoiser, Embedder, GNInfer


def test_base():
    assert NAME == "scprint"
    populate_my_ontology(
        organisms=["NCBITaxon:10090", "NCBITaxon:9606"],
        sex=["PATO:0000384", "PATO:0000383"],
        # celltypes=None,
        # ethnicities=None,
        # assays=None,
        # tissues=None,
        # diseases=None,
        # dev_stages=None,
    )
    filepath = os.path.join(os.path.dirname(__file__), "test.h5ad")
    ckpt_path = os.path.join(os.path.dirname(__file__), "small.ckpt")
    if not os.path.exists(ckpt_path):
        url = "https://huggingface.co/jkobject/scPRINT/resolve/main/small.ckpt"
        urllib.request.urlretrieve(url, ckpt_path)

    adata = sc.read_h5ad(filepath)
    adata.obs.drop(columns="is_primary_data", inplace=True, errors="ignore")
    adata.obs["organism_ontology_term_id"] = "NCBITaxon:9606"
    preprocessor = Preprocessor(
        do_postp=False,
        force_preprocess=True,
    )
    adata = preprocessor(adata)
    # conf = dict(self.config_init[subcommand])
    model = scPrint.load_from_checkpoint(
        ckpt_path,
        precpt_gene_emb=None,
        # triton gets installed so it must think it has cuda enabled
        transformer="normal",
    )
    dn = Denoiser(
        max_cells=10,
        batch_size=2,
        num_workers=1,
        max_len=300,
        downsample=0.3,
        predict_depth_mult=3,
        dtype=torch.float32,
    )
    metrics, random_indices, genes, expr_pred = dn(
        model=model,
        adata=adata,
    )
    assert metrics["reco2full"] - metrics["noisy2full"] > 0, "Model is not denoising"
    # emb, class, grn inf and fit function for scPRINT
    # Cell embedding
    cell_embedder = Embedder(
        batch_size=2,
        num_workers=1,
        how="random expr",
        max_len=300,
        doclass=True,
        pred_embedding=[
            "cell_type_ontology_term_id",
            "disease_ontology_term_id",
            "self_reported_ethnicity_ontology_term_id",
            "sex_ontology_term_id",
        ],
        plot_corr_size=8,
        doplot=True,
        keep_all_cls_pred=False,
        dtype=torch.float32,
    )
    adata_emb, metrics = cell_embedder(model, adata[:10, :])
    assert "scprint" in adata_emb.obsm, "Cell embedding failed"

    assert any(
        col.startswith("pred_") for col in adata_emb.obs.columns
    ), "Classification failed"

    # GRN inference
    grn_inferer = GNInfer(
        layer=[0, 1],
        batch_size=2,
        how="most var within",
        preprocess="softmax",
        head_agg="mean",
        filtration="thresh",
        forward_mode="none",
        num_genes=100,
        max_cells=10,
        doplot=False,
        dtype=torch.float32,
    )
    grn_adata = grn_inferer(model, adata)
    assert "GRN" in grn_adata.varp, "GRN inference failed"
    # fit scprint
    # cli
    # get_Seq
    # sinkhorn
    # knn_smooth
    # layernorm
    # tmfg
    # utils
    # layer_norm
    # flashattention
    # encoders
    # model
    # cell emb
    # denoise
    # grn
