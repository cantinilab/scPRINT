													
colgroup	names	comment	time per epoch (A100)	denoising	embedding & batch correction		cell type prediction		gn prediction score				run id
colgroup	names	comment	time per epoch (A100)	score	lung	pancreas	lung	pancreas	OR gwps	OR omnipath	AUPRC gwps	AUPRC omnipath	run id
BASE	BASE + var across seed		130	0,02+-0,02	0,52+-0,02	0,45+-0,02	0,62+-0,07	0,53+-0.1	4,4+-0,8	1,8+-0,5	0,044+-0.002	0,00139+-0.00008	icy-serenity-2, snowy-paper-5, still-dragon-75, atomic-totem-251
	BASE medium model		180	0,03	0,53	0,45	0,64	0,48	4,7	1,5	0,048	0,00146	solar-durian-637
architecture	no dropout	stopped at 11	130	-0,02	0,55	0,5	0,71	0,61	4,9	1,2	0,042	0,0136	graceful-cloud-64
	large classifier		130	0	0,53	0,44	0,53	0,49	4,4	1,4	0,046	0,00156	chocolate-snowball-718
	MVC		90	0,00	0,51	0,43	0,68	0,64	3,9	1,6	0,04	0,0014	wise-wood-77
	no decoders / generation		80	-0,02	0,48	0,44	0,7	0,64	3,7	1,1	0,034	0,00114	lunar-disco-67
	XPressor		180	0,01	0,56	0,5	0,75	0,69	4,1	1,7	0,04	0,00147	peach-disco-72
data	only tahoe		130	0	0,4	0,33	0	0	4,8	0,5	0,0041	0,00104	young-bush-669
	all + tahoe (+denoise)		150	0,16	0,44	0,37	0,54	0,25	4,7	2	0,044	0,00144	wobbly-brook-309
	full CZI		130	0,03	0,51	0,44	0,67	0,18	3,8	2	0,043	0,00162	faithful-dragon-663
	high quality human data only		130	0,04	0,53	0,45	0,64	0,19	3,9	2,8	0,041	0,00147	stoic-dust-9
	good quality data		130	0,02	0,54	0,47	0,69	0,65	3,3	1	0,039	0,00139	funny-you-10
	no replacement /no weighted random sampling		130	0,00	0,5	0,45	0,36	0,34	4,5	2,4	0,045	0,0016	autumn-aardvark-702
	only clust cell type		130	0,03	0,51	0,44	0,69	0,62	3,7	2	0,0399	0,00145	absurd-plasma-1
	meta-cell		180	0,02	0,55	0,47	0,72	0,66	4,9	1,5	0,045	0,00149	solar-monkey-69
attention	softpick attn	RERUN	240										pretty-plant-410
	criss cross attn (+3000 context length)		150	0,03	0,5	0,44	0,46	0,3	2,7	2	0,034	0,00145	swept-field-339
	hyper attn(+denoise)		200	0,16	0,45	0,41	0,17	0,03	4,7	1,1	0,048	0,00143	colorful-leaf-340
	attention bias	RERUN	150	0,03	0,43	0,34	0,3	0,1	3,8	1,1	0,042	0,00146	curious-shape-578
loss	embedding contrastive (loss) (+full forward+denoise)	RERUN	200	0,16	0,44	0,38	0,7	0,57	4	1,7	0,04	0,00157	pretty-glitter-94
	embedding elastic similarity (loss)		130	0,01	0,5	0,44	0,68	0,54	4,9	1,3	0,047	0,00148	classic-surf-79
	embedding independence (loss)		130	0,02	0,53	0,47	0,65	0,65	4,2	1,3	0,044	0,00145	devoted-dew-68
	ZINB+MSE (loss)		130	0,3	0,53	0,45	0,62	0,47	3,2	2,7	0,037	0,00187	fast-cherry-61
	MSE (loss)		130	-0,04	0,54	0,46	0,62	0,43	3,3	1,2	0,042	0,00166	generous-dawn-666
	with VAE (loss)		140	0,03	0,51	0,42	0,38	0,27	4,2	1,7	0,044	0,0016	wild-terrain-694
pretraining task	var context length and larger context (task)		260	0,03	0,55	0,47	0,75	0,71	4,8	1,3	0,044	0,00137	stoic-spaceship-58
	TF masking (task)		130	0,04	0,49	0,44	0,6	0,6	4,4	1,3	0,043	0,00151	volcanic-capybara-65
	denoising (task)		130	0,22	0,55	0,47	0,7	0,69	3,7	3	0,038	0,0018	stoic-spaceship-58
	GNN		150	0,44	0,48	0,42	0,38	0,35	4	1,4	0,042	0,00128	
	binning		130	-0,02	0,52	0,46	0,43	0,41	4,2	1,3	0,047	0,00162	sage-bird-657
	no classification		130	0,03	0,5	0,4	0	0	3,9	1,2	0,043	0,00129	copper-frost-625, misty-frog-428
	adv classifier (+larger classif)		130	0,01	0,52	0,42	0,48	0,43	4,1	1,6	0,044	0,0014	sunny-morning-629
input	sum normalization	likely because the second dataset esp has many different seq methodology and simpler to sum norm	130	0,02	0,53	0,49	0,73	0,7	2,7	1	0,028	0,00122	vocal-bee-78
	only expr genes		130	0,01	0,51	0,45	0,52	0,37	4,5	2.1	0,045	0,164	rural-pine-670
	depth at input	REDO with denoising	130	0,03	0,53	0,46	0,71	0,6	4,6	1,6	0,044	0,00163	revived-disco-63
	without gene location		130	0,03	0,55	0,47	0,73	0,64	3,8	1,1	0,039	0,00139	worthy-durian-70
	learn gene emb		200	0,03	0,53	0,43	0,7	0,54	3,6	1,6	0,039	0,00143	vibrant-serenity-66
	fine-tune ESM2		130	0,02	0,54	0,45	0,71	0,68	4,5	2,4	0,043	0,00143	curious-sky-160
	tiny model (V1)		130	0,34	0,44	0,41	0,22	0,11	4,4	2	0,039	0,00137	
	small model (V1)		200	0,2	0,54	0,52	0,54	0,78	3,9	1,6	0,039	0,00145	
	medium model (V1)		300	0,25	0,56	0,48	0,48	0,81	3,7	1,6	0,046	0,00183	