model:
  nhead: 8
  num_heads_kv: 4
  nlayers: 16 #used to be 12
  layers_cls: [512]
  d_model: 512
  dropout: 0.1
data:
  batch_size: 8 #16

