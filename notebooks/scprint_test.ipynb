{
      "cells": [
            {
                  "cell_type": "code",
                  "execution_count": 24,
                  "metadata": {},
                  "outputs": [
                        {
                              "name": "stdout",
                              "output_type": "stream",
                              "text": [
                                    "^C\n",
                                    "Traceback (most recent call last):\n",
                                    "  File \"/home/ml4ig1/miniconda3/envs/scprint/bin/lamin\", line 5, in <module>\n",
                                    "    from lamin_cli.__main__ import main\n",
                                    "  File \"/home/ml4ig1/miniconda3/envs/scprint/lib/python3.10/site-packages/lamin_cli/__main__.py\", line 11, in <module>\n",
                                    "    import rich_click as click\n",
                                    "  File \"/home/ml4ig1/miniconda3/envs/scprint/lib/python3.10/site-packages/rich_click/__init__.py\", line 73, in <module>\n",
                                    "    from . import rich_click as rich_click\n",
                                    "  File \"/home/ml4ig1/miniconda3/envs/scprint/lib/python3.10/site-packages/rich_click/rich_click.py\", line 6, in <module>\n",
                                    "    import rich.columns\n",
                                    "  File \"/home/ml4ig1/miniconda3/envs/scprint/lib/python3.10/site-packages/rich/columns.py\", line 7, in <module>\n",
                                    "    from .console import Console, ConsoleOptions, RenderableType, RenderResult\n",
                                    "  File \"/home/ml4ig1/miniconda3/envs/scprint/lib/python3.10/site-packages/rich/console.py\", line 57, in <module>\n",
                                    "    from .markup import render as render_markup\n",
                                    "  File \"<frozen importlib._bootstrap>\", line 1027, in _find_and_load\n",
                                    "  File \"<frozen importlib._bootstrap>\", line 1006, in _find_and_load_unlocked\n",
                                    "  File \"<frozen importlib._bootstrap>\", line 674, in _load_unlocked\n",
                                    "  File \"<frozen importlib._bootstrap>\", line 577, in module_from_spec\n",
                                    "  File \"<frozen importlib._bootstrap>\", line 541, in _init_module_attrs\n",
                                    "KeyboardInterrupt\n"
                              ]
                        }
                  ],
                  "source": [
                        "! lamin load scprint"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 1,
                  "metadata": {},
                  "outputs": [
                        {
                              "name": "stderr",
                              "output_type": "stream",
                              "text": [
                                    "Global seed set to 42\n"
                              ]
                        },
                        {
                              "name": "stdout",
                              "output_type": "stream",
                              "text": [
                                    "ðŸ’¡ connected lamindb: jkobject/scprint\n"
                              ]
                        },
                        {
                              "name": "stderr",
                              "output_type": "stream",
                              "text": [
                                    "/home/ml4ig1/miniconda3/envs/scprint/lib/python3.10/site-packages/umap/__init__.py:9: ImportWarning: Tensorflow not installed; ParametricUMAP will be unavailable\n",
                                    "  warn(\n",
                                    "2024-05-14 10:34:41,093:INFO - Downloading data from `https://omnipathdb.org/queries/enzsub?format=json`\n",
                                    "2024-05-14 10:34:41,233:INFO - Downloading data from `https://omnipathdb.org/queries/interactions?format=json`\n",
                                    "2024-05-14 10:34:41,327:INFO - Downloading data from `https://omnipathdb.org/queries/complexes?format=json`\n",
                                    "2024-05-14 10:34:41,420:INFO - Downloading data from `https://omnipathdb.org/queries/annotations?format=json`\n",
                                    "2024-05-14 10:34:41,506:INFO - Downloading data from `https://omnipathdb.org/queries/intercell?format=json`\n",
                                    "2024-05-14 10:34:41,716:INFO - Downloading data from `https://omnipathdb.org/about?format=text`\n",
                                    "/home/ml4ig1/miniconda3/envs/scprint/lib/python3.10/site-packages/arboreto/core.py:12: DeprecationWarning: The current Dask DataFrame implementation is deprecated. \n",
                                    "In a future release, Dask DataFrame will use a new implementation that\n",
                                    "contains several improvements including a logical query planning.\n",
                                    "The user-facing DataFrame API will remain unchanged.\n",
                                    "\n",
                                    "The new implementation is already available and can be enabled by\n",
                                    "installing the dask-expr library:\n",
                                    "\n",
                                    "    $ pip install dask-expr\n",
                                    "\n",
                                    "and turning the query planning option on:\n",
                                    "\n",
                                    "    >>> import dask\n",
                                    "    >>> dask.config.set({'dataframe.query-planning': True})\n",
                                    "    >>> import dask.dataframe as dd\n",
                                    "\n",
                                    "API documentation for the new implementation is available at\n",
                                    "https://docs.dask.org/en/stable/dask-expr-api.html\n",
                                    "\n",
                                    "Any feedback can be reported on the Dask issue tracker\n",
                                    "https://github.com/dask/dask/issues \n",
                                    "\n",
                                    "To disable this warning in the future, set dask config:\n",
                                    "\n",
                                    "    # via Python\n",
                                    "    >>> dask.config.set({'dataframe.query-planning-warning': False})\n",
                                    "\n",
                                    "    # via CLI\n",
                                    "    dask config set dataframe.query-planning-warning False\n",
                                    "\n",
                                    "\n",
                                    "  from dask.dataframe import from_delayed\n",
                                    "/home/ml4ig1/miniconda3/envs/scprint/lib/python3.10/site-packages/pyscenic/transform.py:42: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
                                    "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
                                    "  (\"Enrichment\", COLUMN_NAME_ANNOTATION): np.object,\n",
                                    "/home/ml4ig1/miniconda3/envs/scprint/lib/python3.10/site-packages/pyscenic/transform.py:43: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
                                    "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
                                    "  (\"Enrichment\", COLUMN_NAME_CONTEXT): np.object,\n",
                                    "/home/ml4ig1/miniconda3/envs/scprint/lib/python3.10/site-packages/pyscenic/transform.py:44: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
                                    "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
                                    "  (\"Enrichment\", COLUMN_NAME_TARGET_GENES): np.object,\n",
                                    "/home/ml4ig1/miniconda3/envs/scprint/lib/python3.10/site-packages/chex/_src/pytypes.py:53: DeprecationWarning: jax.core.Shape is deprecated. Use Shape = Sequence[int | Any].\n",
                                    "  Shape = jax.core.Shape\n",
                                    "/home/ml4ig1/miniconda3/envs/scprint/lib/python3.10/site-packages/chex/_src/pytypes.py:54: DeprecationWarning: jax.random.KeyArray is deprecated. Use jax.Array for annotations, and jax.dtypes.issubdtype(arr.dtype, jax.dtypes.prng_key) for runtime detection of typed prng keys (i.e. keys created with jax.random.key).\n",
                                    "For more information, see https://jax.readthedocs.io/en/latest/jep/9263-typed-keys.html\n",
                                    "  PRNGKey = jax.random.KeyArray\n",
                                    "/home/ml4ig1/miniconda3/envs/scprint/lib/python3.10/site-packages/scib_metrics/_types.py:9: DeprecationWarning: jax.random.KeyArray is deprecated. Use jax.Array for annotations, and jax.dtypes.issubdtype(arr.dtype, jax.dtypes.prng_key) for runtime detection of typed prng keys (i.e. keys created with jax.random.key).\n",
                                    "For more information, see https://jax.readthedocs.io/en/latest/jep/9263-typed-keys.html\n",
                                    "  IntOrKey = Union[int, jax.random.KeyArray]\n",
                                    "/home/ml4ig1/miniconda3/envs/scprint/lib/python3.10/site-packages/scib_metrics/utils/_utils.py:40: DeprecationWarning: jax.random.KeyArray is deprecated. Use jax.Array for annotations, and jax.dtypes.issubdtype(arr.dtype, jax.dtypes.prng_key) for runtime detection of typed prng keys (i.e. keys created with jax.random.key).\n",
                                    "For more information, see https://jax.readthedocs.io/en/latest/jep/9263-typed-keys.html\n",
                                    "  def validate_seed(seed: IntOrKey) -> jax.random.KeyArray:\n",
                                    "/home/ml4ig1/miniconda3/envs/scprint/lib/python3.10/site-packages/scib_metrics/utils/_kmeans.py:21: DeprecationWarning: jax.random.KeyArray is deprecated. Use jax.Array for annotations, and jax.dtypes.issubdtype(arr.dtype, jax.dtypes.prng_key) for runtime detection of typed prng keys (i.e. keys created with jax.random.key).\n",
                                    "For more information, see https://jax.readthedocs.io/en/latest/jep/9263-typed-keys.html\n",
                                    "  def _initialize_random(X: jnp.ndarray, n_clusters: int, key: jax.random.KeyArray) -> jnp.ndarray:\n",
                                    "/home/ml4ig1/miniconda3/envs/scprint/lib/python3.10/site-packages/scib_metrics/utils/_kmeans.py:31: DeprecationWarning: jax.random.KeyArray is deprecated. Use jax.Array for annotations, and jax.dtypes.issubdtype(arr.dtype, jax.dtypes.prng_key) for runtime detection of typed prng keys (i.e. keys created with jax.random.key).\n",
                                    "For more information, see https://jax.readthedocs.io/en/latest/jep/9263-typed-keys.html\n",
                                    "  def _initialize_plus_plus(X: jnp.ndarray, n_clusters: int, key: jax.random.KeyArray) -> jnp.ndarray:\n"
                              ]
                        }
                  ],
                  "source": [
                        "from lightning.pytorch import Trainer, seed_everything\n",
                        "from lightning.pytorch.callbacks import ModelCheckpoint, StochasticWeightAveraging, EarlyStopping, LearningRateMonitor, LearningRateFinder\n",
                        "\n",
                        "seed_everything(42, workers=True)\n",
                        "\n",
                        "from scprint import scPrint\n",
                        "from scprint.trainer import TrainingMode\n",
                        "from scdataloader import DataModule \n",
                        "import pandas as pd\n",
                        "from scdataloader.utils import load_genes\n",
                        "\n",
                        "import torch\n",
                        "torch.set_float32_matmul_precision('medium')\n",
                        "\n",
                        "%load_ext autoreload\n",
                        "%autoreload 2"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 2,
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "# TODO: drop tissue & dev stage until part or is taken in account\n",
                        "\n",
                        "hierarchical_clss = [\n",
                        "    \"cell_type_ontology_term_id\", #1\n",
                        "    # \"tissue_ontology_term_id\",\n",
                        "    \"disease_ontology_term_id\", # 2\n",
                        "#    \"development_stage_ontology_term_id\",\n",
                        "    \"assay_ontology_term_id\", #3\n",
                        "    'self_reported_ethnicity_ontology_term_id', #4\n",
                        "]\n",
                        "clss_to_pred = hierarchical_clss+[\n",
                        "    'sex_ontology_term_id', #5\n",
                        "    \"organism_ontology_term_id\", #6\n",
                        "]\n",
                        "all_clss = clss_to_pred+[\n",
                        "    #'dataset_id',\n",
                        "    #'cell_culture',\n",
                        "  #  \"heat_diff\",\n",
                        "  #  \"total_counts\",\n",
                        "  # \"nnz\",\n",
                        "  #  \"dpt_group\",\n",
                        "]\n",
                        "\n",
                        "gene_emb = '../data/main/gene_embeddings.parquet'\n",
                        "d_model=128"
                  ]
            },
            {
                  "cell_type": "markdown",
                  "metadata": {},
                  "source": []
            },
            {
                  "cell_type": "code",
                  "execution_count": 3,
                  "metadata": {},
                  "outputs": [
                        {
                              "name": "stdout",
                              "output_type": "stream",
                              "text": [
                                    "won't do any check but we recommend to have your dataset coming from local storage\n",
                                    "\n",
                                    "80.0% are aligned\n",
                                    "seeing a string: loading gene positions as biomart parquet file\n"
                              ]
                        }
                  ],
                  "source": [
                        "datamodule = DataModule(\n",
                        "    collection_name=\"some\",\n",
                        "    gene_embeddings=gene_emb,\n",
                        "    all_clss=all_clss,\n",
                        "    hierarchical_clss=hierarchical_clss,\n",
                        "    organisms=[\"NCBITaxon:9606\"],#, \"NCBITaxon:10090\"],\n",
                        "    how=\"most expr\",\n",
                        "    max_len=1200,\n",
                        "    add_zero_genes=0,\n",
                        "    # how much more you will see the most present vs less present category \n",
                        "    weight_scaler=10,\n",
                        "    clss_to_weight=clss_to_pred,\n",
                        "    clss_to_pred=clss_to_pred,\n",
                        "    batch_size=1,\n",
                        "    num_workers=1,\n",
                        "    #train_oversampling=2,\n",
                        "    validation_split=0.05,\n",
                        "    do_gene_pos='../data/main/biomart_pos.parquet',\n",
                        "    test_split=0.05)\n",
                        "testfiles = datamodule.setup()"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 4,
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "# create a function to transform an scGPT checkpoint to an scPrint's\n",
                        "# ckpt = torch.load(\"../../scGPT/save/model_e6.pt\")\n",
                        "# scPrint.load_from_checkpoint(\"../../scGPT/save/model_e6.pt\")"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 5,
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "#from lightning.pytorch.profilers import PyTorchProfiler\n",
                        "#pytorch_prof = PyTorchProfiler(\"../data/tensorboard\", emit_nvtx=False, group_by_input_shape=True, record_shapes=True, profile_memory=True, with_stack=True, on_trace_ready=torch.profiler.tensorboard_trace_handler(\"../data/tensorboard/\"),)"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 6,
                  "metadata": {},
                  "outputs": [
                        {
                              "data": {
                                    "text/plain": [
                                          "128"
                                    ]
                              },
                              "execution_count": 6,
                              "metadata": {},
                              "output_type": "execute_result"
                        }
                  ],
                  "source": [
                        "d_model"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 4,
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "model = scPrint(\n",
                        "    genes = datamodule.genes,\n",
                        "    d_model = d_model*4,\n",
                        "    nhead = 4*2,\n",
                        "    nlayers = 1,\n",
                        "    #layers_cls = [d_model],\n",
                        "    #labels = datamodule.labels,\n",
                        "    #cls_hierarchy = datamodule.cls_hierarchy,\n",
                        "    dropout= 0,\n",
                        "    transformer = \"flash\",\n",
                        "    precpt_gene_emb = gene_emb,\n",
                        "    gene_pos_enc = datamodule.gene_pos,\n",
                        "    mvc_decoder = \"inner product\",\n",
                        "    #label_decoders = datamodule.decoders,\n",
                        "    fused_dropout_add_ln = False,\n",
                        "    #num_batch_labels = datamodule.num_datasets,\n",
                        "    checkpointing=False,\n",
                        "    prenorm=True,\n",
                        "    num_heads_kv=None,\n",
                        "    weight_decay=0,\n",
                        ")"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 5,
                  "metadata": {},
                  "outputs": [
                        {
                              "name": "stderr",
                              "output_type": "stream",
                              "text": [
                                    "2024-05-14 10:35:18,565:ERROR - Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
                                    "wandb: Currently logged in as: jkobject (ml4ig). Use `wandb login --relogin` to force relogin\n",
                                    "/home/ml4ig1/miniconda3/envs/scprint/lib/python3.10/site-packages/wandb/sdk/lib/ipython.py:77: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
                                    "  from IPython.core.display import HTML, display  # type: ignore\n"
                              ]
                        },
                        {
                              "data": {
                                    "text/html": [
                                          "wandb version 0.17.0 is available!  To upgrade, please run:\n",
                                          " $ pip install wandb --upgrade"
                                    ],
                                    "text/plain": [
                                          "<IPython.core.display.HTML object>"
                                    ]
                              },
                              "metadata": {},
                              "output_type": "display_data"
                        },
                        {
                              "data": {
                                    "text/html": [
                                          "Tracking run with wandb version 0.16.2"
                                    ],
                                    "text/plain": [
                                          "<IPython.core.display.HTML object>"
                                    ]
                              },
                              "metadata": {},
                              "output_type": "display_data"
                        },
                        {
                              "data": {
                                    "text/html": [
                                          "Run data is saved locally in <code>../data/tensorboard/wandb/run-20240514_103520-jjyqhvwu</code>"
                                    ],
                                    "text/plain": [
                                          "<IPython.core.display.HTML object>"
                                    ]
                              },
                              "metadata": {},
                              "output_type": "display_data"
                        },
                        {
                              "data": {
                                    "text/html": [
                                          "Syncing run <strong><a href='https://wandb.ai/ml4ig/scprint_test/runs/jjyqhvwu' target=\"_blank\">hopeful-dew-73</a></strong> to <a href='https://wandb.ai/ml4ig/scprint_test' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
                                    ],
                                    "text/plain": [
                                          "<IPython.core.display.HTML object>"
                                    ]
                              },
                              "metadata": {},
                              "output_type": "display_data"
                        },
                        {
                              "data": {
                                    "text/html": [
                                          " View project at <a href='https://wandb.ai/ml4ig/scprint_test' target=\"_blank\">https://wandb.ai/ml4ig/scprint_test</a>"
                                    ],
                                    "text/plain": [
                                          "<IPython.core.display.HTML object>"
                                    ]
                              },
                              "metadata": {},
                              "output_type": "display_data"
                        },
                        {
                              "data": {
                                    "text/html": [
                                          " View run at <a href='https://wandb.ai/ml4ig/scprint_test/runs/jjyqhvwu' target=\"_blank\">https://wandb.ai/ml4ig/scprint_test/runs/jjyqhvwu</a>"
                                    ],
                                    "text/plain": [
                                          "<IPython.core.display.HTML object>"
                                    ]
                              },
                              "metadata": {},
                              "output_type": "display_data"
                        },
                        {
                              "name": "stderr",
                              "output_type": "stream",
                              "text": [
                                    "wandb: logging graph, to disable use `wandb.watch(log_graph=False)`\n"
                              ]
                        }
                  ],
                  "source": [
                        "#from lightning.pytorch.loggers import TensorBoardLogger\n",
                        "from lightning.pytorch.loggers import WandbLogger\n",
                        "\n",
                        "wandb_logger = WandbLogger(project=\"scprint_test\", save_dir=\"../data/tensorboard\")\n",
                        "wandb_logger.watch(model, log='all', log_freq=50, log_graph=True)\n",
                        "\n",
                        "#tlogger = TensorBoardLogger(save_dir=\"../data/tensorboard\")\n",
                        "#tlogger.log_graph(model)\n"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 6,
                  "metadata": {},
                  "outputs": [
                        {
                              "name": "stderr",
                              "output_type": "stream",
                              "text": [
                                    "Using 16bit Automatic Mixed Precision (AMP)\n",
                                    "GPU available: True (cuda), used: True\n",
                                    "TPU available: False, using: 0 TPU cores\n",
                                    "IPU available: False, using: 0 IPUs\n",
                                    "HPU available: False, using: 0 HPUs\n",
                                    "`Trainer(limit_val_batches=1)` was configured so 1 batch will be used.\n"
                              ]
                        }
                  ],
                  "source": [
                        "chckp = ModelCheckpoint(monitor=\"val_loss\", save_top_k=-1)\n",
                        "trainingmode = TrainingMode(\n",
                        "    do_denoise=True, \n",
                        "    noise=[0.01],\n",
                        "    do_cce=False, \n",
                        "    cce_sim=0.6, \n",
                        "    do_ecs=False, \n",
                        "    ecs_threshold = 0.4, \n",
                        "    ecs_scale = 0.05,\n",
                        "    class_scale = 0.08,\n",
                        "    do_cls=False,\n",
                        "    do_mvc=False, \n",
                        "    do_adv_cls=False,\n",
                        "    do_next_tp=False, \n",
                        "    mask_ratio=[], \n",
                        "    warmup_duration= 100, \n",
                        "    fused_adam= True,\n",
                        "    lr_reduce_patience=200,\n",
                        "    )\n",
                        "#es = EarlyStopping(patience=2, monitor='val_loss')\n",
                        "#swa = StochasticWeightAveraging(swa_lrs= 0.01)\n",
                        "#lrm = LearningRateMonitor(logging_interval=\"step\")\n",
                        "#lrf = LearningRateFinder(mode=\"exponential\",)\n",
                        "# TODO: to check that the class hierarchy are really ordered from 1-2-3-4... as well (oredered dict)\n",
                        "trainer = Trainer(precision=\"16-mixed\", gradient_clip_val=500, max_time={\"hours\": 2}, limit_val_batches=1, callbacks=[trainingmode], accumulate_grad_batches=1, check_val_every_n_epoch=10000000,reload_dataloaders_every_n_epochs=1000000, logger=wandb_logger)#, logger=tlogger) #detect_anomaly=True, fast_dev_run=20, overfit_batches=10, limit_train_batches=1, limit_val_batches=0\n",
                        "#logger=wandb_logger,"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 7,
                  "metadata": {},
                  "outputs": [
                        {
                              "name": "stderr",
                              "output_type": "stream",
                              "text": [
                                    "Using 16bit Automatic Mixed Precision (AMP)\n",
                                    "GPU available: True (cuda), used: True\n",
                                    "TPU available: False, using: 0 TPU cores\n",
                                    "IPU available: False, using: 0 IPUs\n",
                                    "HPU available: False, using: 0 HPUs\n",
                                    "`Trainer(overfit_batches=1)` was configured so 1 batch will be used.\n"
                              ]
                        }
                  ],
                  "source": [
                        "# sanity. should be overfiting.\n",
                        "trainer = Trainer(precision=\"16-mixed\", gradient_clip_val=500, max_time={\"hours\": 2}, limit_val_batches=1, callbacks=[trainingmode], accumulate_grad_batches=1, check_val_every_n_epoch=1000_000, overfit_batches=1,reload_dataloaders_every_n_epochs=1000_000, logger=wandb_logger)"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 8,
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "model.lr_reduce_patience = 50\n",
                        "model.lr_reduce_ratio = 0.2"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 9,
                  "metadata": {},
                  "outputs": [
                        {
                              "name": "stderr",
                              "output_type": "stream",
                              "text": [
                                    "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
                                    "\n",
                                    "  | Name          | Type                    | Params\n",
                                    "----------------------------------------------------------\n",
                                    "0 | gene_encoder  | GeneEncoder             | 11.9 M\n",
                                    "1 | expr_encoder  | ContinuousValueEncoder  | 264 K \n",
                                    "2 | pos_encoder   | PositionalEncoding      | 0     \n",
                                    "3 | class_encoder | CategoryValueEncoder    | 512   \n",
                                    "4 | depth_encoder | ContinuousValueEncoder  | 264 K \n",
                                    "5 | transformer   | FlashTransformerEncoder | 3.2 M \n",
                                    "6 | expr_decoder  | ExprDecoder             | 528 K \n",
                                    "7 | cls_decoders  | ModuleDict              | 0     \n",
                                    "8 | mvc_decoder   | MVCDecoder              | 1.1 M \n",
                                    "----------------------------------------------------------\n",
                                    "5.3 M     Trainable params\n",
                                    "11.9 M    Non-trainable params\n",
                                    "17.1 M    Total params\n",
                                    "68.459    Total estimated model params size (MB)\n",
                                    "wandb: WARNING Serializing object of type list that is 194680 bytes\n",
                                    "wandb: WARNING Serializing object of type list that is 194680 bytes\n",
                                    "wandb: WARNING Serializing object of type list that is 194680 bytes\n",
                                    "wandb: WARNING Serializing object of type list that is 194680 bytes\n"
                              ]
                        },
                        {
                              "data": {
                                    "application/vnd.jupyter.widget-view+json": {
                                          "model_id": "9831f2ec5d884eee9cc7f0f29f092b94",
                                          "version_major": 2,
                                          "version_minor": 0
                                    },
                                    "text/plain": [
                                          "Sanity Checking: 0it [00:00, ?it/s]"
                                    ]
                              },
                              "metadata": {},
                              "output_type": "display_data"
                        },
                        {
                              "name": "stdout",
                              "output_type": "stream",
                              "text": [
                                    "> /home/ml4ig1/Documents code/scPRINT/scprint/model/model.py(852)_compute_loss()\n",
                                    "    850         import/home/ml4ig1/Documents code/scPRINT/scprint/model/model.py(852)_compute_loss()\n",
                                    "    850         import pdb\n",
                                    "    851         pdb.set_trace()\n",
                                    "--> 852         loss_expr = loss.zinb(\n",
                                    "    853             theta=output[\"disp\"],\n",
                                    "    854             pi=output[\"zero_logits\"],\n",
                                    "\n",
                                    "*** NameError: name 'F' is not defined\n",
                                    "*** NameError: name 'F' is not defined\n",
                                    "tensor([[238., 141., 138.,  ...,   1.,   1.,   1.]], device='cuda:0')\n",
                                    "tensor([[238., 141., 138.,  ...,   0.,   0.,   0.]], device='cuda:0')\n",
                                    "tensor(2.8642, device='cuda:0')\n",
                                    "tensor([[-10., -10., -10.,  ..., -10., -10., -10.]], device='cuda:0')\n",
                                    "*** NameError: name 'disp' is not defined\n",
                                    "tensor([[100., 100., 100.,  ..., 100., 100., 100.]], device='cuda:0')\n",
                                    "tensor(1.1938, device='cuda:0')\n",
                                    "tensor(1.1816, device='cuda:0')\n",
                                    "tensor(nan, device='cuda:0')\n",
                                    "tensor(3.0091, device='cuda:0')\n",
                                    "tensor(7.2273, device='cuda:0')\n",
                                    "tensor(1.1851, device='cuda:0')\n",
                                    "tensor(1.2073, device='cuda:0')\n",
                                    "tensor(1.2054, device='cuda:0')\n",
                                    "tensor(1.2073, device='cuda:0')\n",
                                    "tensor(1.1938, device='cuda:0')\n",
                                    "tensor(1.4527, device='cuda:0')\n",
                                    "tensor(nan, device='cuda:0')\n",
                                    "tensor(1.1938, device='cuda:0')\n",
                                    "tensor(1.1938, device='cuda:0')\n",
                                    "tensor(1.1816, device='cuda:0')\n",
                                    "tensor(1.1851, device='cuda:0')\n",
                                    "tensor(4.5796, device='cuda:0')\n",
                                    "tensor(1.1938, device='cuda:0')\n",
                                    "tensor([[238., 141., 138.,  ...,   0.,   0.,   0.]], device='cuda:0')\n",
                                    "tensor(1.1938, device='cuda:0')\n",
                                    "tensor(1.1851, device='cuda:0')\n",
                                    "tensor(89.6938, device='cuda:0')\n",
                                    "tensor(1.1938, device='cuda:0')\n",
                                    "tensor(1.1938, device='cuda:0')\n",
                                    "tensor(1.1938, device='cuda:0')\n",
                                    "tensor(nan, device='cuda:0')\n",
                                    "tensor([[238., 141., 138.,  ...,   0.,   0.,   0.]], device='cuda:0')\n",
                                    "tensor([[238., 141., 138.,  90.,  67.,  64.,  53.,  43.,  40.,  36.,  36.,  36.,\n",
                                    "          36.,  32.,  31.,  30.,  30.,  28.,  26.,  26.,  23.,  23.,  22.,  21.,\n",
                                    "          20.,  20.,  20.,  19.,  19.,  19.,  18.,  18.,  18.,  17.,  16.,  16.,\n",
                                    "          16.,  16.,  16.,  16.,  16.,  15.,  15.,  15.,  15.,  15.,  15.,  15.,\n",
                                    "          15.,  15.,  15.,  14.,  14.,  14.,  13.,  13.,  12.,  12.,  12.,  12.,\n",
                                    "          11.,  11.,  11.,  11.,  11.,  10.,  10.,   9.,   9.,   9.,   9.,   9.,\n",
                                    "           9.,   9.,   8.,   8.,   8.,   8.,   8.,   7.,   7.,   7.,   7.,   7.,\n",
                                    "           7.,   6.,   6.,   6.,   6.,   6.,   6.,   6.,   6.,   6.,   6.,   6.,\n",
                                    "           6.,   6.,   6.,   5.]], device='cuda:0')\n",
                                    "tensor(0.4011, device='cuda:0')\n"
                              ]
                        }
                  ],
                  "source": [
                        "trainer.fit(model, datamodule=datamodule)"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": null,
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "expression[:100]"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": null,
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "weirdly, when input expression is set to 0 and pi is set to 1000. I get a loss of 0\n",
                        "when input expression is set to some set of values and pi=-10, disp=max, mean=input, I get 0.479, decreasing pi doesn't help, making it higher, makes it worse, max of disp is ~3M afterward it increases back (likely due to some overflow??). I am guessing that it would need to be set to infinity for it to work. might be better to use dispersion instead of inverse dispersion?\n",
                        "\n",
                        "all things equal, if disp is set to 2_700_000, I get loss tensor(3.8694, device='cuda:0')\n",
                        "if disp is 2_700_000+1 -> tensor(0.1994, device='cuda:0')\n",
                        "\n",
                        "basically it seems that at too high values or at too low values we get strong instabilities that are exacerbated by the fact that we are in float16.\n",
                        "could it also be because of the espilon? nope\n",
                        "\n",
                        "-> why doesn't my model go to this low loss value??\n",
                        "\n"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": null,
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "import torch.nn.functional as F"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": null,
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "F.mse_loss(expression, expression, reduction=\"mean\")"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": null,
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "loss.nb(\n",
                        "    theta=disp,\n",
                        "    mu=expression,\n",
                        "    target=expression,\n",
                        ")"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": null,
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "loss.nb(\n",
                        "    theta=output[\"disp\"],\n",
                        "    mu=output[\"mean\"],\n",
                        "    target=expression,\n",
                        ").mean()"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": null,
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "loss.zinb(\n",
                        "            theta=output[\"disp\"],\n",
                        "            pi=output[\"zero_logits\"],\n",
                        "            mu=output[\"mean\"],\n",
                        "            target=expression,\n",
                        "        )"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": null,
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "exp(15)"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": null,
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "disp = torch.zeros_like(output[\"disp\"])\n",
                        "pi = torch.zeros_like(output[\"disp\"]) - 10"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": null,
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "# why if it is the inverse dispersion? does setting it to 3_000_000 works but not 10_000_000?\n",
                        "# maybe some overflow??"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": null,
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "loss.zinb(\n",
                        "    theta=disp,\n",
                        "    pi=pi,\n",
                        "    mu=output[\"mean\"],\n",
                        "    target=expression,\n",
                        ")"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": null,
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "loss.zinb(\n",
                        "    theta=disp,\n",
                        "    pi=pi,\n",
                        "    mu=output[\"mean\"],\n",
                        "    target=expression,\n",
                        ")"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": null,
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "loss.zinb(\n",
                        "    theta=disp,\n",
                        "    pi=pi,\n",
                        "    mu=expression,\n",
                        "    target=expression,\n",
                        ")"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": null,
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "loss.zinb(\n",
                        "    theta=output[\"disp\"],\n",
                        "    pi=output[\"zero_logits\"],\n",
                        "    mu=expression,\n",
                        "    target=expression,\n",
                        ")"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": null,
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "loss.zinb(\n",
                        "    theta=disp,\n",
                        "    pi=pi,\n",
                        "    mu=expression,\n",
                        "    target=expression,\n",
                        ")"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": null,
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "%reload_ext tensorboard\n",
                        "%tensorboard --logdir=\"../data/tensorboard\""
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": null,
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "#wandb_logger.finalize(status=\"aborted\")\n",
                        "torch.cuda.empty_cache()"
                  ]
            }
      ],
      "metadata": {
            "kernelspec": {
                  "display_name": "scprint",
                  "language": "python",
                  "name": "python3"
            },
            "language_info": {
                  "codemirror_mode": {
                        "name": "ipython",
                        "version": 3
                  },
                  "file_extension": ".py",
                  "mimetype": "text/x-python",
                  "name": "python",
                  "nbconvert_exporter": "python",
                  "pygments_lexer": "ipython3",
                  "version": "3.10.0"
            }
      },
      "nbformat": 4,
      "nbformat_minor": 2
}
