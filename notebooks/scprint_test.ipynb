{
      "cells": [
            {
                  "cell_type": "code",
                  "execution_count": 1,
                  "metadata": {},
                  "outputs": [
                        {
                              "name": "stderr",
                              "output_type": "stream",
                              "text": [
                                    "Seed set to 42\n",
                                    "/pasteur/appa/homes/jkalfon/miniconda3/envs/scprint17/lib/python3.10/site-packages/bitsandbytes/cextension.py:31: UserWarning: The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n",
                                    "  warn(\"The installed version of bitsandbytes was compiled without GPU support. \"\n"
                              ]
                        },
                        {
                              "name": "stdout",
                              "output_type": "stream",
                              "text": [
                                    "/pasteur/appa/homes/jkalfon/miniconda3/envs/scprint17/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cpu.so: undefined symbol: cadam32bit_grad_fp32\n",
                                    "ðŸ’¡ connected lamindb: jkobject/scprint\n"
                              ]
                        }
                  ],
                  "source": [
                        "from lightning.pytorch import Trainer, seed_everything\n",
                        "from lightning.pytorch.callbacks import ModelCheckpoint, StochasticWeightAveraging, EarlyStopping, LearningRateMonitor, LearningRateFinder\n",
                        "\n",
                        "seed_everything(42, workers=True)\n",
                        "\n",
                        "from scprint import scPrint\n",
                        "from scprint.trainer import TrainingMode\n",
                        "from scdataloader import DataModule \n",
                        "import pandas as pd\n",
                        "from scdataloader.utils import load_genes\n",
                        "\n",
                        "import torch\n",
                        "torch.set_float32_matmul_precision('medium')\n",
                        "\n",
                        "%load_ext autoreload\n",
                        "%autoreload 2"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 2,
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "# TODO: drop tissue & dev stage until part or is taken in account\n",
                        "\n",
                        "hierarchical_clss = [\n",
                        "    \"cell_type_ontology_term_id\",  # 1\n",
                        "    # \"tissue_ontology_term_id\",\n",
                        "    \"disease_ontology_term_id\",  # 2\n",
                        "    #    \"development_stage_ontology_term_id\",\n",
                        "    \"assay_ontology_term_id\",  # 3\n",
                        "    'self_reported_ethnicity_ontology_term_id',  # 4\n",
                        "]\n",
                        "clss_to_pred = hierarchical_clss+[\n",
                        "    'sex_ontology_term_id',  # 5\n",
                        "    \"organism_ontology_term_id\",  # 6\n",
                        "]\n",
                        "all_clss = clss_to_pred+[\n",
                        "    # 'dataset_id',\n",
                        "    # 'cell_culture',\n",
                        "    #  \"heat_diff\",\n",
                        "    #  \"total_counts\",\n",
                        "    # \"nnz\",\n",
                        "    #  \"dpt_group\",\n",
                        "]\n",
                        "\n",
                        "gene_emb = '../data/main/gene_embeddings.parquet'\n",
                        "d_model = 128"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 3,
                  "metadata": {},
                  "outputs": [
                        {
                              "name": "stdout",
                              "output_type": "stream",
                              "text": [
                                    "won't do any check but we recommend to have your dataset coming from local storage\n",
                                    "83.14606741573034% are aligned\n",
                                    "seeing a string: loading gene positions as biomart parquet file\n"
                              ]
                        }
                  ],
                  "source": [
                        "datamodule = DataModule(\n",
                        "    collection_name=\"preprocessed dataset\",\n",
                        "    gene_embeddings=gene_emb,\n",
                        "    all_clss=all_clss,\n",
                        "    hierarchical_clss=hierarchical_clss,\n",
                        "    organisms=[\"NCBITaxon:9606\"],  # , \"NCBITaxon:10090\"],\n",
                        "    how=\"most expr\",\n",
                        "    max_len=1200,\n",
                        "    add_zero_genes=0,\n",
                        "    # how much more you will see the most present vs less present category\n",
                        "    weight_scaler=10,\n",
                        "    clss_to_weight=clss_to_pred,\n",
                        "    clss_to_pred=clss_to_pred,\n",
                        "    batch_size=1,\n",
                        "    num_workers=1,\n",
                        "    # train_oversampling=2,\n",
                        "    validation_split=0.05,\n",
                        "    do_gene_pos='../data/main/biomart_pos.parquet',\n",
                        "    test_split=0.05)\n",
                        "testfiles = datamodule.setup()"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 4,
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "# create a function to transform an scGPT checkpoint to an scPrint's\n",
                        "# ckpt = torch.load(\"../../scGPT/save/model_e6.pt\")\n",
                        "# scPrint.load_from_checkpoint(\"../../scGPT/save/model_e6.pt\")"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 5,
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "# from lightning.pytorch.profilers import PyTorchProfiler\n",
                        "# pytorch_prof = PyTorchProfiler(\"../data/tensorboard\", emit_nvtx=False, group_by_input_shape=True, record_shapes=True, profile_memory=True, with_stack=True, on_trace_ready=torch.profiler.tensorboard_trace_handler(\"../data/tensorboard/\"),)"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 4,
                  "metadata": {},
                  "outputs": [
                        {
                              "name": "stderr",
                              "output_type": "stream",
                              "text": [
                                    "2024-05-23 10:06:37,366:INFO - Created a temporary directory at /local/scratch/tmp/tmp3iby1_56\n",
                                    "2024-05-23 10:06:37,367:INFO - Writing /local/scratch/tmp/tmp3iby1_56/_remote_module_non_scriptable.py\n"
                              ]
                        },
                        {
                              "ename": "TypeError",
                              "evalue": "FlashTransformerEncoder.__init__() got an unexpected keyword argument 'weight_decay'",
                              "output_type": "error",
                              "traceback": [
                                    "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                                    "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
                                    "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mscPrint\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgenes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdatamodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43md_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43md_model\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnhead\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnlayers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlayers_cls\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43md_model\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclasses\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclasses\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabels_hierarchy\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabels_hierarchy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdropout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtransformer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mflash\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprecpt_gene_emb\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgene_emb\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgene_pos_enc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdatamodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgene_pos\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmvc_decoder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minner product\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabel_decoders\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfused_dropout_add_ln\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_batch_labels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_datasets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcheckpointing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprenorm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_heads_kv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m#zinb=False\u001b[39;49;00m\n\u001b[1;32m     22\u001b[0m \u001b[43m)\u001b[49m\n",
                                    "File \u001b[0;32m~/scPRINT/scprint/model/model.py:277\u001b[0m, in \u001b[0;36mscPrint.__init__\u001b[0;34m(self, genes, precpt_gene_emb, gene_pos_enc, d_model, nhead, d_hid, edge_dim, nlayers, expr_encoder_layers, layers_cls, classes, labels_hierarchy, dropout, transformer, expr_emb_style, domain_spec_batchnorm, n_input_bins, num_batch_labels, mvc_decoder, pred_embedding, cell_emb_style, freeze_embeddings, label_decoders, zinb, lr, **flash_attention_kwargs)\u001b[0m\n\u001b[1;32m    274\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mflash transformer requires flash package\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    275\u001b[0m         \u001b[38;5;66;03m# NOT flash transformer using the special tritton kernel\u001b[39;00m\n\u001b[1;32m    276\u001b[0m         \u001b[38;5;66;03m# or parallelMHA (add the process group thing and faster)\u001b[39;00m\n\u001b[0;32m--> 277\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransformer \u001b[38;5;241m=\u001b[39m \u001b[43mFlashTransformerEncoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    278\u001b[0m \u001b[43m        \u001b[49m\u001b[43md_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    279\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnhead\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    280\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnlayers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    281\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdropout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    282\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_flash_attn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtransformer\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mflash\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    283\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mflash_attention_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    286\u001b[0m \u001b[38;5;66;03m# decoders\u001b[39;00m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;66;03m# expression\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexpr_decoder \u001b[38;5;241m=\u001b[39m decoders\u001b[38;5;241m.\u001b[39mExprDecoder(\n\u001b[1;32m    289\u001b[0m     d_model,\n\u001b[1;32m    290\u001b[0m     nfirst_tokens_to_skip\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcell_embs_count,\n\u001b[1;32m    291\u001b[0m     dropout\u001b[38;5;241m=\u001b[39mdropout,\n\u001b[1;32m    292\u001b[0m     zinb\u001b[38;5;241m=\u001b[39mzinb\n\u001b[1;32m    293\u001b[0m )\n",
                                    "\u001b[0;31mTypeError\u001b[0m: FlashTransformerEncoder.__init__() got an unexpected keyword argument 'weight_decay'"
                              ]
                        }
                  ],
                  "source": [
                        "model = scPrint(\n",
                        "    genes=datamodule.genes,\n",
                        "    d_model=d_model*4,\n",
                        "    nhead=4*2,\n",
                        "    nlayers=1,\n",
                        "    layers_cls = [d_model],\n",
                        "    classes = datamodule.classes,\n",
                        "    labels_hierarchy = datamodule.labels_hierarchy,\n",
                        "    dropout=0,\n",
                        "    transformer=\"flash\",\n",
                        "    precpt_gene_emb=gene_emb,\n",
                        "    gene_pos_enc=datamodule.gene_pos,\n",
                        "    mvc_decoder=\"inner product\",\n",
                        "    label_decoders = datamodule.decoders,\n",
                        "    fused_dropout_add_ln=False,\n",
                        "    num_batch_labels = datamodule.num_datasets,\n",
                        "    checkpointing=False,\n",
                        "    prenorm=True,\n",
                        "    num_heads_kv=None,\n",
                        "    weight_decay=0.01,\n",
                        "    #zinb=False\n",
                        ")"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 6,
                  "metadata": {},
                  "outputs": [
                        {
                              "name": "stderr",
                              "output_type": "stream",
                              "text": [
                                    "2024-05-22 13:05:20,668:ERROR - Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
                                    "wandb: Currently logged in as: jkobject (ml4ig). Use `wandb login --relogin` to force relogin\n",
                                    "/home/ml4ig1/miniconda3/envs/scprint/lib/python3.10/site-packages/wandb/sdk/lib/ipython.py:77: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
                                    "  from IPython.core.display import HTML, display  # type: ignore\n"
                              ]
                        },
                        {
                              "data": {
                                    "text/html": [
                                          "wandb version 0.17.0 is available!  To upgrade, please run:\n",
                                          " $ pip install wandb --upgrade"
                                    ],
                                    "text/plain": [
                                          "<IPython.core.display.HTML object>"
                                    ]
                              },
                              "metadata": {},
                              "output_type": "display_data"
                        },
                        {
                              "data": {
                                    "text/html": [
                                          "Tracking run with wandb version 0.16.2"
                                    ],
                                    "text/plain": [
                                          "<IPython.core.display.HTML object>"
                                    ]
                              },
                              "metadata": {},
                              "output_type": "display_data"
                        },
                        {
                              "data": {
                                    "text/html": [
                                          "Run data is saved locally in <code>../data/tensorboard/wandb/run-20240522_130522-63lflkuu</code>"
                                    ],
                                    "text/plain": [
                                          "<IPython.core.display.HTML object>"
                                    ]
                              },
                              "metadata": {},
                              "output_type": "display_data"
                        },
                        {
                              "data": {
                                    "text/html": [
                                          "Syncing run <strong><a href='https://wandb.ai/ml4ig/scprint_test/runs/63lflkuu' target=\"_blank\">amber-water-9</a></strong> to <a href='https://wandb.ai/ml4ig/scprint_test' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
                                    ],
                                    "text/plain": [
                                          "<IPython.core.display.HTML object>"
                                    ]
                              },
                              "metadata": {},
                              "output_type": "display_data"
                        },
                        {
                              "data": {
                                    "text/html": [
                                          " View project at <a href='https://wandb.ai/ml4ig/scprint_test' target=\"_blank\">https://wandb.ai/ml4ig/scprint_test</a>"
                                    ],
                                    "text/plain": [
                                          "<IPython.core.display.HTML object>"
                                    ]
                              },
                              "metadata": {},
                              "output_type": "display_data"
                        },
                        {
                              "data": {
                                    "text/html": [
                                          " View run at <a href='https://wandb.ai/ml4ig/scprint_test/runs/63lflkuu' target=\"_blank\">https://wandb.ai/ml4ig/scprint_test/runs/63lflkuu</a>"
                                    ],
                                    "text/plain": [
                                          "<IPython.core.display.HTML object>"
                                    ]
                              },
                              "metadata": {},
                              "output_type": "display_data"
                        },
                        {
                              "name": "stderr",
                              "output_type": "stream",
                              "text": [
                                    "wandb: logging graph, to disable use `wandb.watch(log_graph=False)`\n"
                              ]
                        }
                  ],
                  "source": [
                        "# from lightning.pytorch.loggers import TensorBoardLogger\n",
                        "from lightning.pytorch.loggers import WandbLogger\n",
                        "\n",
                        "wandb_logger = WandbLogger(project=\"scprint_test\",\n",
                        "                           save_dir=\"../data/tensorboard\")\n",
                        "wandb_logger.watch(model, log='all', log_freq=50, log_graph=True)\n",
                        "\n",
                        "# tlogger = TensorBoardLogger(save_dir=\"../data/tensorboard\")\n",
                        "# tlogger.log_graph(model)"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 1,
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "import gseapy as gp"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 2,
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "tfchip = gp.get_library(name=\"ENCODE_TF_ChIP-seq_2014\")\n"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 4,
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "import json\n",
                        "\n",
                        "# Save the dictionary to a JSON file\n",
                        "with open('../data/tfchip_data.json', 'w') as file:\n",
                        "    json.dump(tfchip, file)\n",
                        "\n",
                        "# Load the dictionary back from the JSON file\n",
                        "with open('tfchip_data.json', 'r') as file:\n",
                        "    tfchip_loaded = json.load(file)\n"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 7,
                  "metadata": {},
                  "outputs": [
                        {
                              "name": "stderr",
                              "output_type": "stream",
                              "text": [
                                    "Using 16bit Automatic Mixed Precision (AMP)\n",
                                    "GPU available: True (cuda), used: True\n",
                                    "TPU available: False, using: 0 TPU cores\n",
                                    "IPU available: False, using: 0 IPUs\n",
                                    "HPU available: False, using: 0 HPUs\n",
                                    "`Trainer(limit_val_batches=1)` was configured so 1 batch will be used.\n"
                              ]
                        }
                  ],
                  "source": [
                        "chckp = ModelCheckpoint(monitor=\"val_loss\", save_top_k=-1)\n",
                        "trainingmode = TrainingMode(\n",
                        "    do_denoise=True,\n",
                        "    noise=[0.01],\n",
                        "    do_cce=False,\n",
                        "    cce_sim=0.6,\n",
                        "    do_ecs=False,\n",
                        "    ecs_threshold=0.4,\n",
                        "    ecs_scale=0.05,\n",
                        "    class_scale=0.08,\n",
                        "    do_cls=False,\n",
                        "    do_mvc=False,\n",
                        "    do_adv_cls=False,\n",
                        "    do_next_tp=False,\n",
                        "    mask_ratio=[],\n",
                        "    warmup_duration=100,\n",
                        "    fused_adam=True,\n",
                        "    lr_reduce_patience=200,\n",
                        ")\n",
                        "# es = EarlyStopping(patience=2, monitor='val_loss')\n",
                        "# swa = StochasticWeightAveraging(swa_lrs= 0.01)\n",
                        "# lrm = LearningRateMonitor(logging_interval=\"step\")\n",
                        "# lrf = LearningRateFinder(mode=\"exponential\",)\n",
                        "# TODO: to check that the class hierarchy are really ordered from 1-2-3-4... as well (oredered dict)\n",
                        "# , logger=tlogger) #detect_anomaly=True, fast_dev_run=20, overfit_batches=10, limit_train_batches=1, limit_val_batches=0\n",
                        "trainer = Trainer(precision=\"16-mixed\", gradient_clip_val=500, max_time={\"hours\": 2}, limit_val_batches=1, callbacks=[\n",
                        "                  trainingmode], accumulate_grad_batches=1, check_val_every_n_epoch=1, reload_dataloaders_every_n_epochs=1000000, logger=wandb_logger)\n",
                        "# logger=wandb_logger,"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 7,
                  "metadata": {},
                  "outputs": [
                        {
                              "name": "stderr",
                              "output_type": "stream",
                              "text": [
                                    "Using 16bit Automatic Mixed Precision (AMP)\n",
                                    "GPU available: True (cuda), used: True\n",
                                    "TPU available: False, using: 0 TPU cores\n",
                                    "IPU available: False, using: 0 IPUs\n",
                                    "HPU available: False, using: 0 HPUs\n",
                                    "`Trainer(overfit_batches=1)` was configured so 1 batch will be used.\n"
                              ]
                        }
                  ],
                  "source": [
                        "# sanity. should be overfiting.\n",
                        "trainer = Trainer(precision=\"16-mixed\", gradient_clip_val=500, max_time={\"hours\": 2}, limit_val_batches=1, callbacks=[\n",
                        "                  trainingmode], accumulate_grad_batches=1, check_val_every_n_epoch=1, overfit_batches=1, reload_dataloaders_every_n_epochs=1000_000, logger=wandb_logger, num_sanity_val_steps=0)"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": null,
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "from scprint.tasks.grn import default_benchmark"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 9,
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "model.lr_reduce_patience = 50\n",
                        "model.lr_reduce_ratio = 0.2"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 10,
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "model.lr = 0.00001"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": null,
                  "metadata": {},
                  "outputs": [
                        {
                              "name": "stderr",
                              "output_type": "stream",
                              "text": [
                                    "/home/ml4ig1/Documents code/scPRINT/scprint/tasks/grn.py:515: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
                                    "  organisms=adata.obs['organism_ontology_term_id'][0],\n",
                                    "Using 16bit Automatic Mixed Precision (AMP)\n",
                                    "GPU available: True (cuda), used: True\n",
                                    "TPU available: False, using: 0 TPU cores\n",
                                    "IPU available: False, using: 0 IPUs\n",
                                    "HPU available: False, using: 0 HPUs\n",
                                    "/home/ml4ig1/Documents code/scPRINT/scprint/tasks/grn.py:167: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
                                    "  organisms=[subadata.obs['organism_ontology_term_id'][0]],\n",
                                    "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
                              ]
                        },
                        {
                              "data": {
                                    "application/vnd.jupyter.widget-view+json": {
                                          "model_id": "e98d671466dc4343b9e21418751bc904",
                                          "version_major": 2,
                                          "version_minor": 0
                                    },
                                    "text/plain": [
                                          "Predicting: 0it [00:00, ?it/s]"
                                    ]
                              },
                              "metadata": {},
                              "output_type": "display_data"
                        },
                        {
                              "name": "stdout",
                              "output_type": "stream",
                              "text": [
                                    "avg link count: 536246649, sparsity: 1.0\n",
                                    "base enrichment\n",
                                    "too many genes for central computation\n",
                                    "_________________________________________\n",
                                    "TF specific enrichment\n"
                              ]
                        },
                        {
                              "name": "stderr",
                              "output_type": "stream",
                              "text": [
                                    "2024-05-22 13:16:10,303:INFO - Downloading and generating Enrichr library gene sets...\n",
                                    "2024-05-22 13:16:10,305:INFO - Library is already downloaded in: /home/ml4ig1/.cache/gseapy/Enrichr.ENCODE_TF_ChIP-seq_2014.gmt, use local file\n",
                                    "2024-05-22 13:16:10,530:INFO - 0332 gene_sets have been filtered out when max_size=2000 and min_size=0\n"
                              ]
                        },
                        {
                              "name": "stdout",
                              "output_type": "stream",
                              "text": [
                                    "found some significant results for  7.142857142857143 % TFs\n",
                                    "\n",
                                    "_________________________________________\n",
                                    "loading GT,  omnipath\n"
                              ]
                        },
                        {
                              "name": "stderr",
                              "output_type": "stream",
                              "text": [
                                    "/home/ml4ig1/Documents code/benGRN/bengrn/base.py:109: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
                                    "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
                                    "  da = np.zeros(adj.shape, dtype=np.float)\n",
                                    " 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 98/99 [00:26<00:00,  3.76it/s]/home/ml4ig1/Documents code/benGRN/bengrn/base.py:683: RuntimeWarning: invalid value encountered in long_scalars\n",
                                    "  precision_list.append(precision)\n",
                                    "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 99/99 [00:26<00:00,  3.74it/s]\n",
                                    "/home/ml4ig1/Documents code/scPRINT/scprint/tasks/grn.py:532: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
                                    "  organisms=adata.obs['organism_ontology_term_id'][0],\n",
                                    "Using 16bit Automatic Mixed Precision (AMP)\n",
                                    "GPU available: True (cuda), used: True\n",
                                    "TPU available: False, using: 0 TPU cores\n",
                                    "IPU available: False, using: 0 IPUs\n",
                                    "HPU available: False, using: 0 HPUs\n"
                              ]
                        },
                        {
                              "name": "stdout",
                              "output_type": "stream",
                              "text": [
                                    "WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'\n",
                                    "WARNING: It seems you use rank_genes_groups on the raw count data. Please logarithmize your data before calling rank_genes_groups.\n"
                              ]
                        },
                        {
                              "name": "stderr",
                              "output_type": "stream",
                              "text": [
                                    "/home/ml4ig1/Documents code/scPRINT/scprint/tasks/grn.py:167: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
                                    "  organisms=[subadata.obs['organism_ontology_term_id'][0]],\n",
                                    "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
                              ]
                        },
                        {
                              "data": {
                                    "application/vnd.jupyter.widget-view+json": {
                                          "model_id": "6efb9f25b0e24313a1b02f7cc939b638",
                                          "version_major": 2,
                                          "version_minor": 0
                                    },
                                    "text/plain": [
                                          "Predicting: 0it [00:00, ?it/s]"
                                    ]
                              },
                              "metadata": {},
                              "output_type": "display_data"
                        },
                        {
                              "name": "stderr",
                              "output_type": "stream",
                              "text": [
                                    "/home/ml4ig1/Documents code/benGRN/bengrn/base.py:277: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
                                    "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
                                    "  if i in genes and j in genes:\n"
                              ]
                        },
                        {
                              "name": "stdout",
                              "output_type": "stream",
                              "text": [
                                    "true elem 14408 ...\n",
                                    "doing regression....\n"
                              ]
                        },
                        {
                              "name": "stderr",
                              "output_type": "stream",
                              "text": [
                                    "/home/ml4ig1/Documents code/benGRN/bengrn/base.py:303: RuntimeWarning: invalid value encountered in long_scalars\n",
                                    "  \"recall\": (pred[y_test == 1] == 1).sum() / y_test.sum(),\n"
                              ]
                        },
                        {
                              "ename": "ValueError",
                              "evalue": "too many values to unpack (expected 2)",
                              "output_type": "error",
                              "traceback": [
                                    "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                                    "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
                                    "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdefault_benchmark\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m../data/yBCKp6HmXuHa0cZptMo7.h5ad\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m#gwps, other\u001b[39;00m\n",
                                    "File \u001b[0;32m~/Documents code/scPRINT/scprint/tasks/grn.py:539\u001b[0m, in \u001b[0;36mdefault_benchmark\u001b[0;34m(model, default_dataset, cell_types, maxlayers, maxgenes)\u001b[0m\n\u001b[1;32m    526\u001b[0m grn_inferer \u001b[38;5;241m=\u001b[39m GRNfer(model, adata[adata\u001b[38;5;241m.\u001b[39mX\u001b[38;5;241m.\u001b[39msum(\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m500\u001b[39m],\n\u001b[1;32m    527\u001b[0m                      how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmost var across\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    528\u001b[0m                      preprocess\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msoftmax\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    536\u001b[0m                      batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m,\n\u001b[1;32m    537\u001b[0m                      )\n\u001b[1;32m    538\u001b[0m grn \u001b[38;5;241m=\u001b[39m grn_inferer(layer\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mrange\u001b[39m(model\u001b[38;5;241m.\u001b[39mnlayers))[:], cell_type\u001b[38;5;241m=\u001b[39mcelltype)\n\u001b[0;32m--> 539\u001b[0m grn, m \u001b[38;5;241m=\u001b[39m train_classifier(grn, C\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m, train_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m, class_weight\u001b[38;5;241m=\u001b[39m{\n\u001b[1;32m    540\u001b[0m                           \u001b[38;5;241m1\u001b[39m: \u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m0\u001b[39m: \u001b[38;5;241m1\u001b[39m}, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, doplot\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    541\u001b[0m grn\u001b[38;5;241m.\u001b[39mvarp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGRN\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m grn\u001b[38;5;241m.\u001b[39mvarp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclassified\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    542\u001b[0m grn\u001b[38;5;241m.\u001b[39mvar\u001b[38;5;241m.\u001b[39mindex \u001b[38;5;241m=\u001b[39m make_index_unique(grn\u001b[38;5;241m.\u001b[39mvar[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msymbol\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mstr\u001b[39m))\n",
                                    "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
                              ]
                        },
                        {
                              "ename": "",
                              "evalue": "",
                              "output_type": "error",
                              "traceback": [
                                    "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
                                    "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
                                    "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
                                    "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
                              ]
                        }
                  ],
                  "source": [
                        "default_benchmark(model, default_dataset=\"../data/yBCKp6HmXuHa0cZptMo7.h5ad\") #gwps, other"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 9,
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "trainer.fit(model, datamodule=datamodule)"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": null,
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "weirdly, when input expression is set to 0 and pi is set to 1000. I get a loss of 0\n",
                        "when input expression is set to some set of values and pi=-10, disp=max, mean=input, I get 0.479, decreasing pi doesn't help, making it higher, makes it worse, max of disp is ~3M afterward it increases back (likely due to some overflow??). I am guessing that it would need to be set to infinity for it to work. might be better to use dispersion instead of inverse dispersion?\n",
                        "\n",
                        "all things equal, if disp is set to 2_700_000, I get loss tensor(3.8694, device='cuda:0')\n",
                        "if disp is 2_700_000+1 -> tensor(0.1994, device='cuda:0')\n",
                        "\n",
                        "basically it seems that at too high values or at too low values we get strong instabilities that are exacerbated by the fact that we are in float16.\n",
                        "could it also be because of the espilon? nope\n",
                        "\n",
                        "-> why doesn't my model go to this low loss value??\n",
                        "\n"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": null,
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "1. there seems to be an in-between value of disp that makes sense given the expression data\n",
                        "2. "
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": null,
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "import torch.nn.functional as F"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": null,
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "F.mse_loss(expression, expression, reduction=\"mean\")"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": null,
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "loss.nb(\n",
                        "    theta=disp,\n",
                        "    mu=expression,\n",
                        "    target=expression,\n",
                        ")"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": null,
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "loss.zinb(\n",
                        "    theta=output[\"disp\"],\n",
                        "    pi=output[\"zero_logits\"],\n",
                        "    mu=output[\"mean\"],\n",
                        "    target=expression,\n",
                        ")"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": null,
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "loss.zinb(\n",
                        "    theta=output[\"disp\"] + 10000,\n",
                        "    pi=output[\"zero_logits\"]-3,\n",
                        "    mu=expression,\n",
                        "    target=expression,\n",
                        ")"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": null,
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "loss.nb(\n",
                        "    theta=output[\"disp\"],\n",
                        "    mu=output[\"mean\"],\n",
                        "    target=expression,\n",
                        ").mean()"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": null,
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "expr = expression.clone()\n",
                        "expr[:,-20:] = 0\n",
                        "expr[:,:20] +=1"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": null,
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "loss.zinb(\n",
                        "    theta=disp,\n",
                        "    pi=pi,\n",
                        "    mu=output[\"mean\"],\n",
                        "    target=expression,\n",
                        ")"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": null,
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "loss.zinb(\n",
                        "    theta=disp,\n",
                        "    pi=pi,\n",
                        "    mu=1e4*output[\"mean\"]/expression.sum(),\n",
                        "    target=1e4*expression/expression.sum(),\n",
                        ")"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": null,
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "loss.zinb(\n",
                        "    theta=disp,\n",
                        "    pi=pi,\n",
                        "    mu=1e4*expr/expression.sum(),\n",
                        "    target=1e4*expression/expression.sum(),\n",
                        ")"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": null,
                  "metadata": {},
                  "outputs": [],
                  "source": []
            },
            {
                  "cell_type": "code",
                  "execution_count": null,
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "exp(15)"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": null,
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "disp = torch.zeros_like(output[\"disp\"])\n",
                        "pi = torch.zeros_like(output[\"disp\"]) - 10"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": null,
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "# why if it is the inverse dispersion? does setting it to 3_000_000 works but not 10_000_000?\n",
                        "# maybe some overflow??"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": null,
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "loss.zinb(\n",
                        "    theta=disp,\n",
                        "    pi=pi,\n",
                        "    mu=output[\"mean\"],\n",
                        "    target=expression,\n",
                        ")"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": null,
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "loss.zinb(\n",
                        "    theta=disp,\n",
                        "    pi=pi,\n",
                        "    mu=expression,\n",
                        "    target=expression,\n",
                        ")"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": null,
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "loss.zinb(\n",
                        "    theta=output[\"disp\"],\n",
                        "    pi=output[\"zero_logits\"],\n",
                        "    mu=expression,\n",
                        "    target=expression,\n",
                        ")"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": null,
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "loss.zinb(\n",
                        "    theta=disp,\n",
                        "    pi=pi,\n",
                        "    mu=expression,\n",
                        "    target=expression,\n",
                        ")"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": null,
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "%reload_ext tensorboard\n",
                        "%tensorboard --logdir=\"../data/tensorboard\""
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": null,
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "# wandb_logger.finalize(status=\"aborted\")\n",
                        "torch.cuda.empty_cache()"
                  ]
            }
      ],
      "metadata": {
            "kernelspec": {
                  "display_name": "scprint",
                  "language": "python",
                  "name": "python3"
            },
            "language_info": {
                  "codemirror_mode": {
                        "name": "ipython",
                        "version": 3
                  },
                  "file_extension": ".py",
                  "mimetype": "text/x-python",
                  "name": "python",
                  "nbconvert_exporter": "python",
                  "pygments_lexer": "ipython3",
                  "version": "3.10.0"
            }
      },
      "nbformat": 4,
      "nbformat_minor": 2
}
