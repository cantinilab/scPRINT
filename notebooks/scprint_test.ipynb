{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! lamin load scprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ’¡ lamindb instance: jkobject/scprint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Seed set to 42\n",
      "2024-01-23 14:01:57,152:INFO - Seed set to 42\n",
      "2024-01-23 14:01:57,152:INFO - Seed set to 42\n"
     ]
    }
   ],
   "source": [
    "import lamindb as ln\n",
    "import lnschema_bionty as lb\n",
    "\n",
    "import pandas as pd\n",
    "import scanpy as sc \n",
    "\n",
    "from lightning.pytorch import Trainer, seed_everything\n",
    "seed_everything(42, workers=True)\n",
    "\n",
    "from scprint import scPrint\n",
    "from scprint.utils import getBiomartTable\n",
    "\n",
    "from scdataloader import Dataset\n",
    "from scdataloader import DataModule\n",
    "from scprint.dataloader import embed\n",
    "from scdataloader.utils import load_genes\n",
    "from scprint.dataloader import Collator\n",
    "\n",
    "import torch \n",
    "torch.set_float32_matmul_precision('medium')\n",
    "\n",
    "lb.settings.organism = \"human\"\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading gene names from biomart\n",
      "['ensembl_gene_id', 'hgnc_symbol', 'gene_biotype', 'entrezgene_id', 'start_position', 'chromosome_name']\n",
      "\n",
      "['ensembl_gene_id', 'hgnc_symbol', 'gene_biotype', 'entrezgene_id', 'start_position', 'chromosome_name']\n",
      "reduced the size to 0.6722574020195106\n"
     ]
    }
   ],
   "source": [
    "## Gene embeddings\n",
    "# embeddings = embed(genedf=genedf,\n",
    "#     organism=\"homo_sapiens\",\n",
    "#     cache=True,\n",
    "#     fasta_path=\"/tmp/data/fasta/\",\n",
    "#     embedding_size=1024,)\n",
    "# embeddings.to_parquet('../data/temp/embeddings.parquet')\n",
    "embeddings = pd.read_parquet('../data/temp/embeddings.parquet')\n",
    "embeddings.columns = ['emb_'+str(i) for i in embeddings.columns]\n",
    "# and annotations\n",
    "biomart = getBiomartTable(attributes=['start_position', 'chromosome_name']).set_index('ensembl_gene_id')\n",
    "biomart = biomart.loc[~biomart.index.duplicated(keep='first')]\n",
    "biomart = biomart.sort_values(by=['chromosome_name', 'start_position'])\n",
    "# and location\n",
    "c = []\n",
    "i = 0\n",
    "prev_position = -100000\n",
    "prev_chromosome = None\n",
    "for _, r in biomart.iterrows():\n",
    "    if r['chromosome_name'] != prev_chromosome or r['start_position'] - prev_position > 10_000:\n",
    "        i += 1\n",
    "    c.append(i)\n",
    "    prev_position = r['start_position']\n",
    "    prev_chromosome = r['chromosome_name']\n",
    "print(f'reduced the size to {len(set(c))/len(biomart)}')\n",
    "biomart['pos'] = c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[autoreload of scprint.model.model failed: Traceback (most recent call last):\n",
      "  File \"/home/ml4ig1/miniconda3/envs/scprint/lib/python3.10/site-packages/IPython/extensions/autoreload.py\", line 276, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/home/ml4ig1/miniconda3/envs/scprint/lib/python3.10/site-packages/IPython/extensions/autoreload.py\", line 475, in superreload\n",
      "    module = reload(module)\n",
      "  File \"/home/ml4ig1/miniconda3/envs/scprint/lib/python3.10/importlib/__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 619, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 879, in exec_module\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 1017, in get_code\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 947, in source_to_code\n",
      "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
      "  File \"/home/ml4ig1/Documents code/scPRINT/scprint/model/model.py\", line 593\n",
      "    drop = cl == -1  # unknown label\n",
      "IndentationError: expected an indented block after 'if' statement on line 591\n",
      "]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "91"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# OR directly load the dataset\n",
    "name=\"preprocessed dataset\"\n",
    "dataset = ln.Collection.filter(name=name).first()\n",
    "dataset.artifacts.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: drop tissue & dev stage until part or is taken in account\n",
    "\n",
    "hierarchical_labels = [\n",
    "    \"cell_type_ontology_term_id\",\n",
    "    #\"tissue_ontology_term_id\",\n",
    "    \"disease_ontology_term_id\",\n",
    "    #\"development_stage_ontology_term_id\",\n",
    "    \"assay_ontology_term_id\",\n",
    "    'self_reported_ethnicity_ontology_term_id',\n",
    "]\n",
    "\n",
    "labels_weighted_sampling = hierarchical_labels+[\n",
    "    'sex_ontology_term_id',\n",
    "    \"organism_ontology_term_id\",\n",
    "]\n",
    "\n",
    "all_labels = labels_weighted_sampling+[\n",
    "    #'dataset_id',\n",
    "    #'cell_culture',\n",
    "    \"heat_diff\",\n",
    "    \"total_counts\",\n",
    "    \"nnz\",\n",
    "    \"dpt_group\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "won't do any check but we recommend to have your dataset coming from local storage\n",
      "\n",
      "82.41758241758242% are aligned\n",
      "total dataset size is 106.584138411 Gb\n",
      "---\n",
      "dataset contains:\n",
      "     5567614 cells\n",
      "     70116 genes\n",
      "     10 labels\n",
      "     1 organisms\n",
      "dataset contains 232 classes to predict\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mdataset = Dataset(dataset, organisms=[\"NCBITaxon:9606\"], obs=all_labels, clss_to_pred=labels_weighted_sampling, hierarchical_clss=hierarchical_labels, )\n",
    "print(mdataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[autoreload of scprint.model.model failed: Traceback (most recent call last):\n",
      "  File \"/home/ml4ig1/miniconda3/envs/scprint/lib/python3.10/site-packages/IPython/extensions/autoreload.py\", line 276, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/home/ml4ig1/miniconda3/envs/scprint/lib/python3.10/site-packages/IPython/extensions/autoreload.py\", line 475, in superreload\n",
      "    module = reload(module)\n",
      "  File \"/home/ml4ig1/miniconda3/envs/scprint/lib/python3.10/importlib/__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 619, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 879, in exec_module\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 1017, in get_code\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 947, in source_to_code\n",
      "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
      "  File \"/home/ml4ig1/Documents code/scPRINT/scprint/model/model.py\", line 593\n",
      "    drop = cl == -1  # unknown label\n",
      "IndentationError: expected an indented block after 'if' statement on line 591\n",
      "]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# we might want not to order the genes by expression (or do it?)\n",
    "# we might want to not introduce zeros and "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = Collator(organisms=[\"NCBITaxon:9606\",], labels=all_labels, genelist=embeddings.index.tolist(), max_len=2000, add_zero_genes=200, org_to_id={'NCBITaxon:9606': mdataset.encoder['organism_ontology_term_id']['NCBITaxon:9606']})#mdataset.encoder['organism_ontology_term_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "datamodule = DataModule(mdataset, label_to_weight=labels_weighted_sampling, collate_fn=col, batch_size=16, num_workers=4)\n",
    "datamodule.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in datamodule.train_dataloader():\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = {k: len(v) for k, v in mdataset.class_topred.items()}\n",
    "\n",
    "cls_hierarchies = {}\n",
    "for k, dic in mdataset.class_groupings.items():\n",
    "    rdic = {}\n",
    "    for sk, v in dic.items():\n",
    "        rdic[mdataset.encoder[k][sk]] = [mdataset.encoder[k][i] for i in list(v)]\n",
    "    cls_hierarchies[k] = rdic\n",
    "\n",
    "df = embeddings.join(biomart,how=\"inner\")\n",
    "\n",
    "genedf = load_genes(['NCBITaxon:9606'])\n",
    "df = df.loc[genedf[genedf.index.isin(df.index)].index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cell_type_ontology_term_id': 190,\n",
       " 'disease_ontology_term_id': 18,\n",
       " 'assay_ontology_term_id': 11,\n",
       " 'self_reported_ethnicity_ontology_term_id': 8,\n",
       " 'sex_ontology_term_id': 3,\n",
       " 'organism_ontology_term_id': 2}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(cls_hierarchies['assay_ontology_term_id'].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "scPrint.__init__() got an unexpected keyword argument 'do_adv_cls'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mscPrint\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgenes\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtolist\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43md_model\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnhead\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43md_hid\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnlayers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlayers_cls\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcls_hierarchy\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcls_hierarchies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdropout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtransformer\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfast\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_precpt_gene_emb\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgene_pos_enc\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpos\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtolist\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmvc_decoder\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minner product\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdo_adv_cls\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: scPrint.__init__() got an unexpected keyword argument 'do_adv_cls'"
     ]
    }
   ],
   "source": [
    "model = scPrint(\n",
    "    genes = df.index.tolist(),\n",
    "    d_model = 64,\n",
    "    nhead = 2,\n",
    "    d_hid = 64,\n",
    "    nlayers = 2,\n",
    "    layers_cls = [],\n",
    "    labels = labels,\n",
    "    cls_hierarchy = cls_hierarchies,\n",
    "    dropout= 0.2,\n",
    "    transformer = \"fast\",\n",
    "    use_precpt_gene_emb = df.values[:, :64].astype(float),\n",
    "    gene_pos_enc = df['pos'].tolist(),\n",
    "    mvc_decoder = \"inner product\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoding\n",
      "\n",
      "torch.Size([14, 7, 64])\n",
      "> /home/ml4ig1/Documents code/scPRINT/scprint/model/model.py(589)_compute_loss()\n",
      "    587 \n",
      "    588             pdb.set_trace()\n",
      "--> 589             for labelname, cl in zip(self.labels, clss.T):\n",
      "    590                 drop = cl == -1  # unknown label\n",
      "    591                 cl = cl[~drop]\n",
      "\n",
      "> /home/ml4ig1/Documents code/scPRINT/scprint/model/model.py(590)_compute_loss()\n",
      "    588             pdb.set_trace()\n",
      "    589             for labelname, cl in zip(self.labels, clss.T):\n",
      "--> 590                 drop = cl == -1  # unknown label\n",
      "    591                 cl = cl[~drop]\n",
      "    592                 pred = output[\"cls_output_\" + labelname]\n",
      "\n",
      "> /home/ml4ig1/Documents code/scPRINT/scprint/model/model.py(591)_compute_loss()\n",
      "    589             for labelname, cl in zip(self.labels, clss.T):\n",
      "    590                 drop = cl == -1  # unknown label\n",
      "--> 591                 cl = cl[~drop]\n",
      "    592                 pred = output[\"cls_output_\" + labelname]\n",
      "    593                 pred = pred[~drop]\n",
      "\n",
      "> /home/ml4ig1/Documents code/scPRINT/scprint/model/model.py(592)_compute_loss()\n",
      "    590                 drop = cl == -1  # unknown label\n",
      "    591                 cl = cl[~drop]\n",
      "--> 592                 pred = output[\"cls_output_\" + labelname]\n",
      "    593                 pred = pred[~drop]\n",
      "    594 \n",
      "\n",
      "> /home/ml4ig1/Documents code/scPRINT/scprint/model/model.py(593)_compute_loss()\n",
      "    591                 cl = cl[~drop]\n",
      "    592                 pred = output[\"cls_output_\" + labelname]\n",
      "--> 593                 pred = pred[~drop]\n",
      "    594 \n",
      "    595                 if len(self.cls_hierarchy) > 0:\n",
      "\n",
      "> /home/ml4ig1/Documents code/scPRINT/scprint/model/model.py(595)_compute_loss()\n",
      "    593                 pred = pred[~drop]\n",
      "    594 \n",
      "--> 595                 if len(self.cls_hierarchy) > 0:\n",
      "    596                     if len(self.cls_hierarchy.get(labelname, [])) > 0:\n",
      "    597                         truth = torch.zeros_like(pred)\n",
      "\n",
      "> /home/ml4ig1/Documents code/scPRINT/scprint/model/model.py(596)_compute_loss()\n",
      "    594 \n",
      "    595                 if len(self.cls_hierarchy) > 0:\n",
      "--> 596                     if len(self.cls_hierarchy.get(labelname, [])) > 0:\n",
      "    597                         truth = torch.zeros_like(pred)\n",
      "    598                         for i, c in enumerate(cl):\n",
      "\n",
      "> /home/ml4ig1/Documents code/scPRINT/scprint/model/model.py(597)_compute_loss()\n",
      "    595                 if len(self.cls_hierarchy) > 0:\n",
      "    596                     if len(self.cls_hierarchy.get(labelname, [])) > 0:\n",
      "--> 597                         truth = torch.zeros_like(pred)\n",
      "    598                         for i, c in enumerate(cl):\n",
      "    599                             if c in self.cls_hierarchy[labelname].keys():\n",
      "\n",
      "> /home/ml4ig1/Documents code/scPRINT/scprint/model/model.py(598)_compute_loss()\n",
      "    596                     if len(self.cls_hierarchy.get(labelname, [])) > 0:\n",
      "    597                         truth = torch.zeros_like(pred)\n",
      "--> 598                         for i, c in enumerate(cl):\n",
      "    599                             if c in self.cls_hierarchy[labelname].keys():\n",
      "    600                                 # we have to compute the loss by comparing the known\n",
      "\n",
      "> /home/ml4ig1/Documents code/scPRINT/scprint/model/model.py(599)_compute_loss()\n",
      "    597                         truth = torch.zeros_like(pred)\n",
      "    598                         for i, c in enumerate(cl):\n",
      "--> 599                             if c in self.cls_hierarchy[labelname].keys():\n",
      "    600                                 # we have to compute the loss by comparing the known\n",
      "    601                                 # class to the children probabilities\n",
      "\n",
      "> /home/ml4ig1/Documents code/scPRINT/scprint/model/model.py(606)_compute_loss()\n",
      "    604                                 truth[i, children] = 1 / len(children)\n",
      "    605                             else:\n",
      "--> 606                                 truth[i, c] = 1\n",
      "    607                         cl = truth\n",
      "    608                 loss_cls += nn.functional.cross_entropy(pred, target=cl)\n",
      "\n",
      "> /home/ml4ig1/Documents code/scPRINT/scprint/model/model.py(607)_compute_loss()\n",
      "    605                             else:\n",
      "    606                                 truth[i, c] = 1\n",
      "--> 607                         cl = truth\n",
      "    608                 loss_cls += nn.functional.cross_entropy(pred, target=cl)\n",
      "    609                 # TASK 2bis. adversarial label prediction\n",
      "\n",
      "tensor(14, dtype=torch.int32)\n",
      "dict_keys([5, 7, 9, 16, 24, 27, 28, 31, 32, 34, 37, 38, 41, 45, 51, 52, 50, 53, 55, 57, 61, 69, 70, 72, 73, 74, 75, 77, 78, 79, 82, 81, 80, 85, 84, 90, 93, 94, 97, 105, 102, 104, 106, 108, 117, 118, 120, 125, 124, 129, 130, 131, 136, 138, 140, 142, 150, 153, 154, 156, 157, 165, 168, 172, 174, 176, 178, 182, 184, 185, 186, 188, 187, 190, 194, 198, 200, 205, 204, 207, 214, 215, 218, 217, 221, 222, 223, 224, 230, 235, 238, 241, 251, 254, 256, 264, 265, 267, 269, 272, 274, 276, 277, 283, 288, 295])\n"
     ]
    }
   ],
   "source": [
    "model.training_step(i, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scPrint(\n",
       "  (gene_encoder): GeneEncoder(\n",
       "    (embedding): Embedding(33890, 64)\n",
       "    (enc_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (expr_encoder): ContinuousValueEncoder(\n",
       "    (linear1): Linear(in_features=1, out_features=64, bias=True)\n",
       "    (activation): ReLU()\n",
       "    (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.2, inplace=False)\n",
       "  )\n",
       "  (pos_encoder): PositionalEncoding(\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (label_encoder): BatchLabelEncoder(\n",
       "    (embedding): Embedding(9, 64)\n",
       "    (enc_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (time_encoder): ContinuousValueEncoder(\n",
       "    (linear1): Linear(in_features=1, out_features=64, bias=True)\n",
       "    (activation): ReLU()\n",
       "    (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.2, inplace=False)\n",
       "  )\n",
       "  (depth_encoder): ContinuousValueEncoder(\n",
       "    (linear1): Linear(in_features=1, out_features=64, bias=True)\n",
       "    (activation): ReLU()\n",
       "    (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.2, inplace=False)\n",
       "  )\n",
       "  (transformer): TransformerEncoder(\n",
       "    (layers): ModuleList(\n",
       "      (0-1): 2 x TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "        (linear2): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.2, inplace=False)\n",
       "        (dropout2): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (expr_decoder): ExprDecoder(\n",
       "    (fc): Sequential(\n",
       "      (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "    (pred_var_zero): Linear(in_features=64, out_features=3, bias=True)\n",
       "    (depth_fc): Sequential(\n",
       "      (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Linear(in_features=64, out_features=1, bias=True)\n",
       "      (3): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (cls_decoders): ModuleDict(\n",
       "    (cell_type_ontology_term_id): ClsDecoder(\n",
       "      (_decoder): ModuleList()\n",
       "      (out_layer): Linear(in_features=64, out_features=0, bias=True)\n",
       "    )\n",
       "    (disease_ontology_term_id): ClsDecoder(\n",
       "      (_decoder): ModuleList()\n",
       "      (out_layer): Linear(in_features=64, out_features=0, bias=True)\n",
       "    )\n",
       "    (assay_ontology_term_id): ClsDecoder(\n",
       "      (_decoder): ModuleList()\n",
       "      (out_layer): Linear(in_features=64, out_features=0, bias=True)\n",
       "    )\n",
       "    (self_reported_ethnicity_ontology_term_id): ClsDecoder(\n",
       "      (_decoder): ModuleList()\n",
       "      (out_layer): Linear(in_features=64, out_features=9, bias=True)\n",
       "    )\n",
       "    (sex_ontology_term_id): ClsDecoder(\n",
       "      (_decoder): ModuleList()\n",
       "      (out_layer): Linear(in_features=64, out_features=2, bias=True)\n",
       "    )\n",
       "    (organism_ontology_term_id): ClsDecoder(\n",
       "      (_decoder): ModuleList()\n",
       "      (out_layer): Linear(in_features=64, out_features=0, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (mvc_decoder): MVCDecoder(\n",
       "    (gene2query): Linear(in_features=64, out_features=64, bias=True)\n",
       "    (query_activation): Sigmoid()\n",
       "    (pred_var_zero): Linear(in_features=64, out_features=192, bias=False)\n",
       "  )\n",
       "  (sim): Similarity(\n",
       "    (cos): CosineSimilarity()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: GPU available: True (cuda), used: True\n",
      "2024-01-19 10:24:00,318:INFO - GPU available: True (cuda), used: True\n",
      "INFO: TPU available: False, using: 0 TPU cores\n",
      "2024-01-19 10:24:00,321:INFO - TPU available: False, using: 0 TPU cores\n",
      "INFO: IPU available: False, using: 0 IPUs\n",
      "2024-01-19 10:24:00,324:INFO - IPU available: False, using: 0 IPUs\n",
      "INFO: HPU available: False, using: 0 HPUs\n",
      "2024-01-19 10:24:00,328:INFO - HPU available: False, using: 0 HPUs\n",
      "INFO: Running in `fast_dev_run` mode: will run the requested loop using 1 batch(es). Logging and checkpointing is suppressed.\n",
      "2024-01-19 10:24:00,373:INFO - Running in `fast_dev_run` mode: will run the requested loop using 1 batch(es). Logging and checkpointing is suppressed.\n",
      "2024-01-19 10:24:00,318:INFO - GPU available: True (cuda), used: True\n",
      "INFO: TPU available: False, using: 0 TPU cores\n",
      "2024-01-19 10:24:00,321:INFO - TPU available: False, using: 0 TPU cores\n",
      "INFO: IPU available: False, using: 0 IPUs\n",
      "2024-01-19 10:24:00,324:INFO - IPU available: False, using: 0 IPUs\n",
      "INFO: HPU available: False, using: 0 HPUs\n",
      "2024-01-19 10:24:00,328:INFO - HPU available: False, using: 0 HPUs\n",
      "INFO: Running in `fast_dev_run` mode: will run the requested loop using 1 batch(es). Logging and checkpointing is suppressed.\n",
      "2024-01-19 10:24:00,373:INFO - Running in `fast_dev_run` mode: will run the requested loop using 1 batch(es). Logging and checkpointing is suppressed.\n"
     ]
    }
   ],
   "source": [
    "# sets seeds for numpy, torch and python.random.\n",
    "trainer = Trainer(deterministic=True, fast_dev_run=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = datamodule.train_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(model, trainloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: test unseen genes (do we see much being kept after filtering and stuff)\n",
    "# TODO: debug the timepoint problem\n",
    "# TODO: find the neighboors and next time point cells\n",
    "# TODO: create a version with next time point and neighboors task\n",
    "# TODO: add KO & drug datasets\n",
    "# TODO: create a version with KO and drug effect prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scprint",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
