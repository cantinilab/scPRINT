{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ’¡ found cached instance metadata: /home/ml4ig1/.lamin/instance--jkobject--scprint.env\n",
      "ðŸ’¡ loaded instance: jkobject/scprint\n",
      "\u001b[0mðŸ’¡ loaded instance: jkobject/scprint\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! lamin load scprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from lightning.pytorch import Trainer, seed_everything\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint, StochasticWeightAveraging, EarlyStopping, LearningRateMonitor, LearningRateFinder\n",
    "\n",
    "seed_everything(42, workers=True)\n",
    "\n",
    "from scprint import scPrint\n",
    "from scprint.trainer import TrainingMode\n",
    "from scdataloader import DataModule\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: drop tissue & dev stage until part or is taken in account\n",
    "\n",
    "hierarchical_labels = [\n",
    "    \"cell_type_ontology_term_id\", #1\n",
    "    # \"tissue_ontology_term_id\",\n",
    "    \"disease_ontology_term_id\", # 2\n",
    "#    \"development_stage_ontology_term_id\",\n",
    "    \"assay_ontology_term_id\", #3\n",
    "    'self_reported_ethnicity_ontology_term_id', #4\n",
    "]\n",
    "labels_to_pred = hierarchical_labels+[\n",
    "    'sex_ontology_term_id', #5\n",
    "    \"organism_ontology_term_id\", #6\n",
    "]\n",
    "all_labels = labels_to_pred+[\n",
    "    #'dataset_id',\n",
    "    'cell_culture',\n",
    "    \"heat_diff\",\n",
    "    \"total_counts\",\n",
    "    \"nnz\",\n",
    "    \"dpt_group\",\n",
    "]\n",
    "\n",
    "gene_emb = '../data/temp/embeddings.parquet'\n",
    "d_model=128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we might want not to order the genes by expression (or do it?)\n",
    "# we might want to not introduce zeros and "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "won't do any check but we recommend to have your dataset coming from local storage\n",
      "\n",
      "0.0% are aligned\n",
      "total dataset size is 104.788359405 Gb\n",
      "---\n",
      "dataset contains:\n",
      "     5527449 cells\n",
      "     70116 genes\n",
      "     11 labels\n",
      "     1 organisms\n",
      "dataset contains 230 classes to predict\n",
      "\n",
      "seeing a string: loading gene positions as biomart parquet file\n",
      "these files will be considered test datasets:\n",
      "    /home/ml4ig1/scprint/.lamindb/BljRloq1xjcxRNDpejzI.h5ad\n",
      "perc test:  0.002277723412735242\n"
     ]
    }
   ],
   "source": [
    "datamodule = DataModule(\n",
    "    collection_name=\"preprocessed dataset\",\n",
    "    gene_embeddings=gene_emb,\n",
    "    all_labels=all_labels,\n",
    "    hierarchical_labels=hierarchical_labels,\n",
    "    organisms=[\"NCBITaxon:9606\"],\n",
    "    how=\"most expr\",\n",
    "    max_len=1000,\n",
    "    add_zero_genes=100,\n",
    "    label_to_weight=labels_to_pred,\n",
    "    label_to_pred=labels_to_pred,\n",
    "    batch_size=64,\n",
    "    num_workers=16,\n",
    "    train_oversampling=1.7,\n",
    "    validation_split=0.2,\n",
    "    do_gene_pos='../data/main/biomart.parquet',\n",
    "    test_split=0.1)\n",
    "testfiles = datamodule.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = pd.read_parquet(gene_emb).loc[model.genes]\n",
    "sembeddings = torch.nn.AdaptiveAvgPool1d(d_model)(\n",
    "    torch.tensor(embeddings.values)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 3.7021e-03,  1.9993e-02, -3.4491e-03,  1.1713e-02,  7.6410e-03,\n",
       "         3.8214e-02, -2.5759e-03,  1.4394e-02,  1.6626e-02, -2.5141e-02,\n",
       "        -3.0845e-02, -1.7926e-02,  2.9747e-03,  1.4398e-02, -3.4161e-02,\n",
       "         1.1524e-02,  8.0428e-03,  1.2203e-02, -4.4529e-03,  1.6340e-02,\n",
       "        -2.9258e-02,  2.1006e-02, -4.2241e-02, -4.2910e-02,  4.3020e-02,\n",
       "        -3.0580e-02, -3.9011e-02,  2.0069e-02,  1.7439e-02, -1.7942e-02,\n",
       "         1.1015e-02, -1.2625e-02, -8.5026e-03, -7.2202e-03,  4.9086e-03,\n",
       "        -1.3565e-03,  2.5166e-02,  3.2748e-02, -1.4290e-03,  8.9639e-03,\n",
       "         1.7316e-02,  2.2168e-02,  1.0759e-02, -2.9722e-02,  1.0154e-02,\n",
       "         8.2518e-03,  3.5274e-02, -5.7122e-03, -2.0104e-02, -2.9521e-02,\n",
       "         1.0372e-02,  5.1883e-03, -1.3417e-02,  1.7161e-02,  5.3995e-03,\n",
       "        -1.1004e-02,  1.7635e-02,  5.9054e-02, -1.6850e-02,  1.8962e-02,\n",
       "        -8.4115e-03,  1.8526e-02,  2.9677e-02, -1.3948e-02,  8.8496e-03,\n",
       "        -1.7609e-02,  8.1042e-03, -1.1275e-03,  3.8094e-02, -6.6677e-03,\n",
       "         2.5674e-02,  3.2120e-02,  1.2649e-02,  1.6701e-02,  3.6365e-03,\n",
       "         4.1337e-02, -1.6444e-02,  4.5049e-03, -1.0924e-02,  2.7407e-02,\n",
       "        -1.4958e-02, -1.3522e-03,  4.0260e-03,  5.8480e-03, -2.0982e-02,\n",
       "         5.8962e-03,  1.2044e-03, -3.2786e-02, -9.4273e-04,  1.8588e-02,\n",
       "        -5.3187e-03,  5.2998e-03, -1.7994e-02, -1.5629e-02,  4.7982e-02,\n",
       "         4.4628e-02, -2.9259e-05,  1.8827e-02, -6.9406e-03, -4.8162e-03,\n",
       "         4.7291e-03, -5.0094e-03,  7.9910e-03,  3.3655e-02,  2.6448e-02,\n",
       "        -3.6027e-03,  1.8304e-02, -3.9152e-03,  1.0703e-02, -6.3188e-03,\n",
       "        -5.4296e-03,  2.5167e-02, -3.5750e-02,  2.9846e-03,  5.1283e-03,\n",
       "         1.0693e-02, -4.3294e-01,  1.0512e-02,  1.3109e-02,  5.5184e-02,\n",
       "        -6.9749e-03, -1.3813e-02, -7.1409e-03,  3.7017e-02,  1.3736e-02,\n",
       "         2.0224e-02,  3.4460e-02, -3.1282e-02], dtype=torch.float64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sembeddings[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "adding\n",
      "tensor([[ 0.0037,  0.0200, -0.0034,  ...,  0.0202,  0.0345, -0.0313],\n",
      "        [-0.0007,  0.0393, -0.0069,  ...,  0.0281,  0.0400, -0.0190],\n",
      "        [-0.0175,  0.0621, -0.0132,  ...,  0.0161,  0.0288, -0.0111],\n",
      "        ...,\n",
      "        [-0.0217,  0.0621, -0.0146,  ...,  0.0505,  0.0368, -0.0321],\n",
      "        [ 0.0173,  0.0463, -0.0083,  ...,  0.0037,  0.0115, -0.0153],\n",
      "        [ 0.0525,  0.0525, -0.0402,  ...,  0.0067,  0.0007, -0.0331]])\n",
      "scPrint(\n",
      "  (gene_encoder): GeneEncoder(\n",
      "    (embedding): Embedding(33890, 128)\n",
      "    (enc_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (expr_encoder): ContinuousValueEncoder(\n",
      "    (linear1): Linear(in_features=1, out_features=128, bias=True)\n",
      "    (activation): ReLU()\n",
      "    (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (pos_encoder): PositionalEncoding(\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (label_encoder): CategoryValueEncoder(\n",
      "    (embedding): Embedding(8, 128)\n",
      "    (enc_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (time_encoder): ContinuousValueEncoder(\n",
      "    (linear1): Linear(in_features=1, out_features=128, bias=True)\n",
      "    (activation): ReLU()\n",
      "    (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (transformer): FlashTransformerEncoder(\n",
      "    (blocks): ModuleList(\n",
      "      (0-3): 4 x Block(\n",
      "        (mixer): MHA(\n",
      "          (Wqkv): Linear(in_features=128, out_features=384, bias=True)\n",
      "          (inner_attn): FlashSelfAttention()\n",
      "          (inner_cross_attn): FlashCrossAttention(\n",
      "            (drop): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (out_proj): Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (drop_path1): StochasticDepth(p=0.0, mode=row)\n",
      "        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
      "          (activation): GELU(approximate='none')\n",
      "          (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
      "        )\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "        (drop_path2): StochasticDepth(p=0.0, mode=row)\n",
      "        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "    (drop_path): StochasticDepth(p=0.0, mode=row)\n",
      "    (norm): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
      "  )\n",
      "  (expr_decoder): ExprDecoder(\n",
      "    (fc): Sequential(\n",
      "      (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "      (1): LeakyReLU(negative_slope=0.01)\n",
      "      (2): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (finalfc): Sequential(\n",
      "      (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "      (1): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (depth_encoder): Sequential(\n",
      "      (0): ContinuousValueEncoder(\n",
      "        (linear1): Linear(in_features=1, out_features=128, bias=True)\n",
      "        (activation): ReLU()\n",
      "        (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (1): Linear(in_features=128, out_features=128, bias=True)\n",
      "      (2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "      (3): LeakyReLU(negative_slope=0.01)\n",
      "      (4): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (pred_var_zero): Linear(in_features=128, out_features=3, bias=True)\n",
      "    (depth_fc): Sequential(\n",
      "      (0): Linear(in_features=128, out_features=1, bias=True)\n",
      "      (1): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (cls_decoders): ModuleDict(\n",
      "    (cell_type_ontology_term_id): ClsDecoder(\n",
      "      (decoder): Sequential(\n",
      "        (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "        (2): ReLU()\n",
      "        (3): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (out_layer): Linear(in_features=128, out_features=190, bias=True)\n",
      "    )\n",
      "    (disease_ontology_term_id): ClsDecoder(\n",
      "      (decoder): Sequential(\n",
      "        (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "        (2): ReLU()\n",
      "        (3): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (out_layer): Linear(in_features=128, out_features=18, bias=True)\n",
      "    )\n",
      "    (assay_ontology_term_id): ClsDecoder(\n",
      "      (decoder): Sequential(\n",
      "        (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "        (2): ReLU()\n",
      "        (3): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (out_layer): Linear(in_features=128, out_features=11, bias=True)\n",
      "    )\n",
      "    (self_reported_ethnicity_ontology_term_id): ClsDecoder(\n",
      "      (decoder): Sequential(\n",
      "        (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "        (2): ReLU()\n",
      "        (3): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (out_layer): Linear(in_features=128, out_features=7, bias=True)\n",
      "    )\n",
      "    (sex_ontology_term_id): ClsDecoder(\n",
      "      (decoder): Sequential(\n",
      "        (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "        (2): ReLU()\n",
      "        (3): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (out_layer): Linear(in_features=128, out_features=2, bias=True)\n",
      "    )\n",
      "    (organism_ontology_term_id): ClsDecoder(\n",
      "      (decoder): Sequential(\n",
      "        (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "        (2): ReLU()\n",
      "        (3): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (out_layer): Linear(in_features=128, out_features=2, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (mvc_decoder): MVCDecoder(\n",
      "    (depth_encoder): Sequential(\n",
      "      (0): ContinuousValueEncoder(\n",
      "        (linear1): Linear(in_features=1, out_features=128, bias=True)\n",
      "        (activation): ReLU()\n",
      "        (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (1): Linear(in_features=128, out_features=128, bias=True)\n",
      "      (2): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (depth_fc): Sequential(\n",
      "      (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "      (1): LeakyReLU(negative_slope=0.01)\n",
      "      (2): Linear(in_features=128, out_features=1, bias=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (gene2query): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (query_activation): Sigmoid()\n",
      "    (pred_var_zero): Linear(in_features=128, out_features=384, bias=False)\n",
      "  )\n",
      ")\n",
      "\n",
      "adding\n",
      "tensor([[ 0.0037,  0.0200, -0.0034,  ...,  0.0202,  0.0345, -0.0313],\n",
      "        [-0.0007,  0.0393, -0.0069,  ...,  0.0281,  0.0400, -0.0190],\n",
      "        [-0.0175,  0.0621, -0.0132,  ...,  0.0161,  0.0288, -0.0111],\n",
      "        ...,\n",
      "        [-0.0217,  0.0621, -0.0146,  ...,  0.0505,  0.0368, -0.0321],\n",
      "        [ 0.0173,  0.0463, -0.0083,  ...,  0.0037,  0.0115, -0.0153],\n",
      "        [ 0.0525,  0.0525, -0.0402,  ...,  0.0067,  0.0007, -0.0331]])\n",
      "scPrint(\n",
      "  (gene_encoder): GeneEncoder(\n",
      "    (embedding): Embedding(33890, 128)\n",
      "    (enc_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (expr_encoder): ContinuousValueEncoder(\n",
      "    (linear1): Linear(in_features=1, out_features=128, bias=True)\n",
      "    (activation): ReLU()\n",
      "    (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (pos_encoder): PositionalEncoding(\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (label_encoder): CategoryValueEncoder(\n",
      "    (embedding): Embedding(8, 128)\n",
      "    (enc_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (time_encoder): ContinuousValueEncoder(\n",
      "    (linear1): Linear(in_features=1, out_features=128, bias=True)\n",
      "    (activation): ReLU()\n",
      "    (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (transformer): FlashTransformerEncoder(\n",
      "    (blocks): ModuleList(\n",
      "      (0-3): 4 x Block(\n",
      "        (mixer): MHA(\n",
      "          (Wqkv): Linear(in_features=128, out_features=384, bias=True)\n",
      "          (inner_attn): FlashSelfAttention()\n",
      "          (inner_cross_attn): FlashCrossAttention(\n",
      "            (drop): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (out_proj): Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (drop_path1): StochasticDepth(p=0.0, mode=row)\n",
      "        (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
      "          (activation): GELU(approximate='none')\n",
      "          (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
      "        )\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "        (drop_path2): StochasticDepth(p=0.0, mode=row)\n",
      "        (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "    (drop_path): StochasticDepth(p=0.0, mode=row)\n",
      "    (norm): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
      "  )\n",
      "  (expr_decoder): ExprDecoder(\n",
      "    (fc): Sequential(\n",
      "      (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "      (1): LeakyReLU(negative_slope=0.01)\n",
      "      (2): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (finalfc): Sequential(\n",
      "      (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "      (1): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (depth_encoder): Sequential(\n",
      "      (0): ContinuousValueEncoder(\n",
      "        (linear1): Linear(in_features=1, out_features=128, bias=True)\n",
      "        (activation): ReLU()\n",
      "        (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (1): Linear(in_features=128, out_features=128, bias=True)\n",
      "      (2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "      (3): LeakyReLU(negative_slope=0.01)\n",
      "      (4): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (pred_var_zero): Linear(in_features=128, out_features=3, bias=True)\n",
      "    (depth_fc): Sequential(\n",
      "      (0): Linear(in_features=128, out_features=1, bias=True)\n",
      "      (1): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (cls_decoders): ModuleDict(\n",
      "    (cell_type_ontology_term_id): ClsDecoder(\n",
      "      (decoder): Sequential(\n",
      "        (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "        (2): ReLU()\n",
      "        (3): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (out_layer): Linear(in_features=128, out_features=190, bias=True)\n",
      "    )\n",
      "    (disease_ontology_term_id): ClsDecoder(\n",
      "      (decoder): Sequential(\n",
      "        (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "        (2): ReLU()\n",
      "        (3): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (out_layer): Linear(in_features=128, out_features=18, bias=True)\n",
      "    )\n",
      "    (assay_ontology_term_id): ClsDecoder(\n",
      "      (decoder): Sequential(\n",
      "        (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "        (2): ReLU()\n",
      "        (3): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (out_layer): Linear(in_features=128, out_features=11, bias=True)\n",
      "    )\n",
      "    (self_reported_ethnicity_ontology_term_id): ClsDecoder(\n",
      "      (decoder): Sequential(\n",
      "        (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "        (2): ReLU()\n",
      "        (3): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (out_layer): Linear(in_features=128, out_features=7, bias=True)\n",
      "    )\n",
      "    (sex_ontology_term_id): ClsDecoder(\n",
      "      (decoder): Sequential(\n",
      "        (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "        (2): ReLU()\n",
      "        (3): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (out_layer): Linear(in_features=128, out_features=2, bias=True)\n",
      "    )\n",
      "    (organism_ontology_term_id): ClsDecoder(\n",
      "      (decoder): Sequential(\n",
      "        (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "        (2): ReLU()\n",
      "        (3): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (out_layer): Linear(in_features=128, out_features=2, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (mvc_decoder): MVCDecoder(\n",
      "    (depth_encoder): Sequential(\n",
      "      (0): ContinuousValueEncoder(\n",
      "        (linear1): Linear(in_features=1, out_features=128, bias=True)\n",
      "        (activation): ReLU()\n",
      "        (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (1): Linear(in_features=128, out_features=128, bias=True)\n",
      "      (2): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (depth_fc): Sequential(\n",
      "      (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "      (1): LeakyReLU(negative_slope=0.01)\n",
      "      (2): Linear(in_features=128, out_features=1, bias=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (gene2query): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (query_activation): Sigmoid()\n",
      "    (pred_var_zero): Linear(in_features=128, out_features=384, bias=False)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = scPrint(\n",
    "    genes = datamodule.genes,\n",
    "    d_model = d_model,\n",
    "    nhead = 4,\n",
    "    d_hid = d_model,\n",
    "    nlayers = 4,\n",
    "    layers_cls = [d_model],\n",
    "    labels = datamodule.labels,\n",
    "    cls_hierarchy = datamodule.cls_hierarchy,\n",
    "    dropout= 0.1,\n",
    "    transformer = \"flash\",\n",
    "    precpt_gene_emb = gene_emb,\n",
    "    gene_pos_enc = datamodule.gene_pos,\n",
    "    mvc_decoder = \"inner product\",\n",
    "    label_decoders = datamodule.decoders,\n",
    "    fused_dropout_add_ln = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function to transform an scGPT checkpoint to an scPrint's\n",
    "# ckpt = torch.load(\"../../scGPT/save/model_e6.pt\")\n",
    "# scPrint.load_from_checkpoint(\"../../scGPT/save/model_e6.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-19 16:41:43,615:ERROR - Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "wandb: Currently logged in as: jkobject (ml4ig). Use `wandb login --relogin` to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>../data/tensorboard/wandb/run-20240219_164145-iuealg88</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ml4ig/scprint_test/runs/iuealg88' target=\"_blank\">lambent-lamp-64</a></strong> to <a href='https://wandb.ai/ml4ig/scprint_test' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ml4ig/scprint_test' target=\"_blank\">https://wandb.ai/ml4ig/scprint_test</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ml4ig/scprint_test/runs/iuealg88' target=\"_blank\">https://wandb.ai/ml4ig/scprint_test/runs/iuealg88</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: logging graph, to disable use `wandb.watch(log_graph=False)`\n"
     ]
    }
   ],
   "source": [
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "from lightning.pytorch.loggers import WandbLogger\n",
    "\n",
    "wandb_logger = WandbLogger(project=\"scprint_test\", save_dir=\"../data/tensorboard\")\n",
    "wandb_logger.watch(model, log='all', log_freq=50, log_graph=True)\n",
    "\n",
    "#tlogger = TensorBoardLogger(save_dir=\"../data/tensorboard\")\n",
    "#tlogger.log_graph(model, i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from lightning.pytorch.profilers import PyTorchProfiler\n",
    "#pytorch_prof = PyTorchProfiler(\"../data/tensorboard\", emit_nvtx=False, group_by_input_shape=True, record_shapes=True, profile_memory=True, with_stack=True, on_trace_ready=torch.profiler.tensorboard_trace_handler(\"../data/tensorboard/\"),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "chckp = ModelCheckpoint(monitor=\"val_loss\", save_top_k=-1)\n",
    "trainingmode = TrainingMode(do_denoise=True, noise=[0.3], do_cce=True, cce_sim=0.5, do_ecs=True, ecs_threshold = 0.3, ecs_scale = 1.0, do_mvc=False, do_adv_cls=False, do_next_tp=False, class_scale = 5000.0, mask_ratio=[0.15, 0.3])\n",
    "es = EarlyStopping(patience=10, monitor='val_loss')\n",
    "swa = StochasticWeightAveraging(swa_lrs= 0.01)\n",
    "lrm = LearningRateMonitor(logging_interval=\"step\")\n",
    "lrf = LearningRateFinder(mode=\"exponential\",)\n",
    "# TODO: to check that the class hierarchy are really ordered from 1-2-3-4... as well (oredered dict)\n",
    "trainer = Trainer(precision=\"16-mixed\", gradient_clip_val=10, max_time={\"hours\": 3}, limit_train_batches=5000, limit_test_batches=0.03, limit_val_batches=1000, callbacks=[chckp, trainingmode, es, lrm], logger=wandb_logger, accumulate_grad_batches=2, reload_dataloaders_every_n_epochs=1) #detect_anomaly=True, fast_dev_run=20, overfit_batches=10, limit_train_batches=1, limit_val_batches=0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.001, 0.001)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.lr, model.hparams.lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "# sanity. should be overfiting.\n",
    "trainer = Trainer(precision=\"16-mixed\", limit_train_batches=500, limit_val_batches=0, check_val_every_n_epoch=1000, log_every_n_steps=1000) #logger=wandb_logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "these files will be considered test datasets:\n",
      "    /home/ml4ig1/scprint/.lamindb/BljRloq1xjcxRNDpejzI.h5ad\n",
      "perc test:  0.00226129182087695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name          | Type                    | Params\n",
      "----------------------------------------------------------\n",
      "0 | gene_encoder  | GeneEncoder             | 4.3 M \n",
      "1 | expr_encoder  | ContinuousValueEncoder  | 512   \n",
      "2 | pos_encoder   | PositionalEncoding      | 0     \n",
      "3 | label_encoder | CategoryValueEncoder    | 1.3 K \n",
      "4 | time_encoder  | ContinuousValueEncoder  | 512   \n",
      "5 | transformer   | FlashTransformerEncoder | 793 K \n",
      "6 | expr_decoder  | ExprDecoder             | 50.6 K\n",
      "7 | cls_decoders  | ModuleDict              | 130 K \n",
      "8 | mvc_decoder   | MVCDecoder              | 99.3 K\n",
      "----------------------------------------------------------\n",
      "1.1 M     Trainable params\n",
      "4.3 M     Non-trainable params\n",
      "5.4 M     Total params\n",
      "21.656    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc002a3e70fb449a965b2942a27d2410",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.fit(model, datamodule=datamodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir=\"../data/tensorboard\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wandb_logger.finalize(status=\"aborted\")\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: test unseen genes (do we see much being kept after filtering and stuff) (0.5 day)\n",
    "----\n",
    "# TODO: connect with maestro people to ask for longer compute time \n",
    "# TODO: do the same to jean zay (0.5 day)\n",
    "------\n",
    "# TODO: make a model benchmark package (continue from where I left off) (4 days)\n",
    "# TODO: make a task function & make a benchmark function (1 day) (*denoising, *classification, *embeddings, *perturbation prediction)\n",
    "------\n",
    "# TODO: debug the gene embedding creation\n",
    "# TODO: create embedding & make it work for the 4-5 species in the dataset (1 days) \n",
    "# TODO: debug the timepoint problem (2 days)\n",
    "# TODO: find the neighboors and next time point cells (1 days)\n",
    "# TODO: create a version with next time point and neighboors task (1 days)\n",
    "# TODO: make a trajectory prediction task (predict future cell type/s, expression) and benchmark (similarity to known future cell, similarity to known future expression) (1 days)\n",
    "------\n",
    "# TODO: run a large training on maestro (0.5 day)\n",
    "------\n",
    "# TODO: add KO & drug datasets\n",
    "# TODO: create a version with KO and drug effect prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scprint",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
