{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from scprint import scPrint\n",
    "from scprint.tasks import GNInfer\n",
    "\n",
    "from bengrn import BenGRN\n",
    "import scanpy as sc\n",
    "\n",
    "from bengrn.base import train_classifier\n",
    "\n",
    "from anndata.utils import make_index_unique\n",
    "from bengrn import compute_genie3\n",
    "from grnndata import utils as grnutils\n",
    "import numpy as np\n",
    "import joblib\n",
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "from scdataloader import Preprocessor\n",
    "%load_ext autoreload\n",
    "%autoreload 2 \n",
    "\n",
    "import torch\n",
    "torch.set_float32_matmul_precision('medium') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available, using GPU\n",
      "FYI: scPrint is not attached to a `Trainer`.\n"
     ]
    }
   ],
   "source": [
    "model_checkpoint_file = hf_hub_download(\n",
    "    repo_id=\"jkobject/scPRINT\", filename=\"v2-medium.ckpt\"\n",
    ")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available, using GPU\", flush=True)\n",
    "    precision = \"16\"\n",
    "    transformer = \"flash\"\n",
    "else:\n",
    "    print(\"CUDA is not available, using CPU\", flush=True)\n",
    "    precision = \"32\"\n",
    "    transformer = \"normal\"\n",
    "\n",
    "m = torch.load(model_checkpoint_file, map_location=torch.device(\"cpu\"))\n",
    "if \"label_counts\" in m[\"hyper_parameters\"]:\n",
    "    model = scPrint.load_from_checkpoint(\n",
    "        model_checkpoint_file,\n",
    "        transformer=transformer,  # Don't use this for GPUs with flashattention\n",
    "        precpt_gene_emb=None,\n",
    "        classes=m[\"hyper_parameters\"][\"label_counts\"],\n",
    "    )\n",
    "else:\n",
    "    model = scPrint.load_from_checkpoint(\n",
    "        model_checkpoint_file,\n",
    "        transformer=transformer,  # Don't use this for GPUs with flashattention\n",
    "        precpt_gene_emb=None,\n",
    "    )\n",
    "del m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "raw counts - pas normalisé, ni log transformed\n",
    "\n",
    "15 cell types sous \"celltype\",  avec 100 cells ou moins par cell type\n",
    "\n",
    "14  batches sous \"rep\". Je me disais  pas que ca valait pas le coup de traiter chaque batch séparément car ça en fait beaucoup pour la taille du dataset, mais point très ouvert si tu pense que ça vaut le coup \n",
    " \n",
    "network en sortie:\n",
    "Si possible au moins 15k genes conservés, je suis plus intéressé par la qualité et la densité que la différence entre les cell types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs['organism_ontology_term_id'] = 'NCBITaxon:9606'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping layers:  KeysView(Layers with keys: )\n",
      "checking raw counts\n",
      "removed 0 non primary cells, 1296 renamining\n",
      "filtered out 0 cells, 1296 renamining\n",
      "No ENS genes found, assuming gene symbols...\n",
      "> \u001b[0;32m/home/ml4ig1/Documents code/scDataLoader/scdataloader/preprocess.py\u001b[0m(276)\u001b[0;36m__call__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    274 \u001b[0;31m        \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    275 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 276 \u001b[0;31m        \u001b[0madata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    277 \u001b[0;31m        \u001b[0;31m#        var = var.sort_values(by=\"ensembl_gene_id\").set_index(\"ensembl_gene_id\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    278 \u001b[0;31m        \u001b[0;31m# Update adata with combined genes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "Removed 0 genes.\n",
      "startin QC\n",
      "Seeing 235 outliers (18.13% of total dataset):\n",
      "done\n",
      "AnnData object with n_obs × n_vars = 1296 × 70704\n",
      "    obs: 'orig.ident', 'nCount_RNA', 'nFeature_RNA', 'channel', 'nCount_HTO', 'nFeature_HTO', 'MULTI_ID', 'MULTI_classification', 'percent_mito', 'RNA_snn_res.1.5', 'seurat_clusters', 'cluster_manual', 'celltype', 'channel_hashtag', 'sample', 'rep', 'organism_ontology_term_id', 'nnz', 'n_counts', 'n_genes', 'n_genes_by_counts', 'log1p_n_genes_by_counts', 'total_counts', 'log1p_total_counts', 'pct_counts_in_top_20_genes', 'total_counts_mt', 'log1p_total_counts_mt', 'pct_counts_mt', 'total_counts_ribo', 'log1p_total_counts_ribo', 'pct_counts_ribo', 'total_counts_hb', 'log1p_total_counts_hb', 'pct_counts_hb', 'outlier', 'mt_outlier'\n",
      "    var: 'uid', 'symbol', 'ncbi_gene_ids', 'biotype', 'synonyms', 'description', 'organism_id', 'mt', 'ribo', 'hb', 'organism', 'ensembl_gene_id', 'n_cells_by_counts', 'mean_counts', 'log1p_mean_counts', 'pct_dropout_by_counts', 'total_counts', 'log1p_total_counts'\n",
      "    uns: 'unseen_genes'\n"
     ]
    }
   ],
   "source": [
    "preprocessor = Preprocessor(\n",
    "    min_valid_genes_id=min(0.9 * adata.n_vars, 10000),  # 90% of features up to 10,000\n",
    "    # Turn off cell filtering to return results for all cells\n",
    "    filter_cell_by_counts=300,\n",
    "    min_nnz_genes=300,\n",
    "    do_postp=False,\n",
    "    # Skip ontology checks\n",
    "    skip_validate=True,\n",
    "    is_symbol=True,\n",
    "\n",
    "\n",
    ")\n",
    "adata = preprocessor(adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = sc.read_h5ad('../data/temp/rna_pbs_immune_dictionary.h5ad')\n",
    "adata.var[\"isTF\"] = False\n",
    "adata.var.loc[adata.var.symbol.isin(grnutils.TF), \"isTF\"] = True\n",
    "adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {}\n",
    "clf_omni = None\n",
    "shapes = []\n",
    "for celltype in adata.obs['celltype'].unique():\n",
    "    grn_inferer = GNInfer(model, adata[adata.X.sum(1) > 500],\n",
    "                        how=\"random expr\",\n",
    "                        preprocess=\"softmax\",\n",
    "                        head_agg='mean',\n",
    "                        filtration=\"none\",\n",
    "                        forward_mode=\"none\",\n",
    "                        num_genes=3000,\n",
    "                        max_cells=5000,\n",
    "                        doplot=False,\n",
    "                        batch_size=32,\n",
    "                        cell_type_col=\"celltype\",\n",
    "                        )\n",
    "    grn = grn_inferer(layer=list(range(model.nlayers))[:], cell_type=celltype)\n",
    "    grn.var.index = make_index_unique(grn.var['symbol'].astype(str))\n",
    "    metrics[celltype+'_scprint_full'] = BenGRN(grn).scprint_benchmark()\n",
    "    del grn"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scprnt2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
