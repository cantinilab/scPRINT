{
      "cells": [
            {
                  "cell_type": "code",
                  "execution_count": 24,
                  "metadata": {},
                  "outputs": [
                        {
                              "name": "stdout",
                              "output_type": "stream",
                              "text": [
                                    "^C\n",
                                    "Traceback (most recent call last):\n",
                                    "  File \"/home/ml4ig1/miniconda3/envs/scprint/bin/lamin\", line 5, in <module>\n",
                                    "    from lamin_cli.__main__ import main\n",
                                    "  File \"/home/ml4ig1/miniconda3/envs/scprint/lib/python3.10/site-packages/lamin_cli/__main__.py\", line 11, in <module>\n",
                                    "    import rich_click as click\n",
                                    "  File \"/home/ml4ig1/miniconda3/envs/scprint/lib/python3.10/site-packages/rich_click/__init__.py\", line 73, in <module>\n",
                                    "    from . import rich_click as rich_click\n",
                                    "  File \"/home/ml4ig1/miniconda3/envs/scprint/lib/python3.10/site-packages/rich_click/rich_click.py\", line 6, in <module>\n",
                                    "    import rich.columns\n",
                                    "  File \"/home/ml4ig1/miniconda3/envs/scprint/lib/python3.10/site-packages/rich/columns.py\", line 7, in <module>\n",
                                    "    from .console import Console, ConsoleOptions, RenderableType, RenderResult\n",
                                    "  File \"/home/ml4ig1/miniconda3/envs/scprint/lib/python3.10/site-packages/rich/console.py\", line 57, in <module>\n",
                                    "    from .markup import render as render_markup\n",
                                    "  File \"<frozen importlib._bootstrap>\", line 1027, in _find_and_load\n",
                                    "  File \"<frozen importlib._bootstrap>\", line 1006, in _find_and_load_unlocked\n",
                                    "  File \"<frozen importlib._bootstrap>\", line 674, in _load_unlocked\n",
                                    "  File \"<frozen importlib._bootstrap>\", line 577, in module_from_spec\n",
                                    "  File \"<frozen importlib._bootstrap>\", line 541, in _init_module_attrs\n",
                                    "KeyboardInterrupt\n"
                              ]
                        }
                  ],
                  "source": [
                        "! lamin load scprint"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 1,
                  "metadata": {},
                  "outputs": [
                        {
                              "name": "stderr",
                              "output_type": "stream",
                              "text": [
                                    "Global seed set to 42\n"
                              ]
                        },
                        {
                              "name": "stdout",
                              "output_type": "stream",
                              "text": [
                                    "ðŸ’¡ connected lamindb: jkobject/scprint\n"
                              ]
                        },
                        {
                              "name": "stderr",
                              "output_type": "stream",
                              "text": [
                                    "2024-05-21 16:55:39,115:INFO - Downloading data from `https://omnipathdb.org/queries/enzsub?format=json`\n",
                                    "2024-05-21 16:55:39,224:INFO - Downloading data from `https://omnipathdb.org/queries/interactions?format=json`\n",
                                    "2024-05-21 16:55:39,315:INFO - Downloading data from `https://omnipathdb.org/queries/complexes?format=json`\n",
                                    "2024-05-21 16:55:39,405:INFO - Downloading data from `https://omnipathdb.org/queries/annotations?format=json`\n",
                                    "2024-05-21 16:55:39,502:INFO - Downloading data from `https://omnipathdb.org/queries/intercell?format=json`\n",
                                    "2024-05-21 16:55:39,684:INFO - Downloading data from `https://omnipathdb.org/about?format=text`\n",
                                    "/home/ml4ig1/miniconda3/envs/scprint/lib/python3.10/site-packages/umap/__init__.py:9: ImportWarning: Tensorflow not installed; ParametricUMAP will be unavailable\n",
                                    "  warn(\n",
                                    "/home/ml4ig1/miniconda3/envs/scprint/lib/python3.10/site-packages/chex/_src/pytypes.py:53: DeprecationWarning: jax.core.Shape is deprecated. Use Shape = Sequence[int | Any].\n",
                                    "  Shape = jax.core.Shape\n",
                                    "/home/ml4ig1/miniconda3/envs/scprint/lib/python3.10/site-packages/chex/_src/pytypes.py:54: DeprecationWarning: jax.random.KeyArray is deprecated. Use jax.Array for annotations, and jax.dtypes.issubdtype(arr.dtype, jax.dtypes.prng_key) for runtime detection of typed prng keys (i.e. keys created with jax.random.key).\n",
                                    "For more information, see https://jax.readthedocs.io/en/latest/jep/9263-typed-keys.html\n",
                                    "  PRNGKey = jax.random.KeyArray\n",
                                    "/home/ml4ig1/miniconda3/envs/scprint/lib/python3.10/site-packages/scib_metrics/_types.py:9: DeprecationWarning: jax.random.KeyArray is deprecated. Use jax.Array for annotations, and jax.dtypes.issubdtype(arr.dtype, jax.dtypes.prng_key) for runtime detection of typed prng keys (i.e. keys created with jax.random.key).\n",
                                    "For more information, see https://jax.readthedocs.io/en/latest/jep/9263-typed-keys.html\n",
                                    "  IntOrKey = Union[int, jax.random.KeyArray]\n",
                                    "/home/ml4ig1/miniconda3/envs/scprint/lib/python3.10/site-packages/scib_metrics/utils/_utils.py:40: DeprecationWarning: jax.random.KeyArray is deprecated. Use jax.Array for annotations, and jax.dtypes.issubdtype(arr.dtype, jax.dtypes.prng_key) for runtime detection of typed prng keys (i.e. keys created with jax.random.key).\n",
                                    "For more information, see https://jax.readthedocs.io/en/latest/jep/9263-typed-keys.html\n",
                                    "  def validate_seed(seed: IntOrKey) -> jax.random.KeyArray:\n",
                                    "/home/ml4ig1/miniconda3/envs/scprint/lib/python3.10/site-packages/scib_metrics/utils/_kmeans.py:21: DeprecationWarning: jax.random.KeyArray is deprecated. Use jax.Array for annotations, and jax.dtypes.issubdtype(arr.dtype, jax.dtypes.prng_key) for runtime detection of typed prng keys (i.e. keys created with jax.random.key).\n",
                                    "For more information, see https://jax.readthedocs.io/en/latest/jep/9263-typed-keys.html\n",
                                    "  def _initialize_random(X: jnp.ndarray, n_clusters: int, key: jax.random.KeyArray) -> jnp.ndarray:\n",
                                    "/home/ml4ig1/miniconda3/envs/scprint/lib/python3.10/site-packages/scib_metrics/utils/_kmeans.py:31: DeprecationWarning: jax.random.KeyArray is deprecated. Use jax.Array for annotations, and jax.dtypes.issubdtype(arr.dtype, jax.dtypes.prng_key) for runtime detection of typed prng keys (i.e. keys created with jax.random.key).\n",
                                    "For more information, see https://jax.readthedocs.io/en/latest/jep/9263-typed-keys.html\n",
                                    "  def _initialize_plus_plus(X: jnp.ndarray, n_clusters: int, key: jax.random.KeyArray) -> jnp.ndarray:\n"
                              ]
                        }
                  ],
                  "source": [
                        "from lightning.pytorch import Trainer, seed_everything\n",
                        "from lightning.pytorch.callbacks import ModelCheckpoint, StochasticWeightAveraging, EarlyStopping, LearningRateMonitor, LearningRateFinder\n",
                        "\n",
                        "seed_everything(42, workers=True)\n",
                        "\n",
                        "from scprint import scPrint\n",
                        "from scprint.trainer import TrainingMode\n",
                        "from scdataloader import DataModule \n",
                        "import pandas as pd\n",
                        "from scdataloader.utils import load_genes\n",
                        "\n",
                        "import torch\n",
                        "torch.set_float32_matmul_precision('medium')\n",
                        "\n",
                        "%load_ext autoreload\n",
                        "%autoreload 2"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 2,
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "# TODO: drop tissue & dev stage until part or is taken in account\n",
                        "\n",
                        "hierarchical_clss = [\n",
                        "    \"cell_type_ontology_term_id\",  # 1\n",
                        "    # \"tissue_ontology_term_id\",\n",
                        "    \"disease_ontology_term_id\",  # 2\n",
                        "    #    \"development_stage_ontology_term_id\",\n",
                        "    \"assay_ontology_term_id\",  # 3\n",
                        "    'self_reported_ethnicity_ontology_term_id',  # 4\n",
                        "]\n",
                        "clss_to_pred = hierarchical_clss+[\n",
                        "    'sex_ontology_term_id',  # 5\n",
                        "    \"organism_ontology_term_id\",  # 6\n",
                        "]\n",
                        "all_clss = clss_to_pred+[\n",
                        "    # 'dataset_id',\n",
                        "    # 'cell_culture',\n",
                        "    #  \"heat_diff\",\n",
                        "    #  \"total_counts\",\n",
                        "    # \"nnz\",\n",
                        "    #  \"dpt_group\",\n",
                        "]\n",
                        "\n",
                        "gene_emb = '../data/main/gene_embeddings.parquet'\n",
                        "d_model = 128"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": null,
                  "metadata": {},
                  "outputs": [],
                  "source": []
            },
            {
                  "cell_type": "code",
                  "execution_count": 3,
                  "metadata": {},
                  "outputs": [
                        {
                              "name": "stdout",
                              "output_type": "stream",
                              "text": [
                                    "won't do any check but we recommend to have your dataset coming from local storage\n",
                                    "\n",
                                    "80.0% are aligned\n",
                                    "seeing a string: loading gene positions as biomart parquet file\n"
                              ]
                        }
                  ],
                  "source": [
                        "datamodule = DataModule(\n",
                        "    collection_name=\"some\",\n",
                        "    gene_embeddings=gene_emb,\n",
                        "    all_clss=all_clss,\n",
                        "    hierarchical_clss=hierarchical_clss,\n",
                        "    organisms=[\"NCBITaxon:9606\"],  # , \"NCBITaxon:10090\"],\n",
                        "    how=\"most expr\",\n",
                        "    max_len=1200,\n",
                        "    add_zero_genes=0,\n",
                        "    # how much more you will see the most present vs less present category\n",
                        "    weight_scaler=10,\n",
                        "    clss_to_weight=clss_to_pred,\n",
                        "    clss_to_pred=clss_to_pred,\n",
                        "    batch_size=1,\n",
                        "    num_workers=1,\n",
                        "    # train_oversampling=2,\n",
                        "    validation_split=0.05,\n",
                        "    do_gene_pos='../data/main/biomart_pos.parquet',\n",
                        "    test_split=0.05)\n",
                        "testfiles = datamodule.setup()"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 4,
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "# create a function to transform an scGPT checkpoint to an scPrint's\n",
                        "# ckpt = torch.load(\"../../scGPT/save/model_e6.pt\")\n",
                        "# scPrint.load_from_checkpoint(\"../../scGPT/save/model_e6.pt\")"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 5,
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "# from lightning.pytorch.profilers import PyTorchProfiler\n",
                        "# pytorch_prof = PyTorchProfiler(\"../data/tensorboard\", emit_nvtx=False, group_by_input_shape=True, record_shapes=True, profile_memory=True, with_stack=True, on_trace_ready=torch.profiler.tensorboard_trace_handler(\"../data/tensorboard/\"),)"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 4,
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "model = scPrint(\n",
                        "    genes=datamodule.genes,\n",
                        "    d_model=d_model*4,\n",
                        "    nhead=4*2,\n",
                        "    nlayers=1,\n",
                        "    # layers_cls = [d_model],\n",
                        "    # labels = datamodule.labels,\n",
                        "    # cls_hierarchy = datamodule.cls_hierarchy,\n",
                        "    dropout=0,\n",
                        "    transformer=\"flash\",\n",
                        "    precpt_gene_emb=gene_emb,\n",
                        "    gene_pos_enc=datamodule.gene_pos,\n",
                        "    mvc_decoder=\"inner product\",\n",
                        "    # label_decoders = datamodule.decoders,\n",
                        "    fused_dropout_add_ln=False,\n",
                        "    # num_batch_labels = datamodule.num_datasets,\n",
                        "    checkpointing=False,\n",
                        "    prenorm=True,\n",
                        "    num_heads_kv=None,\n",
                        "    weight_decay=0,\n",
                        "    #zinb=False\n",
                        ")"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 6,
                  "metadata": {},
                  "outputs": [
                        {
                              "name": "stderr",
                              "output_type": "stream",
                              "text": [
                                    "2024-05-21 16:00:36,256:ERROR - Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
                                    "wandb: Currently logged in as: jkobject (ml4ig). Use `wandb login --relogin` to force relogin\n",
                                    "/home/ml4ig1/miniconda3/envs/scprint/lib/python3.10/site-packages/wandb/sdk/lib/ipython.py:77: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
                                    "  from IPython.core.display import HTML, display  # type: ignore\n"
                              ]
                        },
                        {
                              "data": {
                                    "text/html": [
                                          "wandb version 0.17.0 is available!  To upgrade, please run:\n",
                                          " $ pip install wandb --upgrade"
                                    ],
                                    "text/plain": [
                                          "<IPython.core.display.HTML object>"
                                    ]
                              },
                              "metadata": {},
                              "output_type": "display_data"
                        },
                        {
                              "data": {
                                    "text/html": [
                                          "Tracking run with wandb version 0.16.2"
                                    ],
                                    "text/plain": [
                                          "<IPython.core.display.HTML object>"
                                    ]
                              },
                              "metadata": {},
                              "output_type": "display_data"
                        },
                        {
                              "data": {
                                    "text/html": [
                                          "Run data is saved locally in <code>../data/tensorboard/wandb/run-20240521_160037-vmd7thz7</code>"
                                    ],
                                    "text/plain": [
                                          "<IPython.core.display.HTML object>"
                                    ]
                              },
                              "metadata": {},
                              "output_type": "display_data"
                        },
                        {
                              "data": {
                                    "text/html": [
                                          "Syncing run <strong><a href='https://wandb.ai/ml4ig/scprint_test/runs/vmd7thz7' target=\"_blank\">magic-forest-5</a></strong> to <a href='https://wandb.ai/ml4ig/scprint_test' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
                                    ],
                                    "text/plain": [
                                          "<IPython.core.display.HTML object>"
                                    ]
                              },
                              "metadata": {},
                              "output_type": "display_data"
                        },
                        {
                              "data": {
                                    "text/html": [
                                          " View project at <a href='https://wandb.ai/ml4ig/scprint_test' target=\"_blank\">https://wandb.ai/ml4ig/scprint_test</a>"
                                    ],
                                    "text/plain": [
                                          "<IPython.core.display.HTML object>"
                                    ]
                              },
                              "metadata": {},
                              "output_type": "display_data"
                        },
                        {
                              "data": {
                                    "text/html": [
                                          " View run at <a href='https://wandb.ai/ml4ig/scprint_test/runs/vmd7thz7' target=\"_blank\">https://wandb.ai/ml4ig/scprint_test/runs/vmd7thz7</a>"
                                    ],
                                    "text/plain": [
                                          "<IPython.core.display.HTML object>"
                                    ]
                              },
                              "metadata": {},
                              "output_type": "display_data"
                        },
                        {
                              "name": "stderr",
                              "output_type": "stream",
                              "text": [
                                    "wandb: logging graph, to disable use `wandb.watch(log_graph=False)`\n"
                              ]
                        }
                  ],
                  "source": [
                        "# from lightning.pytorch.loggers import TensorBoardLogger\n",
                        "from lightning.pytorch.loggers import WandbLogger\n",
                        "\n",
                        "wandb_logger = WandbLogger(project=\"scprint_test\",\n",
                        "                           save_dir=\"../data/tensorboard\")\n",
                        "wandb_logger.watch(model, log='all', log_freq=50, log_graph=True)\n",
                        "\n",
                        "# tlogger = TensorBoardLogger(save_dir=\"../data/tensorboard\")\n",
                        "# tlogger.log_graph(model)"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 7,
                  "metadata": {},
                  "outputs": [
                        {
                              "name": "stderr",
                              "output_type": "stream",
                              "text": [
                                    "Using 16bit Automatic Mixed Precision (AMP)\n",
                                    "GPU available: True (cuda), used: True\n",
                                    "TPU available: False, using: 0 TPU cores\n",
                                    "IPU available: False, using: 0 IPUs\n",
                                    "HPU available: False, using: 0 HPUs\n",
                                    "`Trainer(limit_val_batches=1)` was configured so 1 batch will be used.\n",
                                    "GPU available: True (cuda), used: True\n",
                                    "TPU available: False, using: 0 TPU cores\n",
                                    "IPU available: False, using: 0 IPUs\n",
                                    "HPU available: False, using: 0 HPUs\n",
                                    "`Trainer(limit_val_batches=1)` was configured so 1 batch will be used.\n"
                              ]
                        }
                  ],
                  "source": [
                        "chckp = ModelCheckpoint(monitor=\"val_loss\", save_top_k=-1)\n",
                        "trainingmode = TrainingMode(\n",
                        "    do_denoise=True,\n",
                        "    noise=[0.01],\n",
                        "    do_cce=False,\n",
                        "    cce_sim=0.6,\n",
                        "    do_ecs=False,\n",
                        "    ecs_threshold=0.4,\n",
                        "    ecs_scale=0.05,\n",
                        "    class_scale=0.08,\n",
                        "    do_cls=False,\n",
                        "    do_mvc=False,\n",
                        "    do_adv_cls=False,\n",
                        "    do_next_tp=False,\n",
                        "    mask_ratio=[],\n",
                        "    warmup_duration=100,\n",
                        "    fused_adam=True,\n",
                        "    lr_reduce_patience=200,\n",
                        ")\n",
                        "# es = EarlyStopping(patience=2, monitor='val_loss')\n",
                        "# swa = StochasticWeightAveraging(swa_lrs= 0.01)\n",
                        "# lrm = LearningRateMonitor(logging_interval=\"step\")\n",
                        "# lrf = LearningRateFinder(mode=\"exponential\",)\n",
                        "# TODO: to check that the class hierarchy are really ordered from 1-2-3-4... as well (oredered dict)\n",
                        "# , logger=tlogger) #detect_anomaly=True, fast_dev_run=20, overfit_batches=10, limit_train_batches=1, limit_val_batches=0\n",
                        "trainer = Trainer(precision=\"16-mixed\", gradient_clip_val=500, max_time={\"hours\": 2}, limit_val_batches=1, callbacks=[\n",
                        "                  trainingmode], accumulate_grad_batches=1, check_val_every_n_epoch=1, reload_dataloaders_every_n_epochs=1000000, logger=wandb_logger)\n",
                        "# logger=wandb_logger,"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 14,
                  "metadata": {},
                  "outputs": [
                        {
                              "name": "stderr",
                              "output_type": "stream",
                              "text": [
                                    "Using 16bit Automatic Mixed Precision (AMP)\n",
                                    "GPU available: True (cuda), used: True\n",
                                    "TPU available: False, using: 0 TPU cores\n",
                                    "IPU available: False, using: 0 IPUs\n",
                                    "HPU available: False, using: 0 HPUs\n",
                                    "`Trainer(overfit_batches=1)` was configured so 1 batch will be used.\n",
                                    "GPU available: True (cuda), used: True\n",
                                    "TPU available: False, using: 0 TPU cores\n",
                                    "IPU available: False, using: 0 IPUs\n",
                                    "HPU available: False, using: 0 HPUs\n",
                                    "`Trainer(overfit_batches=1)` was configured so 1 batch will be used.\n"
                              ]
                        }
                  ],
                  "source": [
                        "# sanity. should be overfiting.\n",
                        "trainer = Trainer(precision=\"16-mixed\", gradient_clip_val=500, max_time={\"hours\": 2}, limit_val_batches=1, callbacks=[\n",
                        "                  trainingmode], accumulate_grad_batches=1, check_val_every_n_epoch=1, overfit_batches=1, reload_dataloaders_every_n_epochs=1000_000, logger=wandb_logger, num_sanity_val_steps=0)"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 16,
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "from scprint.tasks.cell_emb import default_benchmark"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 9,
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "model.lr_reduce_patience = 50\n",
                        "model.lr_reduce_ratio = 0.2"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 10,
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "model.lr = 0.00001"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 17,
                  "metadata": {},
                  "outputs": [
                        {
                              "name": "stderr",
                              "output_type": "stream",
                              "text": [
                                    "/home/ml4ig1/miniconda3/envs/scprint/lib/python3.10/site-packages/anndata/__init__.py:51: FutureWarning: `anndata.read` is deprecated, use `anndata.read_h5ad` instead. `ad.read` will be removed in mid 2024.\n",
                                    "  warnings.warn(\n",
                                    "/home/ml4ig1/miniconda3/envs/scprint/lib/python3.10/site-packages/anndata/_io/specs/registry.py:249: OldFormatWarning: Element '/layers' was written without encoding metadata.\n",
                                    "  return self.callback(read_func, elem.name, elem, iospec=get_spec(elem))\n",
                                    "/home/ml4ig1/miniconda3/envs/scprint/lib/python3.10/site-packages/anndata/_io/utils.py:205: OldFormatWarning: Element '/obs/__categories/dataset' was written without encoding metadata.\n",
                                    "  return func(*args, **kwargs)\n",
                                    "/home/ml4ig1/miniconda3/envs/scprint/lib/python3.10/site-packages/anndata/_io/utils.py:205: OldFormatWarning: Element '/obs/dataset' was written without encoding metadata.\n",
                                    "  return func(*args, **kwargs)\n",
                                    "/home/ml4ig1/miniconda3/envs/scprint/lib/python3.10/site-packages/anndata/_io/utils.py:205: OldFormatWarning: Element '/obs/__categories/location' was written without encoding metadata.\n",
                                    "  return func(*args, **kwargs)\n",
                                    "/home/ml4ig1/miniconda3/envs/scprint/lib/python3.10/site-packages/anndata/_io/utils.py:205: OldFormatWarning: Element '/obs/location' was written without encoding metadata.\n",
                                    "  return func(*args, **kwargs)\n",
                                    "/home/ml4ig1/miniconda3/envs/scprint/lib/python3.10/site-packages/anndata/_io/utils.py:205: OldFormatWarning: Element '/obs/nGene' was written without encoding metadata.\n",
                                    "  return func(*args, **kwargs)\n",
                                    "/home/ml4ig1/miniconda3/envs/scprint/lib/python3.10/site-packages/anndata/_io/utils.py:205: OldFormatWarning: Element '/obs/nUMI' was written without encoding metadata.\n",
                                    "  return func(*args, **kwargs)\n",
                                    "/home/ml4ig1/miniconda3/envs/scprint/lib/python3.10/site-packages/anndata/_io/utils.py:205: OldFormatWarning: Element '/obs/__categories/patientGroup' was written without encoding metadata.\n",
                                    "  return func(*args, **kwargs)\n",
                                    "/home/ml4ig1/miniconda3/envs/scprint/lib/python3.10/site-packages/anndata/_io/utils.py:205: OldFormatWarning: Element '/obs/patientGroup' was written without encoding metadata.\n",
                                    "  return func(*args, **kwargs)\n",
                                    "/home/ml4ig1/miniconda3/envs/scprint/lib/python3.10/site-packages/anndata/_io/utils.py:205: OldFormatWarning: Element '/obs/percent.mito' was written without encoding metadata.\n",
                                    "  return func(*args, **kwargs)\n",
                                    "/home/ml4ig1/miniconda3/envs/scprint/lib/python3.10/site-packages/anndata/_io/utils.py:205: OldFormatWarning: Element '/obs/__categories/protocol' was written without encoding metadata.\n",
                                    "  return func(*args, **kwargs)\n",
                                    "/home/ml4ig1/miniconda3/envs/scprint/lib/python3.10/site-packages/anndata/_io/utils.py:205: OldFormatWarning: Element '/obs/protocol' was written without encoding metadata.\n",
                                    "  return func(*args, **kwargs)\n",
                                    "/home/ml4ig1/miniconda3/envs/scprint/lib/python3.10/site-packages/anndata/_io/utils.py:205: OldFormatWarning: Element '/obs/__categories/sanger_type' was written without encoding metadata.\n",
                                    "  return func(*args, **kwargs)\n",
                                    "/home/ml4ig1/miniconda3/envs/scprint/lib/python3.10/site-packages/anndata/_io/utils.py:205: OldFormatWarning: Element '/obs/sanger_type' was written without encoding metadata.\n",
                                    "  return func(*args, **kwargs)\n",
                                    "/home/ml4ig1/miniconda3/envs/scprint/lib/python3.10/site-packages/anndata/_io/utils.py:205: OldFormatWarning: Element '/obs/size_factors' was written without encoding metadata.\n",
                                    "  return func(*args, **kwargs)\n",
                                    "/home/ml4ig1/miniconda3/envs/scprint/lib/python3.10/site-packages/anndata/_io/utils.py:205: OldFormatWarning: Element '/obs/__categories/sampling_method' was written without encoding metadata.\n",
                                    "  return func(*args, **kwargs)\n",
                                    "/home/ml4ig1/miniconda3/envs/scprint/lib/python3.10/site-packages/anndata/_io/utils.py:205: OldFormatWarning: Element '/obs/sampling_method' was written without encoding metadata.\n",
                                    "  return func(*args, **kwargs)\n",
                                    "/home/ml4ig1/miniconda3/envs/scprint/lib/python3.10/site-packages/anndata/_io/utils.py:205: OldFormatWarning: Element '/obs/__categories/batch' was written without encoding metadata.\n",
                                    "  return func(*args, **kwargs)\n",
                                    "/home/ml4ig1/miniconda3/envs/scprint/lib/python3.10/site-packages/anndata/_io/utils.py:205: OldFormatWarning: Element '/obs/batch' was written without encoding metadata.\n",
                                    "  return func(*args, **kwargs)\n",
                                    "/home/ml4ig1/miniconda3/envs/scprint/lib/python3.10/site-packages/anndata/_io/utils.py:205: OldFormatWarning: Element '/obs/__categories/cell_type' was written without encoding metadata.\n",
                                    "  return func(*args, **kwargs)\n",
                                    "/home/ml4ig1/miniconda3/envs/scprint/lib/python3.10/site-packages/anndata/_io/utils.py:205: OldFormatWarning: Element '/obs/cell_type' was written without encoding metadata.\n",
                                    "  return func(*args, **kwargs)\n",
                                    "/home/ml4ig1/miniconda3/envs/scprint/lib/python3.10/site-packages/anndata/_io/utils.py:205: OldFormatWarning: Element '/obs/__categories/donor' was written without encoding metadata.\n",
                                    "  return func(*args, **kwargs)\n",
                                    "/home/ml4ig1/miniconda3/envs/scprint/lib/python3.10/site-packages/anndata/_io/utils.py:205: OldFormatWarning: Element '/obs/donor' was written without encoding metadata.\n",
                                    "  return func(*args, **kwargs)\n",
                                    "/home/ml4ig1/miniconda3/envs/scprint/lib/python3.10/site-packages/anndata/_io/utils.py:205: OldFormatWarning: Element '/obs/index' was written without encoding metadata.\n",
                                    "  return func(*args, **kwargs)\n",
                                    "/home/ml4ig1/miniconda3/envs/scprint/lib/python3.10/site-packages/anndata/_io/utils.py:205: OldFormatWarning: Element '/var/index' was written without encoding metadata.\n",
                                    "  return func(*args, **kwargs)\n",
                                    "/home/ml4ig1/Documents code/scPRINT/scprint/tasks/cell_emb.py:366: FutureWarning: The behavior of Series.replace (and DataFrame.replace) with CategoricalDtype is deprecated. In a future version, replace will only be used for cases that preserve the categories. To change the categories, use ser.cat.rename_categories instead.\n",
                                    "  adata.obs['cell_type_ontology_term_id'] = adata.obs['cell_type'].replace(\n"
                              ]
                        },
                        {
                              "name": "stdout",
                              "output_type": "stream",
                              "text": [
                                    "X was not raw counts, using 'counts' layer\n",
                                    "Dropping layers:  KeysView(Layers with keys: counts)\n",
                                    "checking raw counts\n",
                                    "Data is not raw counts, please check layers, find raw data, or bypass with force_preprocess\n",
                                    "removed 0 non primary cells, 32472 renamining\n",
                                    "filtered out 221 cells, 32251 renamining\n",
                                    "Removed 0 genes.\n",
                                    "startin QC\n",
                                    "Seeing 10331 outliers (32.03% of total dataset):\n",
                                    "done\n",
                                    "> /home/ml4ig1/Documents code/scPRINT/scprint/tasks/cell_emb.py(383)default_benchmark()\n",
                                    "    381     import pdb\n",
                                    "    382     pdb.set_trace()\n",
                                    "--> 383     embedder = Embedder(\n",
                                    "    384         model, pred_embedding=[\"cell_type_ontology_term_id\"], organisms=[adata.obs[\"organism_ontology_term_id\"].values[0]]\n",
                                    "    385     )\n",
                                    "\n"
                              ]
                        },
                        {
                              "name": "stderr",
                              "output_type": "stream",
                              "text": [
                                    "Using 16bit Automatic Mixed Precision (AMP)\n",
                                    "GPU available: True (cuda), used: True\n",
                                    "TPU available: False, using: 0 TPU cores\n",
                                    "IPU available: False, using: 0 IPUs\n",
                                    "HPU available: False, using: 0 HPUs\n",
                                    "/home/ml4ig1/miniconda3/envs/scprint/lib/python3.10/site-packages/torch/utils/tensorboard/__init__.py:4: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
                                    "  if not hasattr(tensorboard, \"__version__\") or LooseVersion(\n",
                                    "/home/ml4ig1/miniconda3/envs/scprint/lib/python3.10/site-packages/torch/utils/tensorboard/__init__.py:6: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
                                    "  ) < LooseVersion(\"1.15\"):\n",
                                    "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
                              ]
                        },
                        {
                              "data": {
                                    "application/vnd.jupyter.widget-view+json": {
                                          "model_id": "390f86adeade41caba17e0dd00d8bb48",
                                          "version_major": 2,
                                          "version_minor": 0
                                    },
                                    "text/plain": [
                                          "Predicting: 0it [00:00, ?it/s]"
                                    ]
                              },
                              "metadata": {},
                              "output_type": "display_data"
                        },
                        {
                              "ename": "ValueError",
                              "evalue": "'cell_type_ontology_term_id' is not in list",
                              "output_type": "error",
                              "traceback": [
                                    "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                                    "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
                                    "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdefault_benchmark\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlung\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
                                    "File \u001b[0;32m~/Documents code/scPRINT/scprint/tasks/cell_emb.py:386\u001b[0m, in \u001b[0;36mdefault_benchmark\u001b[0;34m(model, default_dataset, do_class, coarse)\u001b[0m\n\u001b[1;32m    382\u001b[0m pdb\u001b[38;5;241m.\u001b[39mset_trace()\n\u001b[1;32m    383\u001b[0m embedder \u001b[38;5;241m=\u001b[39m Embedder(\n\u001b[1;32m    384\u001b[0m     model, pred_embedding\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type_ontology_term_id\u001b[39m\u001b[38;5;124m\"\u001b[39m], organisms\u001b[38;5;241m=\u001b[39m[adata\u001b[38;5;241m.\u001b[39mobs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124morganism_ontology_term_id\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues[\u001b[38;5;241m0\u001b[39m]]\n\u001b[1;32m    385\u001b[0m )\n\u001b[0;32m--> 386\u001b[0m embed_adata, metrics \u001b[38;5;241m=\u001b[39m \u001b[43membedder\u001b[49m\u001b[43m(\u001b[49m\u001b[43madata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    388\u001b[0m bm \u001b[38;5;241m=\u001b[39m Benchmarker(\n\u001b[1;32m    389\u001b[0m     embed_adata,\n\u001b[1;32m    390\u001b[0m     batch_key\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtech\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m default_dataset \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpancreas\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    393\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m6\u001b[39m,\n\u001b[1;32m    394\u001b[0m )\n\u001b[1;32m    395\u001b[0m bm\u001b[38;5;241m.\u001b[39mbenchmark()\n",
                                    "File \u001b[0;32m~/Documents code/scPRINT/scprint/tasks/cell_emb.py:123\u001b[0m, in \u001b[0;36mEmbedder.__call__\u001b[0;34m(self, adata, cache, output_expression)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mpred_log_adata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mpred_embedding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpred_embedding\n\u001b[0;32m--> 123\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    125\u001b[0m     mdir \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    126\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39msave_dir\n\u001b[1;32m    127\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39msave_dir \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    128\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    129\u001b[0m     )\n",
                                    "File \u001b[0;32m~/miniconda3/envs/scprint/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:852\u001b[0m, in \u001b[0;36mTrainer.predict\u001b[0;34m(self, model, dataloaders, datamodule, return_predictions, ckpt_path)\u001b[0m\n\u001b[1;32m    850\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39m_lightning_module \u001b[38;5;241m=\u001b[39m model\n\u001b[1;32m    851\u001b[0m _verify_strategy_supports_compile(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrategy)\n\u001b[0;32m--> 852\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    853\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predict_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_predictions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[1;32m    854\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
                                    "File \u001b[0;32m~/miniconda3/envs/scprint/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py:43\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     42\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39mtrainer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 43\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n\u001b[1;32m     46\u001b[0m     _call_teardown_hook(trainer)\n",
                                    "File \u001b[0;32m~/miniconda3/envs/scprint/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:894\u001b[0m, in \u001b[0;36mTrainer._predict_impl\u001b[0;34m(self, model, dataloaders, datamodule, return_predictions, ckpt_path)\u001b[0m\n\u001b[1;32m    889\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_connector\u001b[38;5;241m.\u001b[39mattach_data(model, predict_dataloaders\u001b[38;5;241m=\u001b[39mdataloaders, datamodule\u001b[38;5;241m=\u001b[39mdatamodule)\n\u001b[1;32m    891\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39m_select_ckpt_path(\n\u001b[1;32m    892\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn, ckpt_path, model_provided\u001b[38;5;241m=\u001b[39mmodel_provided, model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    893\u001b[0m )\n\u001b[0;32m--> 894\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    896\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstopped\n\u001b[1;32m    897\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredicting \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
                                    "File \u001b[0;32m~/miniconda3/envs/scprint/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:980\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m    975\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_signal_connector\u001b[38;5;241m.\u001b[39mregister_signal_handlers()\n\u001b[1;32m    977\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    978\u001b[0m \u001b[38;5;66;03m# RUN THE TRAINER\u001b[39;00m\n\u001b[1;32m    979\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m--> 980\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    982\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    983\u001b[0m \u001b[38;5;66;03m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[1;32m    984\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    985\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: trainer tearing down\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
                                    "File \u001b[0;32m~/miniconda3/envs/scprint/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:1018\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1016\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_evaluation_loop\u001b[38;5;241m.\u001b[39mrun()\n\u001b[1;32m   1017\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredicting:\n\u001b[0;32m-> 1018\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1019\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining:\n\u001b[1;32m   1020\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m isolate_rng():\n",
                                    "File \u001b[0;32m~/miniconda3/envs/scprint/lib/python3.10/site-packages/lightning/pytorch/loops/utilities.py:181\u001b[0m, in \u001b[0;36m_no_grad_context.<locals>._decorator\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    179\u001b[0m     context_manager \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mno_grad\n\u001b[1;32m    180\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context_manager():\n\u001b[0;32m--> 181\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloop_run\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
                                    "File \u001b[0;32m~/miniconda3/envs/scprint/lib/python3.10/site-packages/lightning/pytorch/loops/prediction_loop.py:112\u001b[0m, in \u001b[0;36m_PredictionLoop.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    110\u001b[0m     batch, batch_idx, dataloader_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(data_fetcher)\n\u001b[1;32m    111\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_progress\u001b[38;5;241m.\u001b[39mis_last_batch \u001b[38;5;241m=\u001b[39m data_fetcher\u001b[38;5;241m.\u001b[39mdone\n\u001b[0;32m--> 112\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predict_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader_idx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;66;03m# this needs to wrap the `*_step` call too (not just `next`) for `dataloader_iter` support\u001b[39;00m\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
                                    "File \u001b[0;32m~/miniconda3/envs/scprint/lib/python3.10/site-packages/lightning/pytorch/loops/prediction_loop.py:229\u001b[0m, in \u001b[0;36m_PredictionLoop._predict_step\u001b[0;34m(self, batch, batch_idx, dataloader_idx)\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_progress\u001b[38;5;241m.\u001b[39mincrement_started()\n\u001b[1;32m    228\u001b[0m \u001b[38;5;66;03m# configure step_kwargs\u001b[39;00m\n\u001b[0;32m--> 229\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_strategy_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpredict_step\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mstep_kwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    231\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_progress\u001b[38;5;241m.\u001b[39mincrement_processed()\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m predictions \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
                                    "File \u001b[0;32m~/miniconda3/envs/scprint/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py:294\u001b[0m, in \u001b[0;36m_call_strategy_hook\u001b[0;34m(trainer, hook_name, *args, **kwargs)\u001b[0m\n\u001b[1;32m    291\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    293\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[Strategy]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 294\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n\u001b[1;32m    297\u001b[0m pl_module\u001b[38;5;241m.\u001b[39m_current_fx_name \u001b[38;5;241m=\u001b[39m prev_fx_name\n",
                                    "File \u001b[0;32m~/miniconda3/envs/scprint/lib/python3.10/site-packages/lightning/pytorch/strategies/strategy.py:413\u001b[0m, in \u001b[0;36mStrategy.predict_step\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    411\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprecision_plugin\u001b[38;5;241m.\u001b[39mpredict_step_context():\n\u001b[1;32m    412\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, PredictStep)\n\u001b[0;32m--> 413\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_step\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
                                    "File \u001b[0;32m~/Documents code/scPRINT/scprint/model/model.py:1109\u001b[0m, in \u001b[0;36mscPrint.predict_step\u001b[0;34m(self, batch, batch_idx)\u001b[0m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict_step\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch, batch_idx):\n\u001b[1;32m   1100\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1101\u001b[0m \u001b[38;5;124;03m    embed given gene expression, encode the gene embedding and cell embedding.\u001b[39;00m\n\u001b[1;32m   1102\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;124;03m        Tensor: _description_\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1109\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgenes\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mx\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdepth\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpredict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
                                    "File \u001b[0;32m~/Documents code/scPRINT/scprint/model/model.py:1183\u001b[0m, in \u001b[0;36mscPrint._predict\u001b[0;34m(self, gene_pos, expression, depth, keep_output, max_size_in_mem, name)\u001b[0m\n\u001b[1;32m   1181\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpred_embedding) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1182\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpred_embedding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses\n\u001b[0;32m-> 1183\u001b[0m ind \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses\u001b[38;5;241m.\u001b[39mindex(i) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpred_embedding]\n\u001b[1;32m   1184\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m keep_output:\n\u001b[1;32m   1185\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m   1186\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124membs\u001b[39m\u001b[38;5;124m\"\u001b[39m: torch\u001b[38;5;241m.\u001b[39mmean(cell_embs[:, ind, :], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m),\n\u001b[1;32m   1187\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass\u001b[39m\u001b[38;5;124m\"\u001b[39m: torch\u001b[38;5;241m.\u001b[39mstack(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1194\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexpr\u001b[39m\u001b[38;5;124m\"\u001b[39m: [output[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m], output[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdisp\u001b[39m\u001b[38;5;124m\"\u001b[39m], output[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzero_logits\u001b[39m\u001b[38;5;124m\"\u001b[39m]] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdisp\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m output \u001b[38;5;28;01melse\u001b[39;00m [output[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m]],\n\u001b[1;32m   1195\u001b[0m     }\n",
                                    "File \u001b[0;32m~/Documents code/scPRINT/scprint/model/model.py:1183\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1181\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpred_embedding) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1182\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpred_embedding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses\n\u001b[0;32m-> 1183\u001b[0m ind \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclasses\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpred_embedding]\n\u001b[1;32m   1184\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m keep_output:\n\u001b[1;32m   1185\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m   1186\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124membs\u001b[39m\u001b[38;5;124m\"\u001b[39m: torch\u001b[38;5;241m.\u001b[39mmean(cell_embs[:, ind, :], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m),\n\u001b[1;32m   1187\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass\u001b[39m\u001b[38;5;124m\"\u001b[39m: torch\u001b[38;5;241m.\u001b[39mstack(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1194\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexpr\u001b[39m\u001b[38;5;124m\"\u001b[39m: [output[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m], output[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdisp\u001b[39m\u001b[38;5;124m\"\u001b[39m], output[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzero_logits\u001b[39m\u001b[38;5;124m\"\u001b[39m]] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdisp\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m output \u001b[38;5;28;01melse\u001b[39;00m [output[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m]],\n\u001b[1;32m   1195\u001b[0m     }\n",
                                    "\u001b[0;31mValueError\u001b[0m: 'cell_type_ontology_term_id' is not in list"
                              ]
                        }
                  ],
                  "source": [
                        "default_benchmark(model, default_dataset=\"lung\")"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 15,
                  "metadata": {},
                  "outputs": [
                        {
                              "name": "stderr",
                              "output_type": "stream",
                              "text": [
                                    "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
                                    "\n",
                                    "  | Name          | Type                    | Params\n",
                                    "----------------------------------------------------------\n",
                                    "0 | gene_encoder  | GeneEncoder             | 11.9 M\n",
                                    "1 | expr_encoder  | ContinuousValueEncoder  | 264 K \n",
                                    "2 | pos_encoder   | PositionalEncoding      | 0     \n",
                                    "3 | class_encoder | CategoryValueEncoder    | 512   \n",
                                    "4 | depth_encoder | ContinuousValueEncoder  | 264 K \n",
                                    "5 | transformer   | FlashTransformerEncoder | 3.2 M \n",
                                    "6 | expr_decoder  | ExprDecoder             | 528 K \n",
                                    "7 | cls_decoders  | ModuleDict              | 0     \n",
                                    "8 | mvc_decoder   | MVCDecoder              | 1.1 M \n",
                                    "----------------------------------------------------------\n",
                                    "5.3 M     Trainable params\n",
                                    "11.9 M    Non-trainable params\n",
                                    "17.1 M    Total params\n",
                                    "68.459    Total estimated model params size (MB)\n",
                                    "wandb: WARNING Serializing object of type list that is 194680 bytes\n",
                                    "wandb: WARNING Serializing object of type list that is 194680 bytes\n",
                                    "wandb: WARNING Serializing object of type list that is 194680 bytes\n",
                                    "wandb: WARNING Serializing object of type list that is 194680 bytes\n"
                              ]
                        },
                        {
                              "data": {
                                    "application/vnd.jupyter.widget-view+json": {
                                          "model_id": "d3337edf84d14e19b36e3cd4e1bdc73f",
                                          "version_major": 2,
                                          "version_minor": 0
                                    },
                                    "text/plain": [
                                          "Training: 0it [00:00, ?it/s]"
                                    ]
                              },
                              "metadata": {},
                              "output_type": "display_data"
                        },
                        {
                              "data": {
                                    "application/vnd.jupyter.widget-view+json": {
                                          "model_id": "b611c31d3c234973bb9023a68ef48060",
                                          "version_major": 2,
                                          "version_minor": 0
                                    },
                                    "text/plain": [
                                          "Validation: 0it [00:00, ?it/s]"
                                    ]
                              },
                              "metadata": {},
                              "output_type": "display_data"
                        },
                        {
                              "name": "stdout",
                              "output_type": "stream",
                              "text": [
                                    "AnnData object with n_obs Ã— n_vars = 1 Ã— 512\n",
                                    "couldn't log to tensorboard\n",
                                    "couldn't log to wandb\n"
                              ]
                        },
                        {
                              "name": "stderr",
                              "output_type": "stream",
                              "text": [
                                    "/home/ml4ig1/miniconda3/envs/scprint/lib/python3.10/site-packages/anndata/__init__.py:51: FutureWarning: `anndata.read` is deprecated, use `anndata.read_h5ad` instead. `ad.read` will be removed in mid 2024.\n",
                                    "  warnings.warn(\n",
                                    "/home/ml4ig1/miniconda3/envs/scprint/lib/python3.10/site-packages/anndata/_io/specs/registry.py:249: OldFormatWarning: Element '/layers' was written without encoding metadata.\n",
                                    "  return self.callback(read_func, elem.name, elem, iospec=get_spec(elem))\n",
                                    "/home/ml4ig1/miniconda3/envs/scprint/lib/python3.10/site-packages/anndata/_io/utils.py:205: OldFormatWarning: Element '/obs/__categories/dataset' was written without encoding metadata.\n",
                                    "  return func(*args, **kwargs)\n",
                                    "/home/ml4ig1/miniconda3/envs/scprint/lib/python3.10/site-packages/anndata/_io/utils.py:205: OldFormatWarning: Element '/obs/dataset' was written without encoding metadata.\n",
                                    "  return func(*args, **kwargs)\n",
                                    "/home/ml4ig1/miniconda3/envs/scprint/lib/python3.10/site-packages/anndata/_io/utils.py:205: OldFormatWarning: Element '/obs/__categories/location' was written without encoding metadata.\n",
                                    "  return func(*args, **kwargs)\n",
                                    "/home/ml4ig1/miniconda3/envs/scprint/lib/python3.10/site-packages/anndata/_io/utils.py:205: OldFormatWarning: Element '/obs/location' was written without encoding metadata.\n",
                                    "  return func(*args, **kwargs)\n",
                                    "/home/ml4ig1/miniconda3/envs/scprint/lib/python3.10/site-packages/anndata/_io/utils.py:205: OldFormatWarning: Element '/obs/nGene' was written without encoding metadata.\n",
                                    "  return func(*args, **kwargs)\n",
                                    "/home/ml4ig1/miniconda3/envs/scprint/lib/python3.10/site-packages/anndata/_io/utils.py:205: OldFormatWarning: Element '/obs/nUMI' was written without encoding metadata.\n",
                                    "  return func(*args, **kwargs)\n",
                                    "/home/ml4ig1/miniconda3/envs/scprint/lib/python3.10/site-packages/anndata/_io/utils.py:205: OldFormatWarning: Element '/obs/__categories/patientGroup' was written without encoding metadata.\n",
                                    "  return func(*args, **kwargs)\n",
                                    "/home/ml4ig1/miniconda3/envs/scprint/lib/python3.10/site-packages/anndata/_io/utils.py:205: OldFormatWarning: Element '/obs/patientGroup' was written without encoding metadata.\n",
                                    "  return func(*args, **kwargs)\n",
                                    "/home/ml4ig1/miniconda3/envs/scprint/lib/python3.10/site-packages/anndata/_io/utils.py:205: OldFormatWarning: Element '/obs/percent.mito' was written without encoding metadata.\n",
                                    "  return func(*args, **kwargs)\n",
                                    "/home/ml4ig1/miniconda3/envs/scprint/lib/python3.10/site-packages/anndata/_io/utils.py:205: OldFormatWarning: Element '/obs/__categories/protocol' was written without encoding metadata.\n",
                                    "  return func(*args, **kwargs)\n",
                                    "/home/ml4ig1/miniconda3/envs/scprint/lib/python3.10/site-packages/anndata/_io/utils.py:205: OldFormatWarning: Element '/obs/protocol' was written without encoding metadata.\n",
                                    "  return func(*args, **kwargs)\n",
                                    "/home/ml4ig1/miniconda3/envs/scprint/lib/python3.10/site-packages/anndata/_io/utils.py:205: OldFormatWarning: Element '/obs/__categories/sanger_type' was written without encoding metadata.\n",
                                    "  return func(*args, **kwargs)\n",
                                    "/home/ml4ig1/miniconda3/envs/scprint/lib/python3.10/site-packages/anndata/_io/utils.py:205: OldFormatWarning: Element '/obs/sanger_type' was written without encoding metadata.\n",
                                    "  return func(*args, **kwargs)\n",
                                    "/home/ml4ig1/miniconda3/envs/scprint/lib/python3.10/site-packages/anndata/_io/utils.py:205: OldFormatWarning: Element '/obs/size_factors' was written without encoding metadata.\n",
                                    "  return func(*args, **kwargs)\n",
                                    "/home/ml4ig1/miniconda3/envs/scprint/lib/python3.10/site-packages/anndata/_io/utils.py:205: OldFormatWarning: Element '/obs/__categories/sampling_method' was written without encoding metadata.\n",
                                    "  return func(*args, **kwargs)\n",
                                    "/home/ml4ig1/miniconda3/envs/scprint/lib/python3.10/site-packages/anndata/_io/utils.py:205: OldFormatWarning: Element '/obs/sampling_method' was written without encoding metadata.\n",
                                    "  return func(*args, **kwargs)\n",
                                    "/home/ml4ig1/miniconda3/envs/scprint/lib/python3.10/site-packages/anndata/_io/utils.py:205: OldFormatWarning: Element '/obs/__categories/batch' was written without encoding metadata.\n",
                                    "  return func(*args, **kwargs)\n",
                                    "/home/ml4ig1/miniconda3/envs/scprint/lib/python3.10/site-packages/anndata/_io/utils.py:205: OldFormatWarning: Element '/obs/batch' was written without encoding metadata.\n",
                                    "  return func(*args, **kwargs)\n",
                                    "/home/ml4ig1/miniconda3/envs/scprint/lib/python3.10/site-packages/anndata/_io/utils.py:205: OldFormatWarning: Element '/obs/__categories/cell_type' was written without encoding metadata.\n",
                                    "  return func(*args, **kwargs)\n",
                                    "/home/ml4ig1/miniconda3/envs/scprint/lib/python3.10/site-packages/anndata/_io/utils.py:205: OldFormatWarning: Element '/obs/cell_type' was written without encoding metadata.\n",
                                    "  return func(*args, **kwargs)\n",
                                    "/home/ml4ig1/miniconda3/envs/scprint/lib/python3.10/site-packages/anndata/_io/utils.py:205: OldFormatWarning: Element '/obs/__categories/donor' was written without encoding metadata.\n",
                                    "  return func(*args, **kwargs)\n",
                                    "/home/ml4ig1/miniconda3/envs/scprint/lib/python3.10/site-packages/anndata/_io/utils.py:205: OldFormatWarning: Element '/obs/donor' was written without encoding metadata.\n",
                                    "  return func(*args, **kwargs)\n",
                                    "/home/ml4ig1/miniconda3/envs/scprint/lib/python3.10/site-packages/anndata/_io/utils.py:205: OldFormatWarning: Element '/obs/index' was written without encoding metadata.\n",
                                    "  return func(*args, **kwargs)\n",
                                    "/home/ml4ig1/miniconda3/envs/scprint/lib/python3.10/site-packages/anndata/_io/utils.py:205: OldFormatWarning: Element '/var/index' was written without encoding metadata.\n",
                                    "  return func(*args, **kwargs)\n",
                                    "/home/ml4ig1/Documents code/scPRINT/scprint/tasks/cell_emb.py:366: FutureWarning: The behavior of Series.replace (and DataFrame.replace) with CategoricalDtype is deprecated. In a future version, replace will only be used for cases that preserve the categories. To change the categories, use ser.cat.rename_categories instead.\n",
                                    "  adata.obs['cell_type_ontology_term_id'] = adata.obs['cell_type'].replace(\n"
                              ]
                        },
                        {
                              "name": "stdout",
                              "output_type": "stream",
                              "text": [
                                    "X was not raw counts, using 'counts' layer\n",
                                    "Dropping layers:  KeysView(Layers with keys: counts)\n",
                                    "checking raw counts\n",
                                    "Data is not raw counts, please check layers, find raw data, or bypass with force_preprocess\n",
                                    "removed 0 non primary cells, 32472 renamining\n",
                                    "filtered out 221 cells, 32251 renamining\n",
                                    "Removed 0 genes.\n",
                                    "startin QC\n",
                                    "Seeing 10331 outliers (32.03% of total dataset):\n",
                                    "done\n",
                                    "> /home/ml4ig1/Documents code/scPRINT/scprint/tasks/cell_emb.py(383)default_benchmark()\n",
                                    "    381     import pdb\n",
                                    "    382     pdb.set_trace()\n",
                                    "--> 383     embedder = Embedder(\n",
                                    "    384         model, pred_embedding=[\"cell_type_ontology_term_id\"]\n",
                                    "    385     )  # ), 'sex_ontology_term_id', \"disease_ontology_term_id\"])\n",
                                    "\n",
                                    "> /home/ml4ig1/Documents code/scPRINT/scprint/tasks/cell_emb.py(384)default_benchmark()\n",
                                    "    382     pdb.set_trace()\n",
                                    "    383     embedder = Embedder(\n",
                                    "--> 384         model, pred_embedding=[\"cell_type_ontology_term_id\"]\n",
                                    "    385     )  # ), 'sex_ontology_term_id', \"disease_ontology_term_id\"])\n",
                                    "    386     embed_adata, metrics = embedder(adata.copy())\n",
                                    "\n",
                                    "> /home/ml4ig1/Documents code/scPRINT/scprint/tasks/cell_emb.py(383)default_benchmark()\n",
                                    "    381     import pdb\n",
                                    "    382     pdb.set_trace()\n",
                                    "--> 383     embedder = Embedder(\n",
                                    "    384         model, pred_embedding=[\"cell_type_ontology_term_id\"]\n",
                                    "    385     )  # ), 'sex_ontology_term_id', \"disease_ontology_term_id\"])\n",
                                    "\n",
                                    "--Call--\n",
                                    "> /home/ml4ig1/Documents code/scPRINT/scprint/tasks/cell_emb.py(30)__init__()\n",
                                    "     28 \n",
                                    "     29 class Embedder:\n",
                                    "---> 30     def __init__(\n",
                                    "     31         self,\n",
                                    "     32         model: torch.nn.Module,\n",
                                    "\n",
                                    "> /home/ml4ig1/Documents code/scPRINT/scprint/tasks/cell_emb.py(69)__init__()\n",
                                    "     67             output_expression (str, optional): The type of output expression to be used. Can be one of \"all\", \"sample\", \"none\". Defaults to \"sample\".\n",
                                    "     68         \"\"\"\n",
                                    "---> 69         self.model = model\n",
                                    "     70         self.batch_size = batch_size\n",
                                    "     71         self.num_workers = num_workers\n",
                                    "\n",
                                    "> /home/ml4ig1/Documents code/scPRINT/scprint/tasks/cell_emb.py(70)__init__()\n",
                                    "     68         \"\"\"\n",
                                    "     69         self.model = model\n",
                                    "---> 70         self.batch_size = batch_size\n",
                                    "     71         self.num_workers = num_workers\n",
                                    "     72         self.how = how\n",
                                    "\n",
                                    "> /home/ml4ig1/Documents code/scPRINT/scprint/tasks/cell_emb.py(71)__init__()\n",
                                    "     69         self.model = model\n",
                                    "     70         self.batch_size = batch_size\n",
                                    "---> 71         self.num_workers = num_workers\n",
                                    "     72         self.how = how\n",
                                    "     73         self.max_len = max_len\n",
                                    "\n",
                                    "> /home/ml4ig1/Documents code/scPRINT/scprint/tasks/cell_emb.py(72)__init__()\n",
                                    "     70         self.batch_size = batch_size\n",
                                    "     71         self.num_workers = num_workers\n",
                                    "---> 72         self.how = how\n",
                                    "     73         self.max_len = max_len\n",
                                    "     74         self.add_zero_genes = add_zero_genes\n",
                                    "\n",
                                    "> /home/ml4ig1/Documents code/scPRINT/scprint/tasks/cell_emb.py(73)__init__()\n",
                                    "     71         self.num_workers = num_workers\n",
                                    "     72         self.how = how\n",
                                    "---> 73         self.max_len = max_len\n",
                                    "     74         self.add_zero_genes = add_zero_genes\n",
                                    "     75         self.organisms = organisms\n",
                                    "\n",
                                    "> /home/ml4ig1/Documents code/scPRINT/scprint/tasks/cell_emb.py(74)__init__()\n",
                                    "     72         self.how = how\n",
                                    "     73         self.max_len = max_len\n",
                                    "---> 74         self.add_zero_genes = add_zero_genes\n",
                                    "     75         self.organisms = organisms\n",
                                    "     76         self.pred_embedding = pred_embedding\n",
                                    "\n",
                                    "> /home/ml4ig1/Documents code/scPRINT/scprint/tasks/cell_emb.py(75)__init__()\n",
                                    "     73         self.max_len = max_len\n",
                                    "     74         self.add_zero_genes = add_zero_genes\n",
                                    "---> 75         self.organisms = organisms\n",
                                    "     76         self.pred_embedding = pred_embedding\n",
                                    "     77         self.model_name = model_name\n",
                                    "\n",
                                    "> /home/ml4ig1/Documents code/scPRINT/scprint/tasks/cell_emb.py(76)__init__()\n",
                                    "     74         self.add_zero_genes = add_zero_genes\n",
                                    "     75         self.organisms = organisms\n",
                                    "---> 76         self.pred_embedding = pred_embedding\n",
                                    "     77         self.model_name = model_name\n",
                                    "     78         self.max_cells = max_cells\n",
                                    "\n",
                                    "> /home/ml4ig1/Documents code/scPRINT/scprint/tasks/cell_emb.py(77)__init__()\n",
                                    "     75         self.organisms = organisms\n",
                                    "     76         self.pred_embedding = pred_embedding\n",
                                    "---> 77         self.model_name = model_name\n",
                                    "     78         self.max_cells = max_cells\n",
                                    "     79         self.precision = precision\n",
                                    "\n",
                                    "> /home/ml4ig1/Documents code/scPRINT/scprint/tasks/cell_emb.py(78)__init__()\n",
                                    "     76         self.pred_embedding = pred_embedding\n",
                                    "     77         self.model_name = model_name\n",
                                    "---> 78         self.max_cells = max_cells\n",
                                    "     79         self.precision = precision\n",
                                    "     80         self.doplot = doplot\n",
                                    "\n",
                                    "> /home/ml4ig1/Documents code/scPRINT/scprint/tasks/cell_emb.py(79)__init__()\n",
                                    "     77         self.model_name = model_name\n",
                                    "     78         self.max_cells = max_cells\n",
                                    "---> 79         self.precision = precision\n",
                                    "     80         self.doplot = doplot\n",
                                    "     81         self.model.doplot = doplot\n",
                                    "\n",
                                    "> /home/ml4ig1/Documents code/scPRINT/scprint/tasks/cell_emb.py(80)__init__()\n",
                                    "     78         self.max_cells = max_cells\n",
                                    "     79         self.precision = precision\n",
                                    "---> 80         self.doplot = doplot\n",
                                    "     81         self.model.doplot = doplot\n",
                                    "     82         self.trainer = Trainer(precision=precision)\n",
                                    "\n",
                                    "> /home/ml4ig1/Documents code/scPRINT/scprint/tasks/cell_emb.py(81)__init__()\n",
                                    "     79         self.precision = precision\n",
                                    "     80         self.doplot = doplot\n",
                                    "---> 81         self.model.doplot = doplot\n",
                                    "     82         self.trainer = Trainer(precision=precision)\n",
                                    "     83         # subset_hvg=1000, use_layer='counts', is_symbol=True,force_preprocess=True, skip_validate=True)\n",
                                    "\n",
                                    "> /home/ml4ig1/Documents code/scPRINT/scprint/tasks/cell_emb.py(82)__init__()\n",
                                    "     80         self.doplot = doplot\n",
                                    "     81         self.model.doplot = doplot\n",
                                    "---> 82         self.trainer = Trainer(precision=precision)\n",
                                    "     83         # subset_hvg=1000, use_layer='counts', is_symbol=True,force_preprocess=True, skip_validate=True)\n",
                                    "     84 \n",
                                    "\n"
                              ]
                        },
                        {
                              "name": "stderr",
                              "output_type": "stream",
                              "text": [
                                    "Using 16bit Automatic Mixed Precision (AMP)\n",
                                    "GPU available: True (cuda), used: True\n",
                                    "TPU available: False, using: 0 TPU cores\n",
                                    "IPU available: False, using: 0 IPUs\n",
                                    "HPU available: False, using: 0 HPUs\n"
                              ]
                        },
                        {
                              "name": "stdout",
                              "output_type": "stream",
                              "text": [
                                    "--Return--\n",
                                    "None\n",
                                    "> /home/ml4ig1/Documents code/scPRINT/scprint/tasks/cell_emb.py(82)__init__()\n",
                                    "     80         self.doplot = doplot\n",
                                    "     81         self.model.doplot = doplot\n",
                                    "---> 82         self.trainer = Trainer(precision=precision)\n",
                                    "     83         # subset_hvg=1000, use_layer='counts', is_symbol=True,force_preprocess=True, skip_validate=True)\n",
                                    "     84 \n",
                                    "\n",
                                    "> /home/ml4ig1/Documents code/scPRINT/scprint/tasks/cell_emb.py(386)default_benchmark()\n",
                                    "    384         model, pred_embedding=[\"cell_type_ontology_term_id\"]\n",
                                    "    385     )  # ), 'sex_ontology_term_id', \"disease_ontology_term_id\"])\n",
                                    "--> 386     embed_adata, metrics = embedder(adata.copy())\n",
                                    "    387     # if do_class and default_dataset == \"lung\":\n",
                                    "    388 \n",
                                    "\n",
                                    "IndexError: index 0 is out of bounds for axis 0 with size 0\n",
                                    "> /home/ml4ig1/Documents code/scPRINT/scprint/tasks/cell_emb.py(386)default_benchmark()\n",
                                    "    384         model, pred_embedding=[\"cell_type_ontology_term_id\"]\n",
                                    "    385     )  # ), 'sex_ontology_term_id', \"disease_ontology_term_id\"])\n",
                                    "--> 386     embed_adata, metrics = embedder(adata.copy())\n",
                                    "    387     # if do_class and default_dataset == \"lung\":\n",
                                    "    388 \n",
                                    "\n",
                                    "--Return--\n",
                                    "None\n",
                                    "> /home/ml4ig1/Documents code/scPRINT/scprint/tasks/cell_emb.py(386)default_benchmark()\n",
                                    "    384         model, pred_embedding=[\"cell_type_ontology_term_id\"]\n",
                                    "    385     )  # ), 'sex_ontology_term_id', \"disease_ontology_term_id\"])\n",
                                    "--> 386     embed_adata, metrics = embedder(adata.copy())\n",
                                    "    387     # if do_class and default_dataset == \"lung\":\n",
                                    "    388 \n",
                                    "\n"
                              ]
                        },
                        {
                              "ename": "IndexError",
                              "evalue": "index 0 is out of bounds for axis 0 with size 0",
                              "output_type": "error",
                              "traceback": [
                                    "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                                    "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
                                    "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdatamodule\u001b[49m\u001b[43m)\u001b[49m\n",
                                    "File \u001b[0;32m~/miniconda3/envs/scprint/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:532\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    530\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39m_lightning_module \u001b[38;5;241m=\u001b[39m model\n\u001b[1;32m    531\u001b[0m _verify_strategy_supports_compile(model, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrategy)\n\u001b[0;32m--> 532\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    533\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[1;32m    534\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
                                    "File \u001b[0;32m~/miniconda3/envs/scprint/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py:43\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     42\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39mtrainer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 43\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n\u001b[1;32m     46\u001b[0m     _call_teardown_hook(trainer)\n",
                                    "File \u001b[0;32m~/miniconda3/envs/scprint/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:571\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    561\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_connector\u001b[38;5;241m.\u001b[39mattach_data(\n\u001b[1;32m    562\u001b[0m     model, train_dataloaders\u001b[38;5;241m=\u001b[39mtrain_dataloaders, val_dataloaders\u001b[38;5;241m=\u001b[39mval_dataloaders, datamodule\u001b[38;5;241m=\u001b[39mdatamodule\n\u001b[1;32m    563\u001b[0m )\n\u001b[1;32m    565\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39m_select_ckpt_path(\n\u001b[1;32m    566\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn,\n\u001b[1;32m    567\u001b[0m     ckpt_path,\n\u001b[1;32m    568\u001b[0m     model_provided\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    569\u001b[0m     model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    570\u001b[0m )\n\u001b[0;32m--> 571\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    573\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstopped\n\u001b[1;32m    574\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
                                    "File \u001b[0;32m~/miniconda3/envs/scprint/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:980\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m    975\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_signal_connector\u001b[38;5;241m.\u001b[39mregister_signal_handlers()\n\u001b[1;32m    977\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    978\u001b[0m \u001b[38;5;66;03m# RUN THE TRAINER\u001b[39;00m\n\u001b[1;32m    979\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m--> 980\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    982\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    983\u001b[0m \u001b[38;5;66;03m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[1;32m    984\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    985\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: trainer tearing down\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
                                    "File \u001b[0;32m~/miniconda3/envs/scprint/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:1023\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1021\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_sanity_check()\n\u001b[1;32m   1022\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mset_detect_anomaly(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_detect_anomaly):\n\u001b[0;32m-> 1023\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1024\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1025\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnexpected state \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
                                    "File \u001b[0;32m~/miniconda3/envs/scprint/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py:202\u001b[0m, in \u001b[0;36m_FitLoop.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_start()\n\u001b[0;32m--> 202\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_end()\n\u001b[1;32m    204\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_restarting \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
                                    "File \u001b[0;32m~/miniconda3/envs/scprint/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py:355\u001b[0m, in \u001b[0;36m_FitLoop.advance\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_fetcher\u001b[38;5;241m.\u001b[39msetup(combined_loader)\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_training_epoch\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 355\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepoch_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_fetcher\u001b[49m\u001b[43m)\u001b[49m\n",
                                    "File \u001b[0;32m~/miniconda3/envs/scprint/lib/python3.10/site-packages/lightning/pytorch/loops/training_epoch_loop.py:134\u001b[0m, in \u001b[0;36m_TrainingEpochLoop.run\u001b[0;34m(self, data_fetcher)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madvance(data_fetcher)\n\u001b[0;32m--> 134\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_advance_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    135\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_restarting \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n",
                                    "File \u001b[0;32m~/miniconda3/envs/scprint/lib/python3.10/site-packages/lightning/pytorch/loops/training_epoch_loop.py:249\u001b[0m, in \u001b[0;36m_TrainingEpochLoop.on_advance_end\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m should_check_val:\n\u001b[1;32m    248\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mvalidating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 249\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mval_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    250\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    252\u001b[0m \u001b[38;5;66;03m# update plateau LR scheduler after metrics are logged\u001b[39;00m\n",
                                    "File \u001b[0;32m~/miniconda3/envs/scprint/lib/python3.10/site-packages/lightning/pytorch/loops/utilities.py:181\u001b[0m, in \u001b[0;36m_no_grad_context.<locals>._decorator\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    179\u001b[0m     context_manager \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mno_grad\n\u001b[1;32m    180\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context_manager():\n\u001b[0;32m--> 181\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloop_run\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
                                    "File \u001b[0;32m~/miniconda3/envs/scprint/lib/python3.10/site-packages/lightning/pytorch/loops/evaluation_loop.py:122\u001b[0m, in \u001b[0;36m_EvaluationLoop.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_restarting \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_store_dataloader_outputs()\n\u001b[0;32m--> 122\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_run_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
                                    "File \u001b[0;32m~/miniconda3/envs/scprint/lib/python3.10/site-packages/lightning/pytorch/loops/evaluation_loop.py:244\u001b[0m, in \u001b[0;36m_EvaluationLoop.on_run_end\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39m_logger_connector\u001b[38;5;241m.\u001b[39m_evaluation_epoch_end()\n\u001b[1;32m    243\u001b[0m \u001b[38;5;66;03m# hook\u001b[39;00m\n\u001b[0;32m--> 244\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_on_evaluation_epoch_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    246\u001b[0m logged_outputs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_logged_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_logged_outputs, []  \u001b[38;5;66;03m# free memory\u001b[39;00m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;66;03m# include any logged outputs on epoch_end\u001b[39;00m\n",
                                    "File \u001b[0;32m~/miniconda3/envs/scprint/lib/python3.10/site-packages/lightning/pytorch/loops/evaluation_loop.py:326\u001b[0m, in \u001b[0;36m_EvaluationLoop._on_evaluation_epoch_end\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    324\u001b[0m hook_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_test_epoch_end\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mtesting \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_validation_epoch_end\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    325\u001b[0m call\u001b[38;5;241m.\u001b[39m_call_callback_hooks(trainer, hook_name)\n\u001b[0;32m--> 326\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_lightning_module_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhook_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    328\u001b[0m trainer\u001b[38;5;241m.\u001b[39m_logger_connector\u001b[38;5;241m.\u001b[39mon_epoch_end()\n",
                                    "File \u001b[0;32m~/miniconda3/envs/scprint/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py:146\u001b[0m, in \u001b[0;36m_call_lightning_module_hook\u001b[0;34m(trainer, hook_name, pl_module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    143\u001b[0m pl_module\u001b[38;5;241m.\u001b[39m_current_fx_name \u001b[38;5;241m=\u001b[39m hook_name\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[LightningModule]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpl_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 146\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n\u001b[1;32m    149\u001b[0m pl_module\u001b[38;5;241m.\u001b[39m_current_fx_name \u001b[38;5;241m=\u001b[39m prev_fx_name\n",
                                    "File \u001b[0;32m~/Documents code/scPRINT/scprint/model/model.py:1067\u001b[0m, in \u001b[0;36mscPrint.on_validation_epoch_end\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1065\u001b[0m     \u001b[38;5;66;03m#run the test function on specific dataset\u001b[39;00m\n\u001b[1;32m   1066\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog_adata(gtclass\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfo, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidation_part_\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcounter))\n\u001b[0;32m-> 1067\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
                                    "File \u001b[0;32m~/Documents code/scPRINT/scprint/model/model.py:1071\u001b[0m, in \u001b[0;36mscPrint.test\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1069\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtest\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   1070\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m-> 1071\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43membbed_task\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdefault_benchmark\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlung\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdo_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcoarse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   1072\u001b[0m     metrics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124memb_lung\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m res\n\u001b[1;32m   1074\u001b[0m     res \u001b[38;5;241m=\u001b[39m embbed_task\u001b[38;5;241m.\u001b[39mdefault_benchmark(\u001b[38;5;28mself\u001b[39m, default_dataset\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpancreas\u001b[39m\u001b[38;5;124m\"\u001b[39m, do_class\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, coarse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
                                    "File \u001b[0;32m~/Documents code/scPRINT/scprint/tasks/cell_emb.py:386\u001b[0m, in \u001b[0;36mdefault_benchmark\u001b[0;34m(model, default_dataset, do_class, coarse)\u001b[0m\n\u001b[1;32m    382\u001b[0m pdb\u001b[38;5;241m.\u001b[39mset_trace()\n\u001b[1;32m    383\u001b[0m embedder \u001b[38;5;241m=\u001b[39m Embedder(\n\u001b[1;32m    384\u001b[0m     model, pred_embedding\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type_ontology_term_id\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    385\u001b[0m )\n\u001b[0;32m--> 386\u001b[0m embed_adata, metrics \u001b[38;5;241m=\u001b[39m \u001b[43membedder\u001b[49m\u001b[43m(\u001b[49m\u001b[43madata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    388\u001b[0m bm \u001b[38;5;241m=\u001b[39m Benchmarker(\n\u001b[1;32m    389\u001b[0m     embed_adata,\n\u001b[1;32m    390\u001b[0m     batch_key\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtech\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m default_dataset \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpancreas\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    393\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m6\u001b[39m,\n\u001b[1;32m    394\u001b[0m )\n\u001b[1;32m    395\u001b[0m bm\u001b[38;5;241m.\u001b[39mbenchmark()\n",
                                    "File \u001b[0;32m~/Documents code/scPRINT/scprint/tasks/cell_emb.py:106\u001b[0m, in \u001b[0;36mEmbedder.__call__\u001b[0;34m(self, adata, cache, output_expression)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;66;03m# Add at least the organism you are working with\u001b[39;00m\n\u001b[1;32m    104\u001b[0m adataset \u001b[38;5;241m=\u001b[39m SimpleAnnDataset(\n\u001b[1;32m    105\u001b[0m     adata, obs_to_output\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124morganism_ontology_term_id\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m--> 106\u001b[0m col \u001b[38;5;241m=\u001b[39m \u001b[43mCollator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    107\u001b[0m \u001b[43m    \u001b[49m\u001b[43morganisms\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43morganisms\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalid_genes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    109\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_len\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[43m    \u001b[49m\u001b[43madd_zero_genes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_zero_genes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    113\u001b[0m dataloader \u001b[38;5;241m=\u001b[39m DataLoader(\n\u001b[1;32m    114\u001b[0m     adataset,\n\u001b[1;32m    115\u001b[0m     collate_fn\u001b[38;5;241m=\u001b[39mcol,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    118\u001b[0m     shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    119\u001b[0m )\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mpred_log_adata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
                                    "File \u001b[0;32m~/Documents code/scPRINT/scDataLoader/scdataloader/collator.py:83\u001b[0m, in \u001b[0;36mCollator.__init__\u001b[0;34m(self, organisms, how, org_to_id, valid_genes, max_len, add_zero_genes, logp1, norm_to, n_bins, tp_name, organism_name, class_names, genelist, downsample, save_output)\u001b[0m\n\u001b[1;32m     81\u001b[0m tot \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenedf[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenedf\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39misin(valid_genes)]\n\u001b[1;32m     82\u001b[0m org \u001b[38;5;241m=\u001b[39m org_to_id[organism] \u001b[38;5;28;01mif\u001b[39;00m org_to_id \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m organism\n\u001b[0;32m---> 83\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstart_idx\u001b[38;5;241m.\u001b[39mupdate({org: \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtot\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43morganism\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43morganism\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m})\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(valid_genes) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     85\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccepted_genes\u001b[38;5;241m.\u001b[39mupdate({org: ogenedf\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39misin(valid_genes)})\n",
                                    "\u001b[0;31mIndexError\u001b[0m: index 0 is out of bounds for axis 0 with size 0"
                              ]
                        }
                  ],
                  "source": [
                        "trainer.fit(model, dat\n",
                        "amodule=datamodule)"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": null,
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "expression[:100]"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": null,
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "weirdly, when input expression is set to 0 and pi is set to 1000. I get a loss of 0\n",
                        "when input expression is set to some set of values and pi=-10, disp=max, mean=input, I get 0.479, decreasing pi doesn't help, making it higher, makes it worse, max of disp is ~3M afterward it increases back (likely due to some overflow??). I am guessing that it would need to be set to infinity for it to work. might be better to use dispersion instead of inverse dispersion?\n",
                        "\n",
                        "all things equal, if disp is set to 2_700_000, I get loss tensor(3.8694, device='cuda:0')\n",
                        "if disp is 2_700_000+1 -> tensor(0.1994, device='cuda:0')\n",
                        "\n",
                        "basically it seems that at too high values or at too low values we get strong instabilities that are exacerbated by the fact that we are in float16.\n",
                        "could it also be because of the espilon? nope\n",
                        "\n",
                        "-> why doesn't my model go to this low loss value??\n",
                        "\n"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": null,
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "1. there seems to be an in-between value of disp that makes sense given the expression data\n",
                        "2. "
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": null,
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "import torch.nn.functional as F"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": null,
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "F.mse_loss(expression, expression, reduction=\"mean\")"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": null,
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "loss.nb(\n",
                        "    theta=disp,\n",
                        "    mu=expression,\n",
                        "    target=expression,\n",
                        ")"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": null,
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "loss.zinb(\n",
                        "    theta=output[\"disp\"],\n",
                        "    pi=output[\"zero_logits\"],\n",
                        "    mu=output[\"mean\"],\n",
                        "    target=expression,\n",
                        ")"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": null,
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "loss.zinb(\n",
                        "    theta=output[\"disp\"] + 10000,\n",
                        "    pi=output[\"zero_logits\"]-3,\n",
                        "    mu=expression,\n",
                        "    target=expression,\n",
                        ")"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": null,
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "loss.nb(\n",
                        "    theta=output[\"disp\"],\n",
                        "    mu=output[\"mean\"],\n",
                        "    target=expression,\n",
                        ").mean()"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": null,
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "expr = expression.clone()\n",
                        "expr[:,-20:] = 0\n",
                        "expr[:,:20] +=1"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": null,
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "loss.zinb(\n",
                        "    theta=disp,\n",
                        "    pi=pi,\n",
                        "    mu=output[\"mean\"],\n",
                        "    target=expression,\n",
                        ")"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": null,
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "loss.zinb(\n",
                        "    theta=disp,\n",
                        "    pi=pi,\n",
                        "    mu=1e4*output[\"mean\"]/expression.sum(),\n",
                        "    target=1e4*expression/expression.sum(),\n",
                        ")"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": null,
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "loss.zinb(\n",
                        "    theta=disp,\n",
                        "    pi=pi,\n",
                        "    mu=1e4*expr/expression.sum(),\n",
                        "    target=1e4*expression/expression.sum(),\n",
                        ")"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": null,
                  "metadata": {},
                  "outputs": [],
                  "source": []
            },
            {
                  "cell_type": "code",
                  "execution_count": null,
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "exp(15)"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": null,
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "disp = torch.zeros_like(output[\"disp\"])\n",
                        "pi = torch.zeros_like(output[\"disp\"]) - 10"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": null,
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "# why if it is the inverse dispersion? does setting it to 3_000_000 works but not 10_000_000?\n",
                        "# maybe some overflow??"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": null,
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "loss.zinb(\n",
                        "    theta=disp,\n",
                        "    pi=pi,\n",
                        "    mu=output[\"mean\"],\n",
                        "    target=expression,\n",
                        ")"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": null,
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "loss.zinb(\n",
                        "    theta=disp,\n",
                        "    pi=pi,\n",
                        "    mu=expression,\n",
                        "    target=expression,\n",
                        ")"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": null,
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "loss.zinb(\n",
                        "    theta=output[\"disp\"],\n",
                        "    pi=output[\"zero_logits\"],\n",
                        "    mu=expression,\n",
                        "    target=expression,\n",
                        ")"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": null,
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "loss.zinb(\n",
                        "    theta=disp,\n",
                        "    pi=pi,\n",
                        "    mu=expression,\n",
                        "    target=expression,\n",
                        ")"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": null,
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "%reload_ext tensorboard\n",
                        "%tensorboard --logdir=\"../data/tensorboard\""
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": null,
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "# wandb_logger.finalize(status=\"aborted\")\n",
                        "torch.cuda.empty_cache()"
                  ]
            }
      ],
      "metadata": {
            "kernelspec": {
                  "display_name": "scprint",
                  "language": "python",
                  "name": "python3"
            },
            "language_info": {
                  "codemirror_mode": {
                        "name": "ipython",
                        "version": 3
                  },
                  "file_extension": ".py",
                  "mimetype": "text/x-python",
                  "name": "python",
                  "nbconvert_exporter": "python",
                  "pygments_lexer": "ipython3",
                  "version": "3.10.0"
            }
      },
      "nbformat": 4,
      "nbformat_minor": 2
}
