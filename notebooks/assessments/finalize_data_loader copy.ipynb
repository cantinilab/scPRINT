{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# one-off preparation of the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ saved: User(uid='a3keNAVX', handle='jkobject', updated_at=2023-11-22 09:47:07 UTC)\n",
      "‚úÖ saved: Storage(uid='GZgLW1TI', root='/home/ml4ig1/scprint', type='local', updated_at=2023-11-22 09:47:07 UTC, created_by_id=1)\n",
      "üí° loaded instance: jkobject/scprint\n",
      "üí° did not register local instance on hub\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!lamin init --storage ~/scprint --schema bionty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üí° lamindb instance: jkobject/scprint\n"
     ]
    }
   ],
   "source": [
    "from scprint import data_utils\n",
    "\n",
    "import lamindb as ln\n",
    "import lnschema_bionty as lb\n",
    "import pandas as pd\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb.settings.organism = \"human\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prepare lamin database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ln.File.filter())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap_external>:672: ResourceWarning: unclosed <ssl.SSLSocket fd=81, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('10.20.53.10', 47416), raddr=('104.18.38.107', 443)>\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset(uid='OirHTWDrudY2TYltvIX1', name='cellxgene-census', version='2023-07-25', hash='pEJ9uvIeTLvHkZW2TBT5', visibility=1, updated_at=2023-11-28 21:46:40 UTC, transform_id=11, run_id=16, created_by_id=1)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cx_dataset = ln.Dataset.using(\"laminlabs/cellxgene\").one()\n",
    "cx_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùó no run & transform get linked, consider passing a `run` or calling ln.track()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "850"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cx_dataset.files.all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùó no run & transform get linked, consider passing a `run` or calling ln.track()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùó record with EtxwAoHUyGTdCB8swqaf already exists on default database: File(uid='EtxwAoHUyGTdCB8swqaf', key='cell-census/2023-07-25/h5ads/0738f538-ff2f-4346-b2eb-72704c291188.h5ad', suffix='.h5ad', accessor='AnnData', description='High Resolution Slide-seqV2 Spatial Transcriptomics Enables Discovery of Disease-Specific Cell Neighborhoods and Pathways', size=12110480, hash='8PORLeHJm9wYZ5MUc4AlSw-2', hash_type='md5-n', visibility=1, key_is_virtual=False, updated_at=2023-11-28 22:44:40 UTC, storage_id=2, transform_id=11, run_id=16, created_by_id=1)\n",
      "File cell-census/2023-07-25/h5ads/0738f538-ff2f-4346-b2eb-72704c291188.h5ad already exists in storage\n",
      "‚ùó no run & transform get linked, consider passing a `run` or calling ln.track()\n",
      "File cell-census/2023-07-25/h5ads/07428d73-fdea-4bd4-a801-94b00c4d961c.h5ad already exists in storage\n",
      "‚ùó no run & transform get linked, consider passing a `run` or calling ln.track()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ml4ig1/miniconda3/envs/scprint/lib/python3.10/asyncio/sslproto.py:320: ResourceWarning: unclosed transport <asyncio.sslproto._SSLProtocolTransport object at 0x7f8b49dda980>\n",
      "  _warn(f\"unclosed transport {self!r}\", ResourceWarning, source=self)\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File cell-census/2023-07-25/h5ads/07854d9c-5375-4a9b-ac34-fa919d3c3686.h5ad already exists in storage\n",
      "‚ùó no run & transform get linked, consider passing a `run` or calling ln.track()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ml4ig1/miniconda3/envs/scprint/lib/python3.10/asyncio/sslproto.py:320: ResourceWarning: unclosed transport <asyncio.sslproto._SSLProtocolTransport object at 0x7f8b450b9420>\n",
      "  _warn(f\"unclosed transport {self!r}\", ResourceWarning, source=self)\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File cell-census/2023-07-25/h5ads/07b1d7c8-5c2e-42f7-9246-26f746cd6013.h5ad already exists in storage\n",
      "‚ùó no run & transform get linked, consider passing a `run` or calling ln.track()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ml4ig1/miniconda3/envs/scprint/lib/python3.10/asyncio/sslproto.py:320: ResourceWarning: unclosed transport <asyncio.sslproto._SSLProtocolTransport object at 0x7f8b49b798a0>\n",
      "  _warn(f\"unclosed transport {self!r}\", ResourceWarning, source=self)\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File cell-census/2023-07-25/h5ads/08e94873-c2a6-4f7d-ab72-aeaff3e3f929.h5ad already exists in storage\n",
      "‚ùó no run & transform get linked, consider passing a `run` or calling ln.track()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ml4ig1/miniconda3/envs/scprint/lib/python3.10/asyncio/sslproto.py:320: ResourceWarning: unclosed transport <asyncio.sslproto._SSLProtocolTransport object at 0x7f8b4514e200>\n",
      "  _warn(f\"unclosed transport {self!r}\", ResourceWarning, source=self)\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File cell-census/2023-07-25/h5ads/090da8ea-46e8-40df-bffc-1f78e1538d27.h5ad already exists in storage\n",
      "‚ùó no run & transform get linked, consider passing a `run` or calling ln.track()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ml4ig1/miniconda3/envs/scprint/lib/python3.10/asyncio/sslproto.py:320: ResourceWarning: unclosed transport <asyncio.sslproto._SSLProtocolTransport object at 0x7f8b47684b80>\n",
      "  _warn(f\"unclosed transport {self!r}\", ResourceWarning, source=self)\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File cell-census/2023-07-25/h5ads/095940cb-7422-4510-96e2-cbafd961eb88.h5ad already exists in storage\n",
      "‚ùó no run & transform get linked, consider passing a `run` or calling ln.track()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ml4ig1/miniconda3/envs/scprint/lib/python3.10/asyncio/sslproto.py:320: ResourceWarning: unclosed transport <asyncio.sslproto._SSLProtocolTransport object at 0x7f8b44f692a0>\n",
      "  _warn(f\"unclosed transport {self!r}\", ResourceWarning, source=self)\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File cell-census/2023-07-25/h5ads/0a21f80c-e7a3-465b-8aba-fdda2b4c36bc.h5ad already exists in storage\n",
      "‚ùó no run & transform get linked, consider passing a `run` or calling ln.track()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ml4ig1/miniconda3/envs/scprint/lib/python3.10/asyncio/sslproto.py:320: ResourceWarning: unclosed transport <asyncio.sslproto._SSLProtocolTransport object at 0x7f8b491f8ee0>\n",
      "  _warn(f\"unclosed transport {self!r}\", ResourceWarning, source=self)\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File cell-census/2023-07-25/h5ads/0ae96eac-ff08-4870-9bc3-cd12418af7e4.h5ad already exists in storage\n",
      "‚ùó no run & transform get linked, consider passing a `run` or calling ln.track()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ml4ig1/miniconda3/envs/scprint/lib/python3.10/asyncio/sslproto.py:320: ResourceWarning: unclosed transport <asyncio.sslproto._SSLProtocolTransport object at 0x7f8b450bb0a0>\n",
      "  _warn(f\"unclosed transport {self!r}\", ResourceWarning, source=self)\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File cell-census/2023-07-25/h5ads/0b4a15a7-4e9e-4555-9733-2423e5c66469.h5ad already exists in storage\n",
      "‚ùó no run & transform get linked, consider passing a `run` or calling ln.track()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ml4ig1/miniconda3/envs/scprint/lib/python3.10/asyncio/sslproto.py:320: ResourceWarning: unclosed transport <asyncio.sslproto._SSLProtocolTransport object at 0x7f8b49b7a0e0>\n",
      "  _warn(f\"unclosed transport {self!r}\", ResourceWarning, source=self)\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File cell-census/2023-07-25/h5ads/0b75c598-0893-4216-afe8-5414cab7739d.h5ad already exists in storage\n",
      "‚ùó no run & transform get linked, consider passing a `run` or calling ln.track()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ml4ig1/miniconda3/envs/scprint/lib/python3.10/asyncio/sslproto.py:320: ResourceWarning: unclosed transport <asyncio.sslproto._SSLProtocolTransport object at 0x7f8b49dda980>\n",
      "  _warn(f\"unclosed transport {self!r}\", ResourceWarning, source=self)\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File cell-census/2023-07-25/h5ads/0ba636a1-4754-4786-a8be-7ab3cf760fd6.h5ad already exists in storage\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mydataset = data_utils.load_dataset_local(lb, cx_dataset, \"~/scprint/\", name=\"cellxgene-local\", description=\"the full cellxgene database\", only=(21,200))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load some known ontology names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#you can also load it back\n",
    "mydataset = ln.Dataset.filter(name=\"cellxgene-local\").one()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39055600, 6)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cellxgene_census\n",
    "\n",
    "census = cellxgene_census.open_soma(census_version = \"latest\")\n",
    "val_to_get = ['self_reported_ethnicity_ontology_term_id', 'assay_ontology_term_id', 'development_stage_ontology_term_id', 'disease_ontology_term_id', 'tissue_ontology_term_id']\n",
    "df = census[\"census_data\"][\"homo_sapiens\"].obs.read(column_names=val_to_get, value_filter=\"is_primary_data == True\").concat().to_pandas()\n",
    "df2 = census[\"census_data\"][\"mus_musculus\"].obs.read(column_names=val_to_get, value_filter=\"is_primary_data == True\").concat().to_pandas()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùó now recursing through parents: this only happens once, but is much slower than bulk saving\n",
      "‚ùó now recursing through parents: this only happens once, but is much slower than bulk saving\n"
     ]
    }
   ],
   "source": [
    "data_utils.populate_my_ontology(lb=lb,\n",
    "    organisms=[\"NCBITaxon:10090\", \"NCBITaxon:9606\"],\n",
    "    sex=[\"PATO:0000384\", \"PATO:0000383\"],\n",
    "    ethnicities=df['self_reported_ethnicity_ontology_term_id'].unique().tolist(),\n",
    "    assays=list(set(df['assay_ontology_term_id'].unique()).union(df2['assay_ontology_term_id'].unique())) + ['EFO:0010961'],\n",
    "    tissues=list(set(df['tissue_ontology_term_id'].unique()).union(df2['tissue_ontology_term_id'].unique())),\n",
    "    # we load all possible diseases. makes it easier\n",
    "    #diseases=list(set(df['disease_ontology_term_id'].unique()).union(df2['disease_ontology_term_id'].unique())),\n",
    "    dev_stages=list(df['development_stage_ontology_term_id'].unique()),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùó now recursing through parents: this only happens once, but is much slower than bulk saving\n"
     ]
    }
   ],
   "source": [
    "import bionty as bt\n",
    "\n",
    "bionty_source_ds_mouse = lb.BiontySource.filter(entity=\"DevelopmentalStage\", organism=\"mouse\").one()\n",
    "records = lb.DevelopmentalStage.from_values(df2['development_stage_ontology_term_id'].unique().tolist(), field=lb.DevelopmentalStage.ontology_id, bionty_source=bionty_source_ds_mouse)\n",
    "ln.save(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "assay = ['EFO:0010961']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùó now recursing through parents: this only happens once, but is much slower than bulk saving\n"
     ]
    }
   ],
   "source": [
    "records = lb.ExperimentalFactor.from_values(assay, field=lb.ExperimentalFactor.ontology_id)\n",
    "ln.save(records)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## add some missing ontology names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scprint.dataset.utils import get_ancestry_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "additional_tissues = {\n",
    "    \"UBERON:0037144\": \"wall of heart\",\n",
    "    \"UBERON:0003929\": \"digestive tract epithelium\",\n",
    "    \"UBERON:0002020\": \"gray matter\",\n",
    "    \"UBERON:0000200\": \"gyrus\",\n",
    "    \"UBERON:0000101\": \"lobe of lung\",\n",
    "    \"UBERON:0001981\": \"blood vessel\",\n",
    "    \"UBERON:0001474\": \"bone element\",\n",
    "}\n",
    "\n",
    "additional_diseases = {\n",
    "    \"MONDO:0001106\": \"kidney failure\",\n",
    "    \"MONDO:0021166\": \"inflammatory disease\",\n",
    "    \"MONDO:0004992\": \"cancer\",\n",
    "    \"MONDO:0004994\": \"cardiomyopathy\",\n",
    "    \"MONDO:0700065\": \"trisomy\",\n",
    "    \"MONDO:0021042\": \"glioma\",\n",
    "    \"MONDO:0005265\": \"inflammatory bowel disease\",\n",
    "    \"MONDO:0005550\": \"infectious disease\",\n",
    "    \"MONDO:0005059\": \"leukemia\",\n",
    "}\n",
    "\n",
    "additional_assays = {\n",
    "    \"EFO:0010184\": \"Smart-like\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Did it using the code below to figure out things we might want to add etc.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping, anc, leafs = get_ancestry_mapping(df['tissue_ontology_term_id'].unique(), lb.Tissue.filter().df(include=[\"parents__ontology_id\"]).set_index(\"ontology_id\"))\n",
    "# getting only the leaves for which we don't have a parent\n",
    "leafs = list(leafs - set.union(*[mapping[val] for val in mapping.keys()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb.Tissue.search(list(leafs)[108], field=\"ontology_id\",return_queryset=True).first().view_parents()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scprint.dataset.preprocess import Preprocessor\n",
    "import scanpy as sc\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def additional_preprocess(adata):\n",
    "    adata.obs = adata.obs.replace({'self_reported_ethnicity_ontology_term_id':{\n",
    "        'multiethnic':'unknown',\n",
    "        'American':'unknown',\n",
    "        'Jewish Israeli': 'unknown',\n",
    "        'na':'unknown',\n",
    "    }}) #multi ethnic will have to get renamed\n",
    "    adata.obs['cell_culture'] = False\n",
    "    # if cell_type contains the word \"(cell culture)\" then it is a cell culture and we mark it as so and remove this from the cell type\n",
    "    loc = adata.obs['cell_type_ontology_term_id'].str.contains(\"(cell culture)\")\n",
    "    if loc.sum()>0:\n",
    "        adata.obs.loc[loc, 'cell_culture'] = True\n",
    "        adata.obs.loc[loc, 'cell_type_ontology_term_id'] = adata.obs.loc[loc, 'cell_type_ontology_term_id'].str.replace(\" (cell culture)\", \"\")\n",
    "    return adata\n",
    "\n",
    "def additional_postprocess(adata):\n",
    "    # define the \"up to\" 10 neighbors for each cells and add to obs\n",
    "    # compute neighbors\n",
    "    # need to be connectivities and same labels [cell type, assay, dataset, disease]\n",
    "    # define the \"neighbor\" up to 10(N) cells and add to obs\n",
    "    # define the \"next time point\" up to 5(M) cells and add to obs  # step 1: filter genes\n",
    "    sc.tl.diffmap(adata)\n",
    "    # create a meta group\n",
    "    adata.obs['dpt_group'] = adata.obs['leiden_1'].astype(str) + \"_\" + adata.obs['disease_ontology_term_id'].astype(str) + \"_\" + adata.obs['cell_type_ontology_term_id'].astype(str) + \"_\" + adata.obs['tissue_ontology_term_id'].astype(str) #+ \"_\" + adata.obs['dataset_id'].astype(str)\n",
    "\n",
    "    # if group is too small\n",
    "    okgroup = [i for i, j in adata.obs['dpt_group'].value_counts().items() if j>=10]\n",
    "    not_okgroup = [i for i, j in adata.obs['dpt_group'].value_counts().items() if j<3]\n",
    "    # set the group to empty\n",
    "    adata.obs.loc[adata.obs['dpt_group'].isin(not_okgroup), 'dpt_group'] = ''\n",
    "    adata.obs['heat_diff'] = np.nan\n",
    "    # for each group\n",
    "    for val in set(okgroup):\n",
    "        if val == '':\n",
    "            continue\n",
    "        # get the best root cell\n",
    "        eq = adata.obs.dpt_group==val\n",
    "        loc = np.where(eq)[0]\n",
    "\n",
    "        root_ixs = loc[adata.obsm[\"X_diffmap\"][eq, 0].argmin()]\n",
    "        adata.uns[\"iroot\"] = root_ixs\n",
    "        # compute the diffusion pseudo time from it\n",
    "        sc.tl.dpt(adata)\n",
    "        adata.obs.loc[eq, 'heat_diff'] = adata.obs.loc[eq, 'dpt_pseudotime']\n",
    "        adata.obs.drop(columns=['dpt_pseudotime'], inplace=True)\n",
    "\n",
    "    #sort so that the next time points are aligned for all groups\n",
    "    adata = adata[adata.obs.sort_values(['dpt_group','heat_diff']).index]\n",
    "    #to query N next time points we just get the N elements below and check they are in the group\n",
    "    # to query the N nearest neighbors we just get the N elements above and N below and check they are in the group\n",
    "    return adata\n",
    "\n",
    "do_preprocess = Preprocessor(lb, additional_postprocess=additional_postprocess, additional_preprocess=additional_preprocess)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùó no run & transform get linked, consider passing a `run` or calling ln.track()\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AnnData object with n_obs √ó n_vars = 69709 √ó 25701\n",
      "    obs: 'n_genes', 'sample', 'percent_mito', 'n_counts', 'batch', 'S_score', 'G2M_score', 'phase', 'scrublet_score', 'scrublet_cluster_score', 'zscore', 'bh_pval', 'bonf_pval', 'is_doublet', 'lineage', 'dataset', 'lineageSomatic', 'assay_ontology_term_id', 'cell_type_ontology_term_id', 'development_stage_ontology_term_id', 'disease_ontology_term_id', 'donor_id', 'is_primary_data', 'organism_ontology_term_id', 'self_reported_ethnicity_ontology_term_id', 'sex_ontology_term_id', 'suspension_type', 'tissue_ontology_term_id', 'cell_type', 'assay', 'disease', 'organism', 'sex', 'tissue', 'self_reported_ethnicity', 'development_stage'\n",
      "    var: 'gene_symbols', 'feature_is_filtered', 'feature_name', 'feature_reference', 'feature_biotype'\n",
      "    uns: 'default_embedding', 'lineageSomatic_colors', 'lineage_colors', 'schema_version', 'title'\n",
      "    obsm: 'X_scVI', 'X_umap'\n",
      "Removed 49 genes.\n",
      "Seeing 31596 outliers (45.33% of total dataset):\n",
      "‚ùó no run & transform get linked, consider passing a `run` or calling ln.track()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "... storing 'dpt_group' as categorical\n",
      "... storing 'gene_symbols' as categorical\n",
      "... storing 'symbol' as categorical\n",
      "... storing 'ncbi_gene_id' as categorical\n",
      "... storing 'biotype' as categorical\n",
      "... storing 'description' as categorical\n",
      "... storing 'synonyms' as categorical\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "AnnData object with n_obs √ó n_vars = 13623 √ó 59357\n",
      "    obs: 'roi', 'organism_ontology_term_id', 'disease_ontology_term_id', 'self_reported_ethnicity_ontology_term_id', 'assay_ontology_term_id', 'sex_ontology_term_id', 'development_stage_ontology_term_id', 'donor_id', 'suspension_type', 'dissection', 'fraction_mitochondrial', 'fraction_unspliced', 'cell_cycle_score', 'total_genes', 'total_UMIs', 'sample_id', 'supercluster_term', 'cluster_id', 'subcluster_id', 'cell_type_ontology_term_id', 'tissue_ontology_term_id', 'is_primary_data', 'cell_type', 'assay', 'disease', 'organism', 'sex', 'tissue', 'self_reported_ethnicity', 'development_stage'\n",
      "    var: 'Biotype', 'Chromosome', 'End', 'Gene', 'Start', 'feature_is_filtered', 'feature_name', 'feature_reference', 'feature_biotype'\n",
      "    uns: 'batch_condition', 'schema_version', 'title'\n",
      "    obsm: 'X_UMAP', 'X_tSNE'\n",
      "Removed 128 genes.\n",
      "Seeing 8587 outliers (63.03% of total dataset):\n",
      "‚ùó no run & transform get linked, consider passing a `run` or calling ln.track()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "... storing 'dpt_group' as categorical\n",
      "... storing 'symbol' as categorical\n",
      "... storing 'ncbi_gene_id' as categorical\n",
      "... storing 'biotype' as categorical\n",
      "... storing 'description' as categorical\n",
      "... storing 'synonyms' as categorical\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "AnnData object with n_obs √ó n_vars = 21181 √ó 19157\n",
      "    obs: 'assay_ontology_term_id', 'self_reported_ethnicity_ontology_term_id', 'is_primary_data', 'organism_ontology_term_id', 'sample', 'tissue_ontology_term_id', 'disease_state', 'sex_ontology_term_id', 'genotype', 'development_stage_ontology_term_id', 'author_cell_type', 'cell_type_ontology_term_id', 'disease_ontology_term_id', 'donor_id', 'suspension_type', 'cell_type', 'assay', 'disease', 'organism', 'sex', 'tissue', 'self_reported_ethnicity', 'development_stage'\n",
      "    var: 'feature_is_filtered', 'feature_name', 'feature_reference', 'feature_biotype'\n",
      "    uns: 'schema_version', 'title'\n",
      "    obsm: 'X_spatial'\n",
      "Removed 38 genes.\n",
      "Seeing 374 outliers (3.52% of total dataset):\n",
      "‚ùó no run & transform get linked, consider passing a `run` or calling ln.track()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "... storing 'dpt_group' as categorical\n",
      "... storing 'symbol' as categorical\n",
      "... storing 'ncbi_gene_id' as categorical\n",
      "... storing 'biotype' as categorical\n",
      "... storing 'description' as categorical\n",
      "... storing 'synonyms' as categorical\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "AnnData object with n_obs √ó n_vars = 32900 √ó 21189\n",
      "    obs: 'assay_ontology_term_id', 'self_reported_ethnicity_ontology_term_id', 'is_primary_data', 'organism_ontology_term_id', 'sample', 'tissue_ontology_term_id', 'disease_state', 'sex_ontology_term_id', 'genotype', 'development_stage_ontology_term_id', 'author_cell_type', 'cell_type_ontology_term_id', 'disease_ontology_term_id', 'donor_id', 'suspension_type', 'cell_type', 'assay', 'disease', 'organism', 'sex', 'tissue', 'self_reported_ethnicity', 'development_stage'\n",
      "    var: 'feature_is_filtered', 'feature_name', 'feature_reference', 'feature_biotype'\n",
      "    uns: 'schema_version', 'title'\n",
      "    obsm: 'X_spatial'\n",
      "Removed 48 genes.\n",
      "Seeing 1110 outliers (4.61% of total dataset):\n",
      "‚ùó no run & transform get linked, consider passing a `run` or calling ln.track()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "... storing 'dpt_group' as categorical\n",
      "... storing 'symbol' as categorical\n",
      "... storing 'ncbi_gene_id' as categorical\n",
      "... storing 'biotype' as categorical\n",
      "... storing 'description' as categorical\n",
      "... storing 'synonyms' as categorical\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "AnnData object with n_obs √ó n_vars = 5729 √ó 30666\n",
      "    obs: 'organism_ontology_term_id', 'tissue_ontology_term_id', 'assay_ontology_term_id', 'disease_ontology_term_id', 'cell_type_ontology_term_id', 'self_reported_ethnicity_ontology_term_id', 'development_stage_ontology_term_id', 'sex_ontology_term_id', 'knockout', 'day', 'sample', 'annotation', 'is_primary_data', 'suspension_type', 'donor_id', 'cell_type', 'assay', 'disease', 'organism', 'sex', 'tissue', 'self_reported_ethnicity', 'development_stage'\n",
      "    var: 'gene_name', 'feature_is_filtered', 'feature_name', 'feature_reference', 'feature_biotype'\n",
      "    uns: 'batch_condition', 'schema_version', 'title'\n",
      "    obsm: 'X_umap'\n",
      "Dataset dropped because contains too many secondary cells\n",
      "5\n",
      "AnnData object with n_obs √ó n_vars = 16375 √ó 58604\n",
      "    obs: 'assay_ontology_term_id', 'donor_id', 'anatomical_information', 'n_counts_UMIs', 'n_genes', 'cell_ontology_class', 'free_annotation', 'manually_annotated', 'compartment', 'sex_ontology_term_id', 'disease_ontology_term_id', 'is_primary_data', 'organism_ontology_term_id', 'suspension_type', 'cell_type_ontology_term_id', 'tissue_ontology_term_id', 'development_stage_ontology_term_id', 'self_reported_ethnicity_ontology_term_id', 'cell_type', 'assay', 'disease', 'organism', 'sex', 'tissue', 'self_reported_ethnicity', 'development_stage'\n",
      "    var: 'feature_type', 'highly_variable', 'means', 'dispersions', 'dispersions_norm', 'mean', 'std', 'ensembl_version', 'feature_is_filtered', 'feature_name', 'feature_reference', 'feature_biotype'\n",
      "    uns: '_scvi', '_training_mode', 'assay_colors', 'cell_ontology_class_colors', 'dendrogram_cell_type_tissue', 'dendrogram_computational_compartment_assignment', 'dendrogram_consensus_prediction', 'dendrogram_tissue_cell_type', 'donor_id_colors', 'hvg', 'neighbors', 'schema_version', 'sex_colors', 'tissue_colors', 'title', 'umap'\n",
      "    obsm: 'X_pca', 'X_scvi', 'X_scvi_umap', 'X_umap'\n",
      "    obsp: 'connectivities', 'distances'\n",
      "Dataset dropped because contains too many secondary cells\n",
      "6\n",
      "AnnData object with n_obs √ó n_vars = 76592 √ó 33178\n",
      "    obs: 'nCount_RNA', 'nFeature_RNA', 'Location', 'PCW', 'Genotype', 'Pool', 'Collection.ID', 'Cluster', 'disease_ontology_term_id', 'assay_ontology_term_id', 'self_reported_ethnicity_ontology_term_id', 'cell_type_ontology_term_id', 'is_primary_data', 'organism_ontology_term_id', 'donor_id', 'development_stage_ontology_term_id', 'sex_ontology_term_id', 'tissue_ontology_term_id', 'suspension_type', 'cell_type', 'assay', 'disease', 'organism', 'sex', 'tissue', 'self_reported_ethnicity', 'development_stage'\n",
      "    var: 'feature_is_filtered', 'feature_name', 'feature_reference', 'feature_biotype'\n",
      "    uns: 'schema_version', 'title'\n",
      "    obsm: 'X_pca', 'X_umap'\n",
      "Removed 94 genes.\n",
      "Seeing 45696 outliers (59.66% of total dataset):\n",
      "‚ùó no run & transform get linked, consider passing a `run` or calling ln.track()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "... storing 'dpt_group' as categorical\n",
      "... storing 'symbol' as categorical\n",
      "... storing 'ncbi_gene_id' as categorical\n",
      "... storing 'biotype' as categorical\n",
      "... storing 'description' as categorical\n",
      "... storing 'synonyms' as categorical\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "AnnData object with n_obs √ó n_vars = 3083 √ó 16443\n",
      "    obs: 'n_counts', 'n_genes', 'percent.mt', 'Adipocyte', 'Cardiomyocyte', 'Endothelial', 'Fibroblast', 'Lymphoid', 'Mast', 'Myeloid', 'Neuronal', 'Pericyte', 'Cycling.cells', 'vSMCs', 'cell_type_original', 'assay_ontology_term_id', 'cell_type_ontology_term_id', 'development_stage_ontology_term_id', 'disease_ontology_term_id', 'self_reported_ethnicity_ontology_term_id', 'is_primary_data', 'organism_ontology_term_id', 'sex_ontology_term_id', 'tissue_ontology_term_id', 'donor_id', 'suspension_type', 'cell_type', 'assay', 'disease', 'organism', 'sex', 'tissue', 'self_reported_ethnicity', 'development_stage'\n",
      "    var: 'feature_is_filtered', 'feature_name', 'feature_reference', 'feature_biotype'\n",
      "    uns: 'X_approximate_distribution', 'default_embedding', 'schema_version', 'title'\n",
      "    obsm: 'X_pca', 'X_spatial', 'X_umap'\n",
      "Removed 37 genes.\n",
      "Seeing 1481 outliers (48.04% of total dataset):\n",
      "‚ùó no run & transform get linked, consider passing a `run` or calling ln.track()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "... storing 'dpt_group' as categorical\n",
      "... storing 'symbol' as categorical\n",
      "... storing 'ncbi_gene_id' as categorical\n",
      "... storing 'biotype' as categorical\n",
      "... storing 'description' as categorical\n",
      "... storing 'synonyms' as categorical\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "AnnData object with n_obs √ó n_vars = 11265 √ó 59357\n",
      "    obs: 'roi', 'organism_ontology_term_id', 'disease_ontology_term_id', 'self_reported_ethnicity_ontology_term_id', 'assay_ontology_term_id', 'sex_ontology_term_id', 'development_stage_ontology_term_id', 'donor_id', 'suspension_type', 'dissection', 'fraction_mitochondrial', 'fraction_unspliced', 'cell_cycle_score', 'total_genes', 'total_UMIs', 'sample_id', 'supercluster_term', 'cluster_id', 'subcluster_id', 'cell_type_ontology_term_id', 'tissue_ontology_term_id', 'is_primary_data', 'cell_type', 'assay', 'disease', 'organism', 'sex', 'tissue', 'self_reported_ethnicity', 'development_stage'\n",
      "    var: 'Biotype', 'Chromosome', 'End', 'Gene', 'Start', 'feature_is_filtered', 'feature_name', 'feature_reference', 'feature_biotype'\n",
      "    uns: 'batch_condition', 'schema_version', 'title'\n",
      "    obsm: 'X_UMAP', 'X_tSNE'\n",
      "Removed 128 genes.\n",
      "Seeing 6290 outliers (55.84% of total dataset):\n",
      "‚ùó no run & transform get linked, consider passing a `run` or calling ln.track()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "... storing 'dpt_group' as categorical\n",
      "... storing 'symbol' as categorical\n",
      "... storing 'ncbi_gene_id' as categorical\n",
      "... storing 'biotype' as categorical\n",
      "... storing 'description' as categorical\n",
      "... storing 'synonyms' as categorical\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùó no run & transform get linked, consider passing a `run` or calling ln.track()\n"
     ]
    }
   ],
   "source": [
    "preprocessed_dataset = do_preprocess(mydataset, start_at=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we have processed that many files\n",
    "len(ln.File.filter(version='2', description='preprocessed by scprint'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùó no run & transform get linked, consider passing a `run` or calling ln.track()\n"
     ]
    }
   ],
   "source": [
    "# I need to remake the dataset as it failed for some files and I had to restart at position 11\n",
    "name=\"preprocessed dataset\"\n",
    "description=\"preprocessed dataset using scprint\"\n",
    "dataset = ln.Dataset(ln.File.filter(version='2', description='preprocessed by scprint'), name=name, description=description)\n",
    "dataset.save()\n",
    "dataset.files.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gene embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "organism = lb.Organism.filter(ontology_id=\"NCBITaxon:9606\").one()\n",
    "genedf = lb.Gene.filter(organism_id=organism.id).df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = embed(genedf=genedf,\n",
    "    organism=\"homo_sapiens\",\n",
    "    cache=True,\n",
    "    fasta_path=\"/tmp/data/fasta/\",\n",
    "    embedding_size=1024,)\n",
    "embeddings.to_parquet('../../data/temp/embeddings.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = pd.read_parquet('../../data/temp/embeddings.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from scprint.dataset import Dataset\n",
    "from scprint.base import BaseDataLoader\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# OR directly load the dataset\n",
    "name=\"preprocessed dataset 2\"\n",
    "dataset = ln.Dataset.filter(name=name).one()\n",
    "dataset.files.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: drop tissue & dev stage until part or is taken in account\n",
    "\n",
    "hierarchical_labels = [\n",
    "    \"cell_type_ontology_term_id\",\n",
    "    #\"tissue_ontology_term_id\",\n",
    "    \"disease_ontology_term_id\",\n",
    "    #\"development_stage_ontology_term_id\",\n",
    "    \"assay_ontology_term_id\",\n",
    "    'self_reported_ethnicity_ontology_term_id',\n",
    "\n",
    "]\n",
    "\n",
    "labels_weighted_sampling = hierarchical_labels+[\n",
    "    'sex_ontology_term_id',\n",
    "]\n",
    "\n",
    "all_labels = labels_weighted_sampling+[\n",
    "    #'dataset_id',\n",
    "    #'cell_culture',\n",
    "    \"dpt_group\",\n",
    "    \"heat_diff\",\n",
    "    \"nnz\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cell_type_ontology_term_id': {'CL:1000849': 0,\n",
       "  'CL:0000003': 1,\n",
       "  'CL:0000653': 2,\n",
       "  'CL:0000740': 3,\n",
       "  'CL:1001111': 4,\n",
       "  'CL:0000097': 5,\n",
       "  'CL:1000838': 6,\n",
       "  'CL:0000878': 7,\n",
       "  'CL:0000128': 8,\n",
       "  'CL:0000057': 9,\n",
       "  'CL:0000604': 10,\n",
       "  'CL:0000763': 11,\n",
       "  'CL:0001082': 12,\n",
       "  'CL:0000644': 13,\n",
       "  'CL:1001432': 14,\n",
       "  'CL:0000669': 15,\n",
       "  'CL:0000164': 16,\n",
       "  'CL:0000095': 17,\n",
       "  'CL:0002548': 18,\n",
       "  'CL:0000115': 19,\n",
       "  'CL:0000988': 20,\n",
       "  'CL:0002453': 21,\n",
       "  'CL:0000006': 22,\n",
       "  'CL:0000186': 23,\n",
       "  'CL:0000706': 24,\n",
       "  'CL:0009011': 25,\n",
       "  'CL:0000099': 26,\n",
       "  'CL:0000573': 27,\n",
       "  'CL:0000127': 28,\n",
       "  'CL:0019018': 29,\n",
       "  'CL:0000542': 30,\n",
       "  'CL:0000738': 31,\n",
       "  'CL:1001431': 32,\n",
       "  'CL:0000561': 33,\n",
       "  'CL:0000636': 34,\n",
       "  'CL:0000750': 35,\n",
       "  'CL:0000192': 36,\n",
       "  'CL:0009017': 37,\n",
       "  'CL:0000125': 38,\n",
       "  'CL:0000077': 39,\n",
       "  'CL:1000768': 40,\n",
       "  'CL:0000359': 41,\n",
       "  'CL:0000838': 42,\n",
       "  'CL:0000749': 43,\n",
       "  'CL:0009016': 44,\n",
       "  'CL:0009099': 45,\n",
       "  'CL:1000909': 46,\n",
       "  'CL:0000136': 47,\n",
       "  'CL:0000065': 48,\n",
       "  'CL:0000129': 49,\n",
       "  'CL:0002504': 50,\n",
       "  'CL:0000235': 51,\n",
       "  'CL:0019031': 52,\n",
       "  'CL:0002563': 53,\n",
       "  'CL:0000131': 54,\n",
       "  'CL:0000514': 55,\n",
       "  'CL:0000677': 56,\n",
       "  'CL:0000650': 57,\n",
       "  'CL:1000692': 58,\n",
       "  'CL:0002319': 59,\n",
       "  'CL:1001106': 60,\n",
       "  'CL:0002088': 61,\n",
       "  'CL:0009012': 62,\n",
       "  'CL:0002138': 63,\n",
       "  'CL:0002573': 64,\n",
       "  'CL:0010008': 65,\n",
       "  'CL:0000584': 66,\n",
       "  'CL:0011026': 67,\n",
       "  'CL:0000513': 68,\n",
       "  'CL:0000540': 69,\n",
       "  'CL:0008015': 70},\n",
       " 'disease_ontology_term_id': {'MONDO:0005129': 0,\n",
       "  'MONDO:0005068': 1,\n",
       "  'PATO:0000461': 2},\n",
       " 'assay_ontology_term_id': {'EFO:0009922': 0,\n",
       "  'EFO:0009899': 1,\n",
       "  'EFO:0030062': 2,\n",
       "  'EFO:0010961': 3},\n",
       " 'self_reported_ethnicity_ontology_term_id': {'unknown': 0,\n",
       "  'HANCESTRO:0568': 1,\n",
       "  'HANCESTRO:0005': 2},\n",
       " 'sex_ontology_term_id': {'PATO:0000384': 0, 'PATO:0000383': 1}}"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdataset.mapped_dataset.encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùó no run & transform get linked, consider passing a `run` or calling ln.track()\n",
      "won't do any check but we recommend to have your dataset coming from local storage\n",
      "‚ùó no run & transform get linked, consider passing a `run` or calling ln.track()\n",
      "total dataset size is 6.428849595 Gb\n",
      "---\n",
      "‚ùó no run & transform get linked, consider passing a `run` or calling ln.track()\n",
      "total dataset size is 6.428849595 Gb\n",
      "---\n",
      "dataset contains:\n",
      "     221391 cells\n",
      "     33890 genes\n",
      "     8 labels\n",
      "     1 organisms\n",
      "dataset contains 82 classes to predict\n",
      "embedding size is 1024\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdataset = Dataset(dataset, genedf, gene_embedding=embeddings, organisms=['\"NCBITaxon:9606\"'], obs=all_labels, encode_obs=labels_weighted_sampling, map_hierarchy=hierarchical_labels, )\n",
    "mdataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùó no run & transform get linked, consider passing a `run` or calling ln.track()\n",
      "total dataset size is 6.428849595 Gb\n",
      "---\n",
      "dataset contains:\n",
      "     221391 cells\n",
      "     33890 genes\n",
      "     8 labels\n",
      "     1 organisms\n",
      "dataset contains 82 classes to predict\n",
      "embedding size is 1024\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = BaseDataLoader(mdataset, label_to_weight=labels_weighted_sampling, batch_size=4, num_workers=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44279"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64), tensor([63, 50, 48, 14]), tensor([2, 2, 2, 2]), tensor([0, 0, 0, 2]), tensor([2, 0, 2, 2]), tensor([0, 0, 0, 0]), ('21_PATO:0000461_CL:0002138_UBERON:0014455', '10_PATO:0000461_CL:0002504_UBERON:0002116', '17_PATO:0000461_CL:0000065_UBERON:0005290', '1_PATO:0000461_CL:1001432_UBERON:0001225'), tensor([0.0043, 0.0199, 0.0415, 0.0519], dtype=torch.float64), tensor([2798, 1834, 1206,  102])]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in dataloader:\n",
    "    print(i)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SIZE=2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    0, 46766, 46767,  ..., 10766, 13068,  9769],\n",
       "        [    0, 46769, 46770,  ..., 11313, 30666,  9769],\n",
       "        [    0, 46741, 46742,  ...,  2947,  3199,  9769],\n",
       "        [    0, 46736, 46737,  ..., 18649, 23180,  9769]])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argsort(i[0],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: none of them are raw counts!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([346.2074, 561.9386, 613.1605, 833.3333], dtype=torch.float64)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i[0][:,9769]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the N samples DONE\n",
    "# get the unseen info DONE\n",
    "# get the I most expressed genes, add randomly some unexpressed genes that are not unseen\n",
    "# map the genes to the embeddings DONE\n",
    "# create positions from counts (function)\n",
    "# add to embeddings\n",
    "# create / learn special tokens embeddings. <batch> <class> <library_size> <diffpseudotime>\n",
    "# other version, one token per class type <self_reported_ethnicity_ontology_term_id> <assay_ontology_term_id> <development_stage_ontology_term_id> <disease_ontology_term_id> <cell_type_ontology_term_id> <tissue_ontology_term_id> <sex_ontology_term_id>\n",
    "# define positions for these tokens\n",
    "# get all annotations and parental relations and convert to encoding\n",
    "# get the N nearest neighbors if any\n",
    "# get the 3 next time point if any\n",
    "    # do the same for the 3 next time points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scprint",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
