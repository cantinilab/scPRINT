{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10746ba7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b39090e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ml4ig1/Documents code/scPRINT/.venv/lib/python3.11/site-packages/louvain/__init__.py:54: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import get_distribution, DistributionNotFound\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mâ†’\u001b[0m connected lamindb: jkobject/scprint_v2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ml4ig1/Documents code/simpler_flash/src/simpler_flash/layer_norm.py:1044: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @custom_fwd\n",
      "/home/ml4ig1/Documents code/simpler_flash/src/simpler_flash/layer_norm.py:1107: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  @custom_bwd\n"
     ]
    }
   ],
   "source": [
    "import scanpy as sc\n",
    "from scprint import scPrint\n",
    "from scdataloader import Preprocessor\n",
    "from scdataloader.utils import load_genes\n",
    "import numpy as np\n",
    "import anndata as ad\n",
    "from huggingface_hub import hf_hub_download\n",
    "import lamindb as ln\n",
    "\n",
    "from scprint.tasks import Embedder\n",
    "from scprint.tasks.cell_emb import display_confusion_matrix\n",
    "import pandas as pd\n",
    "\n",
    "from scib_metrics.benchmark import Benchmarker, BioConservation, BatchCorrection\n",
    "from anndata import AnnData\n",
    "from scdataloader.utils import translate\n",
    "import bionty as bt\n",
    "from scprint.tasks.cell_emb import compute_classification\n",
    "\n",
    "from lightning.pytorch import Trainer\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "from scdataloader import SimpleAnnDataset, Collator, DataModule\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import lamindb as ln\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "import scipy.sparse\n",
    "\n",
    "torch.set_float32_matmul_precision(\"medium\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829c1ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_checkpoint_file = hf_hub_download(\n",
    "#    repo_id=\"jkobject/scPRINT\", filename=f\"v2-medium.ckpt\"\n",
    "# )\n",
    "# model_checkpoint_file = ../data/\n",
    "model_checkpoint_file = \"../../../1lzuxvg0.ckpt\"\n",
    "# w937u4o1.ckpt'\n",
    "# da6ao55o.ckpt # 649\n",
    "# 1lzuxvg0.ckpt # 677"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327b650f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gene position encoding has changed in the dataloader compared to last time, trying to revert\n",
      "FYI: scPrint is not attached to a `Trainer`.\n"
     ]
    }
   ],
   "source": [
    "model = scPrint.load_from_checkpoint(\n",
    "    model_checkpoint_file, precpt_gene_emb=None, attention=\"normal\"\n",
    ")\n",
    "model = model.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593d6235",
   "metadata": {},
   "outputs": [],
   "source": [
    "da = sc.read(\"./data/task_3_embed.h5ad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45447a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_to_val = {n: i for i, n in enumerate(set(da.obs[\"batch\"].unique()))}\n",
    "da.obs[\"batch\"] = da.obs[\"batch\"].map(map_to_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc07e5ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data: (21760, 57186)\n",
      "Validation data: (5440, 57186)\n"
     ]
    }
   ],
   "source": [
    "# Prepare data for fine-tuning (using the cat/tiger dataset from above)\n",
    "# Split data into train/val\n",
    "n_train = int(0.8 * len(da))\n",
    "train_idx = np.random.choice(len(da), n_train, replace=False)\n",
    "val_idx = np.setdiff1d(np.arange(len(da)), train_idx)\n",
    "\n",
    "train_data = da[train_idx].copy()\n",
    "val_data = da[val_idx].copy()\n",
    "\n",
    "print(f\"Training data: {train_data.shape}\")\n",
    "print(f\"Validation data: {val_data.shape}\")\n",
    "\n",
    "mencoders = {}\n",
    "for k, v in model.label_decoders.items():\n",
    "    mencoders[k] = {va: ke for ke, va in v.items()}\n",
    "# this needs to remain its original name as it is expect like that by collator, otherwise need to send org_to_id as params\n",
    "mencoders.pop(\"organism_ontology_term_id\")\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = SimpleAnnDataset(\n",
    "    train_data,\n",
    "    obs_to_output=[\"cell_type_ontology_term_id\", \"batch\", \"organism_ontology_term_id\"],\n",
    "    get_knn_cells=model.expr_emb_style == \"metacell\",\n",
    "    encoder=mencoders,\n",
    ")\n",
    "\n",
    "val_dataset = SimpleAnnDataset(\n",
    "    val_data,\n",
    "    obs_to_output=[\"cell_type_ontology_term_id\", \"batch\", \"organism_ontology_term_id\"],\n",
    "    get_knn_cells=model.expr_emb_style == \"metacell\",\n",
    "    encoder=mencoders,\n",
    ")\n",
    "\n",
    "# Create collator\n",
    "collator = Collator(\n",
    "    organisms=model.organisms,\n",
    "    valid_genes=model.genes,\n",
    "    class_names=[\"cell_type_ontology_term_id\", \"batch\"],\n",
    "    how=\"random expr\",  # or \"all expr\" for full expression\n",
    "    max_len=3000,\n",
    "    add_zero_genes=0,\n",
    ")\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    collate_fn=collator,\n",
    "    batch_size=32,  # Adjust based on GPU memory\n",
    "    num_workers=4,\n",
    "    shuffle=True,\n",
    "    pin_memory=True,\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    collate_fn=collator,\n",
    "    batch_size=32,\n",
    "    num_workers=4,\n",
    "    shuffle=False,\n",
    "    pin_memory=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce25257b",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_model_ct = 64  # dimension for cell type classification\n",
    "\n",
    "batch_cls = torch.nn.Sequential(\n",
    "    torch.nn.Linear(d_model_ct, d_model_ct),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(d_model_ct, len(set(da.obs[\"batch\"].unique()))),\n",
    ")\n",
    "batch_cls = batch_cls.to(model.device)\n",
    "\n",
    "# Create a learnable embedding vector of size d_model\n",
    "batch_vector = torch.nn.Embedding(\n",
    "    num_embeddings=2, embedding_dim=model.class_encoder.embedding.weight.shape[1]\n",
    ").to(model.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5544b3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for val in model.parameters():\n",
    "    val.requires_grad = False\n",
    "for val in model.cell_transformer.parameters():\n",
    "    val.requires_grad = True\n",
    "# for val in model.transformer.blocks[7].parameters():\n",
    "#    val.requires_grad = True\n",
    "# model.expr_decoder\n",
    "for i in model.transformer.blocks:\n",
    "    i.cross_attn.requires_grad = True\n",
    "for val in model.compressor.parameters():\n",
    "    val.requires_grad = True\n",
    "for val in model.cls_decoders[\"cell_type_ontology_term_id\"].parameters():\n",
    "    val.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f617f67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3189909/4062043289.py:21: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler() if torch.cuda.is_available() else None\n"
     ]
    }
   ],
   "source": [
    "# Alternative: Manual Training Loop (for more control)\n",
    "# If you prefer to have more control over the training process\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "from scprint.model import loss\n",
    "\n",
    "num_epochs = 40\n",
    "lr = 0.0002\n",
    "\n",
    "# Setup optimizer\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model.parameters(), lr=lr, weight_decay=0.01, betas=(0.9, 0.999), eps=1e-8\n",
    ")\n",
    "\n",
    "# Setup scheduler\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode=\"min\", factor=0.5, patience=2\n",
    ")\n",
    "\n",
    "# Setup automatic mixed precision\n",
    "scaler = torch.cuda.amp.GradScaler() if torch.cuda.is_available() else None\n",
    "\n",
    "_ = model.train()\n",
    "\n",
    "for k, i in model.mat_labels_hierarchy.items():\n",
    "    model.mat_labels_hierarchy[k] = i.to(model.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c28ce78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_corr_pass(batch):\n",
    "    gene_pos = batch[\"genes\"].to(model.device)\n",
    "    expression = batch[\"x\"].to(model.device)\n",
    "    depth = batch[\"depth\"].to(model.device)\n",
    "    class_elem = batch[\"class\"].long().to(model.device)\n",
    "\n",
    "    # Forward pass with automatic mixed precisio^n\n",
    "    with torch.cuda.amp.autocast():\n",
    "        # Forward pass\n",
    "        output = model.forward(\n",
    "            gene_pos,\n",
    "            expression,\n",
    "            req_depth=depth,\n",
    "            depth_mult=expression.sum(1),\n",
    "            do_class=True,\n",
    "            metacell_token=torch.zeros_like(depth),\n",
    "        )\n",
    "\n",
    "        output[\"output_cell_embs\"][\n",
    "            :, model.classes.index(\"organism_ontology_term_id\") + 1, :\n",
    "        ] = batch_vector(class_elem[:, 1])\n",
    "        output_gen = model._generate(\n",
    "            cell_embs=output[\"output_cell_embs\"],\n",
    "            gene_pos=gene_pos,\n",
    "            depth_mult=expression.sum(1),\n",
    "            req_depth=depth,\n",
    "        )\n",
    "        # model.qkv # use it to fine tune on the gene interactions\n",
    "        # predict something like known PPI matrices, cell specific GRNs from atac-seq data\n",
    "\n",
    "        # model.gene_output_embeddings\n",
    "        # use it to train a classifier on top to predict other modalities from gene embeddings given an additional anndata\n",
    "        # could be protein expression, ATAC-seq gene activity, transcript dynamics\n",
    "\n",
    "        # model.gen_output[\"expression\"] # modify the loss so that the model learns to predict KO given additional gene + with learnt KO representation token\n",
    "        # or expression temporal change given learnt temporal token\n",
    "\n",
    "        # for batch correction and classification\n",
    "        # Compute losses\n",
    "        total_loss = 0\n",
    "\n",
    "        if \"zero_logits\" in output_gen:\n",
    "            loss_expr = loss.zinb(\n",
    "                theta=output_gen[\"disp\"],\n",
    "                pi=output_gen[\"zero_logits\"],\n",
    "                mu=output_gen[\"mean\"],\n",
    "                target=expression,\n",
    "            )\n",
    "            if model.zinb_and_mse:\n",
    "                loss_expr += (\n",
    "                    loss.mse(\n",
    "                        input=torch.log(output_gen[\"mean\"] + 1)\n",
    "                        * (1 - torch.sigmoid(output_gen[\"zero_logits\"])),\n",
    "                        target=torch.log(expression + 1),\n",
    "                    )\n",
    "                    / 10  # scale to make it more similar to the zinb\n",
    "                )\n",
    "        else:\n",
    "            loss_expr = loss.mse(\n",
    "                input=torch.log(output_gen[\"mean\"] + 1),\n",
    "                target=torch.log(expression + 1),\n",
    "            )\n",
    "\n",
    "        # Add expression loss to total\n",
    "        total_loss += loss_expr\n",
    "\n",
    "        # Classification loss\n",
    "        cls_output = output.get(\"cls_output_cell_type_ontology_term_id\")\n",
    "        if cls_output is not None:\n",
    "            cls_loss = loss.hierarchical_classification(\n",
    "                pred=cls_output,\n",
    "                cl=batch[\"class\"][:, 0].to(model.device),\n",
    "                labels_hierarchy=model.mat_labels_hierarchy.get(\n",
    "                    \"cell_type_ontology_term_id\"\n",
    "                ).to(\"cuda\"),\n",
    "            )\n",
    "            total_loss += cls_loss\n",
    "\n",
    "        pos = model.classes.index(\"cell_type_ontology_term_id\") + 1\n",
    "        # Apply gradient reversal to the input embedding\n",
    "        selected_emb = (\n",
    "            output[\"compressed_cell_embs\"][pos]\n",
    "            if model.compressor is not None\n",
    "            else output[\"input_cell_embs\"][:, pos, :]\n",
    "        )\n",
    "        adv_input_emb = loss.grad_reverse(selected_emb.clone(), lambd=1.0)\n",
    "        # Get predictions from the adversarial decoder\n",
    "        adv_pred = batch_cls(adv_input_emb)\n",
    "        # do dissim\n",
    "\n",
    "        # Compute the adversarial loss - Fix: Convert target to long type\n",
    "        current_adv_loss = torch.nn.functional.cross_entropy(\n",
    "            input=adv_pred,\n",
    "            target=class_elem[:, 1],  # Convert to long type\n",
    "        )\n",
    "\n",
    "        # Add adversarial loss to total loss\n",
    "        total_loss += current_adv_loss * 1\n",
    "    return total_loss, cls_loss, current_adv_loss, loss_expr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06917e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/680 [00:00<?, ?it/s]/tmp/ipykernel_3189909/546074840.py:8: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 680/680 [04:54<00:00,  2.31it/s, loss=2.4818, avg_loss=2.3124, lr=1.00e-04, cls_loss=0.0195, adv_loss=1.2941, expr_loss=1.1682]\n",
      "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 170/170 [00:36<00:00,  4.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls_loss: 0.0081, adv_loss: 1.2733, expr_loss: 1.1698\n",
      "Train Loss: 2.3124, Val Loss: -0.2513\n",
      "\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 680/680 [04:56<00:00,  2.29it/s, loss=2.4958, avg_loss=2.3977, lr=1.00e-04, cls_loss=0.0126, adv_loss=1.3896, expr_loss=1.0935]\n",
      "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 170/170 [00:36<00:00,  4.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls_loss: 0.0066, adv_loss: 1.3480, expr_loss: 1.1643\n",
      "Train Loss: 2.3977, Val Loss: -0.3468\n",
      "\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 680/680 [04:56<00:00,  2.29it/s, loss=2.5501, avg_loss=2.4850, lr=1.00e-04, cls_loss=0.0124, adv_loss=1.4689, expr_loss=1.0688]\n",
      "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 170/170 [00:36<00:00,  4.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls_loss: 0.0042, adv_loss: 1.4240, expr_loss: 1.1613\n",
      "Train Loss: 2.4850, Val Loss: -0.4467\n",
      "\n",
      "Epoch 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 680/680 [04:56<00:00,  2.29it/s, loss=2.6959, avg_loss=2.5747, lr=1.00e-04, cls_loss=0.0127, adv_loss=1.5359, expr_loss=1.1473]\n",
      "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 170/170 [00:36<00:00,  4.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls_loss: 0.0036, adv_loss: 1.5008, expr_loss: 1.1604\n",
      "Train Loss: 2.5747, Val Loss: -0.5240\n",
      "\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 680/680 [04:57<00:00,  2.29it/s, loss=2.8078, avg_loss=2.6665, lr=1.00e-04, cls_loss=0.0093, adv_loss=1.7007, expr_loss=1.0978]\n",
      "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 170/170 [00:36<00:00,  4.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls_loss: 0.0022, adv_loss: 1.5781, expr_loss: 1.1566\n",
      "Train Loss: 2.6665, Val Loss: -0.6413\n",
      "\n",
      "Epoch 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 680/680 [04:56<00:00,  2.29it/s, loss=2.7283, avg_loss=2.7588, lr=1.00e-04, cls_loss=0.0031, adv_loss=1.7664, expr_loss=0.9588]\n",
      "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 170/170 [00:36<00:00,  4.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls_loss: 0.0014, adv_loss: 1.6556, expr_loss: 1.1564\n",
      "Train Loss: 2.7588, Val Loss: -0.7373\n",
      "\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 680/680 [04:57<00:00,  2.29it/s, loss=2.7686, avg_loss=2.8550, lr=1.00e-04, cls_loss=0.0045, adv_loss=1.8250, expr_loss=0.9391]\n",
      "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 170/170 [00:36<00:00,  4.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls_loss: 0.0029, adv_loss: 1.7354, expr_loss: 1.1564\n",
      "Train Loss: 2.8550, Val Loss: -0.8359\n",
      "\n",
      "Epoch 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 680/680 [04:57<00:00,  2.29it/s, loss=3.0392, avg_loss=2.9520, lr=1.00e-04, cls_loss=0.0015, adv_loss=1.9639, expr_loss=1.0739]\n",
      "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 170/170 [00:36<00:00,  4.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls_loss: 0.0010, adv_loss: 1.8161, expr_loss: 1.1549\n",
      "Train Loss: 2.9520, Val Loss: -0.9370\n",
      "\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 680/680 [04:57<00:00,  2.29it/s, loss=3.1418, avg_loss=3.0504, lr=1.00e-04, cls_loss=0.0015, adv_loss=2.0767, expr_loss=1.0637]\n",
      "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 170/170 [00:37<00:00,  4.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls_loss: 0.0017, adv_loss: 1.8970, expr_loss: 1.1541\n",
      "Train Loss: 3.0504, Val Loss: -1.0383\n",
      "\n",
      "Epoch 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 680/680 [04:57<00:00,  2.29it/s, loss=3.1932, avg_loss=3.1500, lr=1.00e-04, cls_loss=0.0050, adv_loss=2.1660, expr_loss=1.0221]\n",
      "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 170/170 [00:36<00:00,  4.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls_loss: 0.0012, adv_loss: 1.9801, expr_loss: 1.1514\n",
      "Train Loss: 3.1500, Val Loss: -1.1424\n",
      "Manual fine-tuning completed!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    print(f\"\\nEpoch {epoch + 1}/{num_epochs}\")\n",
    "\n",
    "    # Training phase\n",
    "    train_loss = 0.0\n",
    "    train_steps = 0\n",
    "    avg_adv = 0\n",
    "    avg_expr = 0\n",
    "    avg_cls = 0\n",
    "\n",
    "    pbar = tqdm(train_loader, desc=\"Training\")\n",
    "    for batch_idx, batch in enumerate(pbar):\n",
    "        # if epoch == 0:\n",
    "        #    break\n",
    "        # Move batch to device\n",
    "        optimizer.zero_grad()\n",
    "        total_loss, cls_loss, current_adv_loss, loss_expr = batch_corr_pass(batch)\n",
    "        # Backward pass\n",
    "        scaler.scale(total_loss).backward()\n",
    "        scaler.unscale_(optimizer)\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        train_loss += total_loss.item() if not torch.isnan(total_loss) else 0\n",
    "        train_steps += 1\n",
    "        avg_cls += cls_loss.item() if not torch.isnan(cls_loss) else 0\n",
    "        avg_expr += loss_expr.item() if not torch.isnan(loss_expr) else 0\n",
    "        avg_adv += current_adv_loss.item() if not torch.isnan(current_adv_loss) else 0\n",
    "        # Update progress bar\n",
    "        # if batch_idx % 35 == 0:\n",
    "        # print(\n",
    "        #    f\"avg_loss {train_loss / train_steps:.4f}, avg_cls {avg_cls / train_steps:.4f}, avg_expr {avg_expr / train_steps:.4f}, avg_adv {avg_adv / train_steps:.4f}\"\n",
    "        # )\n",
    "        pbar.set_postfix(\n",
    "            {\n",
    "                \"loss\": f\"{total_loss.item():.4f}\",\n",
    "                \"avg_loss\": f\"{train_loss / train_steps:.4f}\",\n",
    "                \"lr\": f\"{optimizer.param_groups[0]['lr']:.2e}\",\n",
    "                \"cls_loss\": f\"{cls_loss.item():.4f}\",\n",
    "                \"adv_loss\": f\"{current_adv_loss.item():.4f}\",\n",
    "                \"expr_loss\": f\"{loss_expr.item():.4f}\",\n",
    "            }\n",
    "        )\n",
    "\n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_steps = 0\n",
    "    val_loss_to_prt = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(val_loader, desc=\"Validation\"):\n",
    "            loss_val, cls_loss, current_adv_loss, loss_expr = batch_corr_pass(batch)\n",
    "            val_loss_to_prt += loss_val.item() - (2 * current_adv_loss.item())\n",
    "            val_loss += loss_val.item()\n",
    "            val_steps += 1\n",
    "    try:\n",
    "        avg_val_loss = val_loss_to_prt / val_steps\n",
    "        avg_train_loss = train_loss / train_steps\n",
    "    except ZeroDivisionError:\n",
    "        print(\"Error: Division by zero occurred while calculating average losses.\")\n",
    "        avg_train_loss = 0\n",
    "    print(\n",
    "        \"cls_loss: {:.4f}, adv_loss: {:.4f}, expr_loss: {:.4f}\".format(\n",
    "            cls_loss.item(), current_adv_loss.item(), loss_expr.item()\n",
    "        )\n",
    "    )\n",
    "    print(f\"Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "    # Update learning rate\n",
    "    scheduler.step(avg_val_loss)\n",
    "\n",
    "    # Early stopping check (simple implementation)\n",
    "    if epoch > 10 and val_loss / val_steps > 1.3 * avg_train_loss:\n",
    "        print(\"Early stopping due to overfitting\")\n",
    "        break\n",
    "\n",
    "print(\"Manual fine-tuning completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98646e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightning as L\n",
    "\n",
    "checkpoint = {\n",
    "    \"epoch\": epoch,\n",
    "    \"global_step\": (1 + epoch) * batch_idx,\n",
    "    \"pytorch-lightning_version\": L.__version__,\n",
    "    \"state_dict\": model.state_dict(),\n",
    "    \"optimizer_states\": [optimizer.state_dict()],\n",
    "    \"lr_schedulers\": [scheduler.state_dict()],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170b5cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"fit_2.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f048ab6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# model.load_state_dict(torch.load(\"fit_2.ckpt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6daa4847",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'pytorch-lightning_version'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 1\u001b[39m\n",
      "\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m model = \u001b[43mscPrint\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_from_checkpoint\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfit.ckpt\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprecpt_gene_emb\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mnormal\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n",
      "\u001b[32m      3\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[32m      4\u001b[39m model = model.to(\u001b[33m\"\u001b[39m\u001b[33mcuda\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents code/scPRINT/.venv/lib/python3.11/site-packages/lightning/pytorch/utilities/model_helpers.py:125\u001b[39m, in \u001b[36m_restricted_classmethod_impl.__get__.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n",
      "\u001b[32m    120\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m instance \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_scripting:\n",
      "\u001b[32m    121\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n",
      "\u001b[32m    122\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mThe classmethod `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.method.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m` cannot be called on an instance.\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[32m    123\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m Please call it on the class type and make sure the return value is used.\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[32m    124\u001b[39m     )\n",
      "\u001b[32m--> \u001b[39m\u001b[32m125\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents code/scPRINT/.venv/lib/python3.11/site-packages/lightning/pytorch/core/module.py:1611\u001b[39m, in \u001b[36mLightningModule.load_from_checkpoint\u001b[39m\u001b[34m(cls, checkpoint_path, map_location, hparams_file, strict, **kwargs)\u001b[39m\n",
      "\u001b[32m   1522\u001b[39m \u001b[38;5;129m@_restricted_classmethod\u001b[39m\n",
      "\u001b[32m   1523\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload_from_checkpoint\u001b[39m(\n",
      "\u001b[32m   1524\u001b[39m     \u001b[38;5;28mcls\u001b[39m,\n",
      "\u001b[32m   (...)\u001b[39m\u001b[32m   1529\u001b[39m     **kwargs: Any,\n",
      "\u001b[32m   1530\u001b[39m ) -> Self:\n",
      "\u001b[32m   1531\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Primary way of loading a model from a checkpoint. When Lightning saves a checkpoint it stores the arguments\u001b[39;00m\n",
      "\u001b[32m   1532\u001b[39m \u001b[33;03m    passed to ``__init__``  in the checkpoint under ``\"hyper_parameters\"``.\u001b[39;00m\n",
      "\u001b[32m   1533\u001b[39m \n",
      "\u001b[32m   (...)\u001b[39m\u001b[32m   1609\u001b[39m \n",
      "\u001b[32m   1610\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[32m-> \u001b[39m\u001b[32m1611\u001b[39m     loaded = \u001b[43m_load_from_checkpoint\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[32m   1612\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m   1613\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcheckpoint_path\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m   1614\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m   1615\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhparams_file\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m   1616\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m   1617\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m   1618\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[32m   1619\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(Self, loaded)\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents code/scPRINT/.venv/lib/python3.11/site-packages/lightning/pytorch/core/saving.py:66\u001b[39m, in \u001b[36m_load_from_checkpoint\u001b[39m\u001b[34m(cls, checkpoint_path, map_location, hparams_file, strict, **kwargs)\u001b[39m\n",
      "\u001b[32m     63\u001b[39m     checkpoint = pl_load(checkpoint_path, map_location=map_location)\n",
      "\u001b[32m     65\u001b[39m \u001b[38;5;66;03m# convert legacy checkpoints to the new format\u001b[39;00m\n",
      "\u001b[32m---> \u001b[39m\u001b[32m66\u001b[39m checkpoint = \u001b[43m_pl_migrate_checkpoint\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[32m     67\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheckpoint_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mPath\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[32m     68\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[32m     70\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m hparams_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[32m     71\u001b[39m     extension = \u001b[38;5;28mstr\u001b[39m(hparams_file).split(\u001b[33m\"\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m)[-\u001b[32m1\u001b[39m]\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents code/scPRINT/.venv/lib/python3.11/site-packages/lightning/pytorch/utilities/migration/utils.py:143\u001b[39m, in \u001b[36m_pl_migrate_checkpoint\u001b[39m\u001b[34m(checkpoint, checkpoint_path)\u001b[39m\n",
      "\u001b[32m    137\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_pl_migrate_checkpoint\u001b[39m(checkpoint: _CHECKPOINT, checkpoint_path: Optional[_PATH] = \u001b[38;5;28;01mNone\u001b[39;00m) -> _CHECKPOINT:\n",
      "\u001b[32m    138\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Applies Lightning version migrations to a checkpoint dictionary and prints infos for the user.\u001b[39;00m\n",
      "\u001b[32m    139\u001b[39m \n",
      "\u001b[32m    140\u001b[39m \u001b[33;03m    This function is used by the Lightning Trainer when resuming from a checkpoint.\u001b[39;00m\n",
      "\u001b[32m    141\u001b[39m \n",
      "\u001b[32m    142\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[32m--> \u001b[39m\u001b[32m143\u001b[39m     old_version = \u001b[43m_get_version\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[32m    144\u001b[39m     checkpoint, migrations = migrate_checkpoint(checkpoint)\n",
      "\u001b[32m    145\u001b[39m     new_version = _get_version(checkpoint)\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents code/scPRINT/.venv/lib/python3.11/site-packages/lightning/pytorch/utilities/migration/utils.py:164\u001b[39m, in \u001b[36m_get_version\u001b[39m\u001b[34m(checkpoint)\u001b[39m\n",
      "\u001b[32m    162\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_get_version\u001b[39m(checkpoint: _CHECKPOINT) -> \u001b[38;5;28mstr\u001b[39m:\n",
      "\u001b[32m    163\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Get the version of a Lightning checkpoint.\"\"\"\u001b[39;00m\n",
      "\u001b[32m--> \u001b[39m\u001b[32m164\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcheckpoint\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpytorch-lightning_version\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\n",
      "\u001b[31mKeyError\u001b[39m: 'pytorch-lightning_version'"
     ]
    }
   ],
   "source": [
    "# model = scPrint.load_from_checkpoint(\n",
    "#    \"fit.ckpt\", precpt_gene_emb=None, attention=\"normal\"\n",
    "# )\n",
    "# model = model.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f5c43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "da.obs = da.obs.iloc[:, :-20]\n",
    "for i in [\n",
    "    \"scprint_emb\",\n",
    "    \"scprint_emb_age_group\",\n",
    "    \"scprint_emb_assay_ontology_term_id\",\n",
    "    \"scprint_emb_cell_culture\",\n",
    "    \"scprint_emb_cell_type_ontology_term_id\",\n",
    "    \"scprint_emb_disease_ontology_term_id\",\n",
    "    \"scprint_emb_organism_ontology_term_id\",\n",
    "    \"scprint_emb_other\",\n",
    "    \"scprint_emb_self_reported_ethnicity_ontology_term_id\",\n",
    "    \"scprint_emb_sex_ontology_term_id\",\n",
    "    \"scprint_emb_tissue_ontology_term_id\",\n",
    "]:\n",
    "    da.obsm.pop(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630a13f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed = Embedder(\n",
    "    how=\"random expr\",\n",
    "    max_len=2600,\n",
    "    num_workers=8,\n",
    "    pred_embedding=[\"all\"],\n",
    "    doplot=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75bb7590",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not on wandb, could not set name\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 425/425 [01:16<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logging the anndata\n",
      "AnnData object with n_obs Ã— n_vars = 27200 Ã— 21550\n",
      "    obs: 'pred_cell_type_ontology_term_id', 'pred_tissue_ontology_term_id', 'pred_disease_ontology_term_id', 'pred_age_group', 'pred_assay_ontology_term_id', 'pred_self_reported_ethnicity_ontology_term_id', 'pred_sex_ontology_term_id', 'pred_organism_ontology_term_id', 'pred_cell_culture', 'conv_pred_cell_type_ontology_term_id', 'conv_pred_tissue_ontology_term_id', 'conv_pred_disease_ontology_term_id', 'conv_pred_age_group', 'conv_pred_assay_ontology_term_id', 'conv_pred_self_reported_ethnicity_ontology_term_id'\n",
      "    obsm: 'scprint_emb_other', 'scprint_emb_cell_type_ontology_term_id', 'scprint_emb_tissue_ontology_term_id', 'scprint_emb_disease_ontology_term_id', 'scprint_emb_age_group', 'scprint_emb_assay_ontology_term_id', 'scprint_emb_self_reported_ethnicity_ontology_term_id', 'scprint_emb_sex_ontology_term_id', 'scprint_emb_organism_ontology_term_id', 'scprint_emb_cell_culture'\n",
      "    layers: 'scprint_mu', 'scprint_theta', 'scprint_pi'\n",
      "too few cells to embed into a umap\n",
      "too few cells to compute a clustering\n"
     ]
    }
   ],
   "source": [
    "n_adata, metrics = embed(model, da.copy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scPRINT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
