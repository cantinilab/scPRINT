{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b39090e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-17T15:24:46.939359Z",
     "iopub.status.busy": "2025-09-17T15:24:46.938763Z",
     "iopub.status.idle": "2025-09-17T15:24:57.092400Z",
     "shell.execute_reply": "2025-09-17T15:24:57.091499Z"
    },
    "papermill": {
     "duration": 10.172254,
     "end_time": "2025-09-17T15:24:57.094996",
     "exception": false,
     "start_time": "2025-09-17T15:24:46.922742",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mâ†’\u001b[0m connected lamindb: jkobject/scprint2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/pasteur/appa/homes/jkalfon/simpler_flash/src/simpler_flash/layer_norm.py:1044: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @custom_fwd\n",
      "/pasteur/appa/homes/jkalfon/simpler_flash/src/simpler_flash/layer_norm.py:1107: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  @custom_bwd\n"
     ]
    }
   ],
   "source": [
    "import scanpy as sc\n",
    "from scprint import scPrint\n",
    "from scdataloader import Preprocessor\n",
    "from scdataloader.utils import load_genes\n",
    "import numpy as np\n",
    "import anndata as ad\n",
    "from huggingface_hub import hf_hub_download\n",
    "import lamindb as ln\n",
    "\n",
    "from scprint.tasks import Embedder\n",
    "from scprint.tasks.cell_emb import display_confusion_matrix\n",
    "import pandas as pd\n",
    "\n",
    "from scib_metrics.benchmark import Benchmarker, BioConservation, BatchCorrection\n",
    "from anndata import AnnData\n",
    "from scdataloader.utils import translate\n",
    "import bionty as bt\n",
    "from scprint.tasks.cell_emb import compute_classification\n",
    "\n",
    "from lightning.pytorch import Trainer\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "from scdataloader import SimpleAnnDataset, Collator, DataModule\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import lamindb as ln\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "import scipy.sparse\n",
    "\n",
    "torch.set_float32_matmul_precision(\"medium\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "829c1ea0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-17T15:24:57.124244Z",
     "iopub.status.busy": "2025-09-17T15:24:57.123471Z",
     "iopub.status.idle": "2025-09-17T15:24:57.182515Z",
     "shell.execute_reply": "2025-09-17T15:24:57.181561Z"
    },
    "papermill": {
     "duration": 0.075487,
     "end_time": "2025-09-17T15:24:57.185346",
     "exception": false,
     "start_time": "2025-09-17T15:24:57.109859",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model_checkpoint_file = hf_hub_download(\n",
    "#    repo_id=\"jkobject/scPRINT\", filename=f\"v2-medium.ckpt\"\n",
    "# )\n",
    "# model_checkpoint_file = ../data/\n",
    "model_checkpoint_file = \"../models/ji9krimq.ckpt\"\n",
    "# w937u4o1.ckpt'\n",
    "# da6ao55o.ckpt # 649\n",
    "# 1lzuxvg0.ckpt # 677\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe8410cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = torch.load(model_checkpoint_file, map_location=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1783e045",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['gene_encoder.0.embeddings.weight', 'gene_encoder.1.weight', 'gene_encoder.1.bias', 'gene_encoder.3.weight', 'gene_encoder.3.bias', 'expr_encoder.encoder.0.weight', 'expr_encoder.encoder.0.bias', 'expr_encoder.encoder.1.weight', 'expr_encoder.encoder.1.bias', 'expr_encoder.encoder.4.weight', 'expr_encoder.encoder.4.bias', 'expr_encoder.encoder.5.weight', 'expr_encoder.encoder.5.bias', 'expr_encoder.encoder.8.weight', 'expr_encoder.encoder.8.bias', 'pos_encoder.pe', 'class_encoder.embedding.weight', 'metacell_encoder.embedding.weight', 'transformer.blocks.0.mixer.Wqkv.weight', 'transformer.blocks.0.mixer.Wqkv.bias', 'transformer.blocks.0.mixer.out_proj.weight', 'transformer.blocks.0.mixer.out_proj.bias', 'transformer.blocks.0.cross_attn.Wq.weight', 'transformer.blocks.0.cross_attn.Wq.bias', 'transformer.blocks.0.cross_attn.Wkv.weight', 'transformer.blocks.0.cross_attn.Wkv.bias', 'transformer.blocks.0.cross_attn.out_proj.weight', 'transformer.blocks.0.cross_attn.out_proj.bias', 'transformer.blocks.0.norm3.weight', 'transformer.blocks.0.norm3.bias', 'transformer.blocks.0.norm1.weight', 'transformer.blocks.0.norm1.bias', 'transformer.blocks.0.mlp.fc1.weight', 'transformer.blocks.0.mlp.fc1.bias', 'transformer.blocks.0.mlp.fc2.weight', 'transformer.blocks.0.mlp.fc2.bias', 'transformer.blocks.0.norm2.weight', 'transformer.blocks.0.norm2.bias', 'transformer.blocks.1.mixer.Wqkv.weight', 'transformer.blocks.1.mixer.Wqkv.bias', 'transformer.blocks.1.mixer.out_proj.weight', 'transformer.blocks.1.mixer.out_proj.bias', 'transformer.blocks.1.cross_attn.Wq.weight', 'transformer.blocks.1.cross_attn.Wq.bias', 'transformer.blocks.1.cross_attn.Wkv.weight', 'transformer.blocks.1.cross_attn.Wkv.bias', 'transformer.blocks.1.cross_attn.out_proj.weight', 'transformer.blocks.1.cross_attn.out_proj.bias', 'transformer.blocks.1.norm3.weight', 'transformer.blocks.1.norm3.bias', 'transformer.blocks.1.norm1.weight', 'transformer.blocks.1.norm1.bias', 'transformer.blocks.1.mlp.fc1.weight', 'transformer.blocks.1.mlp.fc1.bias', 'transformer.blocks.1.mlp.fc2.weight', 'transformer.blocks.1.mlp.fc2.bias', 'transformer.blocks.1.norm2.weight', 'transformer.blocks.1.norm2.bias', 'transformer.blocks.2.mixer.Wqkv.weight', 'transformer.blocks.2.mixer.Wqkv.bias', 'transformer.blocks.2.mixer.out_proj.weight', 'transformer.blocks.2.mixer.out_proj.bias', 'transformer.blocks.2.cross_attn.Wq.weight', 'transformer.blocks.2.cross_attn.Wq.bias', 'transformer.blocks.2.cross_attn.Wkv.weight', 'transformer.blocks.2.cross_attn.Wkv.bias', 'transformer.blocks.2.cross_attn.out_proj.weight', 'transformer.blocks.2.cross_attn.out_proj.bias', 'transformer.blocks.2.norm3.weight', 'transformer.blocks.2.norm3.bias', 'transformer.blocks.2.norm1.weight', 'transformer.blocks.2.norm1.bias', 'transformer.blocks.2.mlp.fc1.weight', 'transformer.blocks.2.mlp.fc1.bias', 'transformer.blocks.2.mlp.fc2.weight', 'transformer.blocks.2.mlp.fc2.bias', 'transformer.blocks.2.norm2.weight', 'transformer.blocks.2.norm2.bias', 'transformer.blocks.3.mixer.Wqkv.weight', 'transformer.blocks.3.mixer.Wqkv.bias', 'transformer.blocks.3.mixer.out_proj.weight', 'transformer.blocks.3.mixer.out_proj.bias', 'transformer.blocks.3.cross_attn.Wq.weight', 'transformer.blocks.3.cross_attn.Wq.bias', 'transformer.blocks.3.cross_attn.Wkv.weight', 'transformer.blocks.3.cross_attn.Wkv.bias', 'transformer.blocks.3.cross_attn.out_proj.weight', 'transformer.blocks.3.cross_attn.out_proj.bias', 'transformer.blocks.3.norm3.weight', 'transformer.blocks.3.norm3.bias', 'transformer.blocks.3.norm1.weight', 'transformer.blocks.3.norm1.bias', 'transformer.blocks.3.mlp.fc1.weight', 'transformer.blocks.3.mlp.fc1.bias', 'transformer.blocks.3.mlp.fc2.weight', 'transformer.blocks.3.mlp.fc2.bias', 'transformer.blocks.3.norm2.weight', 'transformer.blocks.3.norm2.bias', 'transformer.blocks.4.mixer.Wqkv.weight', 'transformer.blocks.4.mixer.Wqkv.bias', 'transformer.blocks.4.mixer.out_proj.weight', 'transformer.blocks.4.mixer.out_proj.bias', 'transformer.blocks.4.cross_attn.Wq.weight', 'transformer.blocks.4.cross_attn.Wq.bias', 'transformer.blocks.4.cross_attn.Wkv.weight', 'transformer.blocks.4.cross_attn.Wkv.bias', 'transformer.blocks.4.cross_attn.out_proj.weight', 'transformer.blocks.4.cross_attn.out_proj.bias', 'transformer.blocks.4.norm3.weight', 'transformer.blocks.4.norm3.bias', 'transformer.blocks.4.norm1.weight', 'transformer.blocks.4.norm1.bias', 'transformer.blocks.4.mlp.fc1.weight', 'transformer.blocks.4.mlp.fc1.bias', 'transformer.blocks.4.mlp.fc2.weight', 'transformer.blocks.4.mlp.fc2.bias', 'transformer.blocks.4.norm2.weight', 'transformer.blocks.4.norm2.bias', 'transformer.blocks.5.mixer.Wqkv.weight', 'transformer.blocks.5.mixer.Wqkv.bias', 'transformer.blocks.5.mixer.out_proj.weight', 'transformer.blocks.5.mixer.out_proj.bias', 'transformer.blocks.5.cross_attn.Wq.weight', 'transformer.blocks.5.cross_attn.Wq.bias', 'transformer.blocks.5.cross_attn.Wkv.weight', 'transformer.blocks.5.cross_attn.Wkv.bias', 'transformer.blocks.5.cross_attn.out_proj.weight', 'transformer.blocks.5.cross_attn.out_proj.bias', 'transformer.blocks.5.norm3.weight', 'transformer.blocks.5.norm3.bias', 'transformer.blocks.5.norm1.weight', 'transformer.blocks.5.norm1.bias', 'transformer.blocks.5.mlp.fc1.weight', 'transformer.blocks.5.mlp.fc1.bias', 'transformer.blocks.5.mlp.fc2.weight', 'transformer.blocks.5.mlp.fc2.bias', 'transformer.blocks.5.norm2.weight', 'transformer.blocks.5.norm2.bias', 'transformer.blocks.6.mixer.Wqkv.weight', 'transformer.blocks.6.mixer.Wqkv.bias', 'transformer.blocks.6.mixer.out_proj.weight', 'transformer.blocks.6.mixer.out_proj.bias', 'transformer.blocks.6.cross_attn.Wq.weight', 'transformer.blocks.6.cross_attn.Wq.bias', 'transformer.blocks.6.cross_attn.Wkv.weight', 'transformer.blocks.6.cross_attn.Wkv.bias', 'transformer.blocks.6.cross_attn.out_proj.weight', 'transformer.blocks.6.cross_attn.out_proj.bias', 'transformer.blocks.6.norm3.weight', 'transformer.blocks.6.norm3.bias', 'transformer.blocks.6.norm1.weight', 'transformer.blocks.6.norm1.bias', 'transformer.blocks.6.mlp.fc1.weight', 'transformer.blocks.6.mlp.fc1.bias', 'transformer.blocks.6.mlp.fc2.weight', 'transformer.blocks.6.mlp.fc2.bias', 'transformer.blocks.6.norm2.weight', 'transformer.blocks.6.norm2.bias', 'transformer.blocks.7.mixer.Wqkv.weight', 'transformer.blocks.7.mixer.Wqkv.bias', 'transformer.blocks.7.mixer.out_proj.weight', 'transformer.blocks.7.mixer.out_proj.bias', 'transformer.blocks.7.cross_attn.Wq.weight', 'transformer.blocks.7.cross_attn.Wq.bias', 'transformer.blocks.7.cross_attn.Wkv.weight', 'transformer.blocks.7.cross_attn.Wkv.bias', 'transformer.blocks.7.cross_attn.out_proj.weight', 'transformer.blocks.7.cross_attn.out_proj.bias', 'transformer.blocks.7.norm3.weight', 'transformer.blocks.7.norm3.bias', 'transformer.blocks.7.norm1.weight', 'transformer.blocks.7.norm1.bias', 'transformer.blocks.7.mlp.fc1.weight', 'transformer.blocks.7.mlp.fc1.bias', 'transformer.blocks.7.mlp.fc2.weight', 'transformer.blocks.7.mlp.fc2.bias', 'transformer.blocks.7.norm2.weight', 'transformer.blocks.7.norm2.bias', 'transformer.blocks.8.mixer.Wqkv.weight', 'transformer.blocks.8.mixer.Wqkv.bias', 'transformer.blocks.8.mixer.out_proj.weight', 'transformer.blocks.8.mixer.out_proj.bias', 'transformer.blocks.8.cross_attn.Wq.weight', 'transformer.blocks.8.cross_attn.Wq.bias', 'transformer.blocks.8.cross_attn.Wkv.weight', 'transformer.blocks.8.cross_attn.Wkv.bias', 'transformer.blocks.8.cross_attn.out_proj.weight', 'transformer.blocks.8.cross_attn.out_proj.bias', 'transformer.blocks.8.norm3.weight', 'transformer.blocks.8.norm3.bias', 'transformer.blocks.8.norm1.weight', 'transformer.blocks.8.norm1.bias', 'transformer.blocks.8.mlp.fc1.weight', 'transformer.blocks.8.mlp.fc1.bias', 'transformer.blocks.8.mlp.fc2.weight', 'transformer.blocks.8.mlp.fc2.bias', 'transformer.blocks.8.norm2.weight', 'transformer.blocks.8.norm2.bias', 'transformer.blocks.9.mixer.Wqkv.weight', 'transformer.blocks.9.mixer.Wqkv.bias', 'transformer.blocks.9.mixer.out_proj.weight', 'transformer.blocks.9.mixer.out_proj.bias', 'transformer.blocks.9.cross_attn.Wq.weight', 'transformer.blocks.9.cross_attn.Wq.bias', 'transformer.blocks.9.cross_attn.Wkv.weight', 'transformer.blocks.9.cross_attn.Wkv.bias', 'transformer.blocks.9.cross_attn.out_proj.weight', 'transformer.blocks.9.cross_attn.out_proj.bias', 'transformer.blocks.9.norm3.weight', 'transformer.blocks.9.norm3.bias', 'transformer.blocks.9.norm1.weight', 'transformer.blocks.9.norm1.bias', 'transformer.blocks.9.mlp.fc1.weight', 'transformer.blocks.9.mlp.fc1.bias', 'transformer.blocks.9.mlp.fc2.weight', 'transformer.blocks.9.mlp.fc2.bias', 'transformer.blocks.9.norm2.weight', 'transformer.blocks.9.norm2.bias', 'transformer.blocks.10.mixer.Wqkv.weight', 'transformer.blocks.10.mixer.Wqkv.bias', 'transformer.blocks.10.mixer.out_proj.weight', 'transformer.blocks.10.mixer.out_proj.bias', 'transformer.blocks.10.cross_attn.Wq.weight', 'transformer.blocks.10.cross_attn.Wq.bias', 'transformer.blocks.10.cross_attn.Wkv.weight', 'transformer.blocks.10.cross_attn.Wkv.bias', 'transformer.blocks.10.cross_attn.out_proj.weight', 'transformer.blocks.10.cross_attn.out_proj.bias', 'transformer.blocks.10.norm3.weight', 'transformer.blocks.10.norm3.bias', 'transformer.blocks.10.norm1.weight', 'transformer.blocks.10.norm1.bias', 'transformer.blocks.10.mlp.fc1.weight', 'transformer.blocks.10.mlp.fc1.bias', 'transformer.blocks.10.mlp.fc2.weight', 'transformer.blocks.10.mlp.fc2.bias', 'transformer.blocks.10.norm2.weight', 'transformer.blocks.10.norm2.bias', 'transformer.blocks.11.mixer.Wqkv.weight', 'transformer.blocks.11.mixer.Wqkv.bias', 'transformer.blocks.11.mixer.out_proj.weight', 'transformer.blocks.11.mixer.out_proj.bias', 'transformer.blocks.11.cross_attn.Wq.weight', 'transformer.blocks.11.cross_attn.Wq.bias', 'transformer.blocks.11.cross_attn.Wkv.weight', 'transformer.blocks.11.cross_attn.Wkv.bias', 'transformer.blocks.11.cross_attn.out_proj.weight', 'transformer.blocks.11.cross_attn.out_proj.bias', 'transformer.blocks.11.norm3.weight', 'transformer.blocks.11.norm3.bias', 'transformer.blocks.11.norm1.weight', 'transformer.blocks.11.norm1.bias', 'transformer.blocks.11.mlp.fc1.weight', 'transformer.blocks.11.mlp.fc1.bias', 'transformer.blocks.11.mlp.fc2.weight', 'transformer.blocks.11.mlp.fc2.bias', 'transformer.blocks.11.norm2.weight', 'transformer.blocks.11.norm2.bias', 'transformer.blocks.12.mixer.Wqkv.weight', 'transformer.blocks.12.mixer.Wqkv.bias', 'transformer.blocks.12.mixer.out_proj.weight', 'transformer.blocks.12.mixer.out_proj.bias', 'transformer.blocks.12.cross_attn.Wq.weight', 'transformer.blocks.12.cross_attn.Wq.bias', 'transformer.blocks.12.cross_attn.Wkv.weight', 'transformer.blocks.12.cross_attn.Wkv.bias', 'transformer.blocks.12.cross_attn.out_proj.weight', 'transformer.blocks.12.cross_attn.out_proj.bias', 'transformer.blocks.12.norm3.weight', 'transformer.blocks.12.norm3.bias', 'transformer.blocks.12.norm1.weight', 'transformer.blocks.12.norm1.bias', 'transformer.blocks.12.mlp.fc1.weight', 'transformer.blocks.12.mlp.fc1.bias', 'transformer.blocks.12.mlp.fc2.weight', 'transformer.blocks.12.mlp.fc2.bias', 'transformer.blocks.12.norm2.weight', 'transformer.blocks.12.norm2.bias', 'transformer.blocks.13.mixer.Wqkv.weight', 'transformer.blocks.13.mixer.Wqkv.bias', 'transformer.blocks.13.mixer.out_proj.weight', 'transformer.blocks.13.mixer.out_proj.bias', 'transformer.blocks.13.cross_attn.Wq.weight', 'transformer.blocks.13.cross_attn.Wq.bias', 'transformer.blocks.13.cross_attn.Wkv.weight', 'transformer.blocks.13.cross_attn.Wkv.bias', 'transformer.blocks.13.cross_attn.out_proj.weight', 'transformer.blocks.13.cross_attn.out_proj.bias', 'transformer.blocks.13.norm3.weight', 'transformer.blocks.13.norm3.bias', 'transformer.blocks.13.norm1.weight', 'transformer.blocks.13.norm1.bias', 'transformer.blocks.13.mlp.fc1.weight', 'transformer.blocks.13.mlp.fc1.bias', 'transformer.blocks.13.mlp.fc2.weight', 'transformer.blocks.13.mlp.fc2.bias', 'transformer.blocks.13.norm2.weight', 'transformer.blocks.13.norm2.bias', 'transformer.blocks.14.mixer.Wqkv.weight', 'transformer.blocks.14.mixer.Wqkv.bias', 'transformer.blocks.14.mixer.out_proj.weight', 'transformer.blocks.14.mixer.out_proj.bias', 'transformer.blocks.14.cross_attn.Wq.weight', 'transformer.blocks.14.cross_attn.Wq.bias', 'transformer.blocks.14.cross_attn.Wkv.weight', 'transformer.blocks.14.cross_attn.Wkv.bias', 'transformer.blocks.14.cross_attn.out_proj.weight', 'transformer.blocks.14.cross_attn.out_proj.bias', 'transformer.blocks.14.norm3.weight', 'transformer.blocks.14.norm3.bias', 'transformer.blocks.14.norm1.weight', 'transformer.blocks.14.norm1.bias', 'transformer.blocks.14.mlp.fc1.weight', 'transformer.blocks.14.mlp.fc1.bias', 'transformer.blocks.14.mlp.fc2.weight', 'transformer.blocks.14.mlp.fc2.bias', 'transformer.blocks.14.norm2.weight', 'transformer.blocks.14.norm2.bias', 'transformer.blocks.15.mixer.Wqkv.weight', 'transformer.blocks.15.mixer.Wqkv.bias', 'transformer.blocks.15.mixer.out_proj.weight', 'transformer.blocks.15.mixer.out_proj.bias', 'transformer.blocks.15.cross_attn.Wq.weight', 'transformer.blocks.15.cross_attn.Wq.bias', 'transformer.blocks.15.cross_attn.Wkv.weight', 'transformer.blocks.15.cross_attn.Wkv.bias', 'transformer.blocks.15.cross_attn.out_proj.weight', 'transformer.blocks.15.cross_attn.out_proj.bias', 'transformer.blocks.15.norm3.weight', 'transformer.blocks.15.norm3.bias', 'transformer.blocks.15.norm1.weight', 'transformer.blocks.15.norm1.bias', 'transformer.blocks.15.mlp.fc1.weight', 'transformer.blocks.15.mlp.fc1.bias', 'transformer.blocks.15.mlp.fc2.weight', 'transformer.blocks.15.mlp.fc2.bias', 'transformer.blocks.15.norm2.weight', 'transformer.blocks.15.norm2.bias', 'transformer.norm.weight', 'transformer.norm.bias', 'cell_transformer.blocks.0.mixer.Wqkv.weight', 'cell_transformer.blocks.0.mixer.Wqkv.bias', 'cell_transformer.blocks.0.mixer.out_proj.weight', 'cell_transformer.blocks.0.mixer.out_proj.bias', 'cell_transformer.blocks.0.cross_attn.Wq.weight', 'cell_transformer.blocks.0.cross_attn.Wq.bias', 'cell_transformer.blocks.0.cross_attn.Wkv.weight', 'cell_transformer.blocks.0.cross_attn.Wkv.bias', 'cell_transformer.blocks.0.cross_attn.out_proj.weight', 'cell_transformer.blocks.0.cross_attn.out_proj.bias', 'cell_transformer.blocks.0.norm3.weight', 'cell_transformer.blocks.0.norm3.bias', 'cell_transformer.blocks.0.norm1.weight', 'cell_transformer.blocks.0.norm1.bias', 'cell_transformer.blocks.0.mlp.fc1.weight', 'cell_transformer.blocks.0.mlp.fc1.bias', 'cell_transformer.blocks.0.mlp.fc2.weight', 'cell_transformer.blocks.0.mlp.fc2.bias', 'cell_transformer.blocks.0.norm2.weight', 'cell_transformer.blocks.0.norm2.bias', 'cell_transformer.blocks.1.mixer.Wqkv.weight', 'cell_transformer.blocks.1.mixer.Wqkv.bias', 'cell_transformer.blocks.1.mixer.out_proj.weight', 'cell_transformer.blocks.1.mixer.out_proj.bias', 'cell_transformer.blocks.1.cross_attn.Wq.weight', 'cell_transformer.blocks.1.cross_attn.Wq.bias', 'cell_transformer.blocks.1.cross_attn.Wkv.weight', 'cell_transformer.blocks.1.cross_attn.Wkv.bias', 'cell_transformer.blocks.1.cross_attn.out_proj.weight', 'cell_transformer.blocks.1.cross_attn.out_proj.bias', 'cell_transformer.blocks.1.norm3.weight', 'cell_transformer.blocks.1.norm3.bias', 'cell_transformer.blocks.1.norm1.weight', 'cell_transformer.blocks.1.norm1.bias', 'cell_transformer.blocks.1.mlp.fc1.weight', 'cell_transformer.blocks.1.mlp.fc1.bias', 'cell_transformer.blocks.1.mlp.fc2.weight', 'cell_transformer.blocks.1.mlp.fc2.bias', 'cell_transformer.blocks.1.norm2.weight', 'cell_transformer.blocks.1.norm2.bias', 'cell_transformer.blocks.2.mixer.Wqkv.weight', 'cell_transformer.blocks.2.mixer.Wqkv.bias', 'cell_transformer.blocks.2.mixer.out_proj.weight', 'cell_transformer.blocks.2.mixer.out_proj.bias', 'cell_transformer.blocks.2.cross_attn.Wq.weight', 'cell_transformer.blocks.2.cross_attn.Wq.bias', 'cell_transformer.blocks.2.cross_attn.Wkv.weight', 'cell_transformer.blocks.2.cross_attn.Wkv.bias', 'cell_transformer.blocks.2.cross_attn.out_proj.weight', 'cell_transformer.blocks.2.cross_attn.out_proj.bias', 'cell_transformer.blocks.2.norm3.weight', 'cell_transformer.blocks.2.norm3.bias', 'cell_transformer.blocks.2.norm1.weight', 'cell_transformer.blocks.2.norm1.bias', 'cell_transformer.blocks.2.mlp.fc1.weight', 'cell_transformer.blocks.2.mlp.fc1.bias', 'cell_transformer.blocks.2.mlp.fc2.weight', 'cell_transformer.blocks.2.mlp.fc2.bias', 'cell_transformer.blocks.2.norm2.weight', 'cell_transformer.blocks.2.norm2.bias', 'cell_transformer.blocks.3.mixer.Wqkv.weight', 'cell_transformer.blocks.3.mixer.Wqkv.bias', 'cell_transformer.blocks.3.mixer.out_proj.weight', 'cell_transformer.blocks.3.mixer.out_proj.bias', 'cell_transformer.blocks.3.cross_attn.Wq.weight', 'cell_transformer.blocks.3.cross_attn.Wq.bias', 'cell_transformer.blocks.3.cross_attn.Wkv.weight', 'cell_transformer.blocks.3.cross_attn.Wkv.bias', 'cell_transformer.blocks.3.cross_attn.out_proj.weight', 'cell_transformer.blocks.3.cross_attn.out_proj.bias', 'cell_transformer.blocks.3.norm3.weight', 'cell_transformer.blocks.3.norm3.bias', 'cell_transformer.blocks.3.norm1.weight', 'cell_transformer.blocks.3.norm1.bias', 'cell_transformer.blocks.3.mlp.fc1.weight', 'cell_transformer.blocks.3.mlp.fc1.bias', 'cell_transformer.blocks.3.mlp.fc2.weight', 'cell_transformer.blocks.3.mlp.fc2.bias', 'cell_transformer.blocks.3.norm2.weight', 'cell_transformer.blocks.3.norm2.bias', 'cell_transformer.blocks.4.mixer.Wqkv.weight', 'cell_transformer.blocks.4.mixer.Wqkv.bias', 'cell_transformer.blocks.4.mixer.out_proj.weight', 'cell_transformer.blocks.4.mixer.out_proj.bias', 'cell_transformer.blocks.4.cross_attn.Wq.weight', 'cell_transformer.blocks.4.cross_attn.Wq.bias', 'cell_transformer.blocks.4.cross_attn.Wkv.weight', 'cell_transformer.blocks.4.cross_attn.Wkv.bias', 'cell_transformer.blocks.4.cross_attn.out_proj.weight', 'cell_transformer.blocks.4.cross_attn.out_proj.bias', 'cell_transformer.blocks.4.norm3.weight', 'cell_transformer.blocks.4.norm3.bias', 'cell_transformer.blocks.4.norm1.weight', 'cell_transformer.blocks.4.norm1.bias', 'cell_transformer.blocks.4.mlp.fc1.weight', 'cell_transformer.blocks.4.mlp.fc1.bias', 'cell_transformer.blocks.4.mlp.fc2.weight', 'cell_transformer.blocks.4.mlp.fc2.bias', 'cell_transformer.blocks.4.norm2.weight', 'cell_transformer.blocks.4.norm2.bias', 'cell_transformer.blocks.5.mixer.Wqkv.weight', 'cell_transformer.blocks.5.mixer.Wqkv.bias', 'cell_transformer.blocks.5.mixer.out_proj.weight', 'cell_transformer.blocks.5.mixer.out_proj.bias', 'cell_transformer.blocks.5.cross_attn.Wq.weight', 'cell_transformer.blocks.5.cross_attn.Wq.bias', 'cell_transformer.blocks.5.cross_attn.Wkv.weight', 'cell_transformer.blocks.5.cross_attn.Wkv.bias', 'cell_transformer.blocks.5.cross_attn.out_proj.weight', 'cell_transformer.blocks.5.cross_attn.out_proj.bias', 'cell_transformer.blocks.5.norm3.weight', 'cell_transformer.blocks.5.norm3.bias', 'cell_transformer.blocks.5.norm1.weight', 'cell_transformer.blocks.5.norm1.bias', 'cell_transformer.blocks.5.mlp.fc1.weight', 'cell_transformer.blocks.5.mlp.fc1.bias', 'cell_transformer.blocks.5.mlp.fc2.weight', 'cell_transformer.blocks.5.mlp.fc2.bias', 'cell_transformer.blocks.5.norm2.weight', 'cell_transformer.blocks.5.norm2.bias', 'cell_transformer.norm.weight', 'cell_transformer.norm.bias', 'expr_decoder.fc.0.weight', 'expr_decoder.fc.0.bias', 'expr_decoder.fc.1.weight', 'expr_decoder.fc.1.bias', 'expr_decoder.fc.4.weight', 'expr_decoder.fc.4.bias', 'expr_decoder.fc.5.weight', 'expr_decoder.fc.5.bias', 'expr_decoder.pred_var_zero.weight', 'expr_decoder.pred_var_zero.bias', 'cls_decoders.cell_type_ontology_term_id.decoder.0.weight', 'cls_decoders.cell_type_ontology_term_id.decoder.0.bias', 'cls_decoders.cell_type_ontology_term_id.decoder.1.weight', 'cls_decoders.cell_type_ontology_term_id.decoder.1.bias', 'cls_decoders.cell_type_ontology_term_id.decoder.4.weight', 'cls_decoders.cell_type_ontology_term_id.decoder.4.bias', 'cls_decoders.cell_type_ontology_term_id.decoder.5.weight', 'cls_decoders.cell_type_ontology_term_id.decoder.5.bias', 'cls_decoders.cell_type_ontology_term_id.out_layer.weight', 'cls_decoders.cell_type_ontology_term_id.out_layer.bias', 'cls_decoders.tissue_ontology_term_id.decoder.0.weight', 'cls_decoders.tissue_ontology_term_id.decoder.0.bias', 'cls_decoders.tissue_ontology_term_id.decoder.1.weight', 'cls_decoders.tissue_ontology_term_id.decoder.1.bias', 'cls_decoders.tissue_ontology_term_id.decoder.4.weight', 'cls_decoders.tissue_ontology_term_id.decoder.4.bias', 'cls_decoders.tissue_ontology_term_id.decoder.5.weight', 'cls_decoders.tissue_ontology_term_id.decoder.5.bias', 'cls_decoders.tissue_ontology_term_id.out_layer.weight', 'cls_decoders.tissue_ontology_term_id.out_layer.bias', 'cls_decoders.disease_ontology_term_id.decoder.0.weight', 'cls_decoders.disease_ontology_term_id.decoder.0.bias', 'cls_decoders.disease_ontology_term_id.decoder.1.weight', 'cls_decoders.disease_ontology_term_id.decoder.1.bias', 'cls_decoders.disease_ontology_term_id.decoder.4.weight', 'cls_decoders.disease_ontology_term_id.decoder.4.bias', 'cls_decoders.disease_ontology_term_id.decoder.5.weight', 'cls_decoders.disease_ontology_term_id.decoder.5.bias', 'cls_decoders.disease_ontology_term_id.out_layer.weight', 'cls_decoders.disease_ontology_term_id.out_layer.bias', 'cls_decoders.age_group.decoder.0.weight', 'cls_decoders.age_group.decoder.0.bias', 'cls_decoders.age_group.decoder.1.weight', 'cls_decoders.age_group.decoder.1.bias', 'cls_decoders.age_group.decoder.4.weight', 'cls_decoders.age_group.decoder.4.bias', 'cls_decoders.age_group.decoder.5.weight', 'cls_decoders.age_group.decoder.5.bias', 'cls_decoders.age_group.out_layer.weight', 'cls_decoders.age_group.out_layer.bias', 'cls_decoders.assay_ontology_term_id.decoder.0.weight', 'cls_decoders.assay_ontology_term_id.decoder.0.bias', 'cls_decoders.assay_ontology_term_id.decoder.1.weight', 'cls_decoders.assay_ontology_term_id.decoder.1.bias', 'cls_decoders.assay_ontology_term_id.decoder.4.weight', 'cls_decoders.assay_ontology_term_id.decoder.4.bias', 'cls_decoders.assay_ontology_term_id.decoder.5.weight', 'cls_decoders.assay_ontology_term_id.decoder.5.bias', 'cls_decoders.assay_ontology_term_id.out_layer.weight', 'cls_decoders.assay_ontology_term_id.out_layer.bias', 'cls_decoders.self_reported_ethnicity_ontology_term_id.decoder.0.weight', 'cls_decoders.self_reported_ethnicity_ontology_term_id.decoder.0.bias', 'cls_decoders.self_reported_ethnicity_ontology_term_id.decoder.1.weight', 'cls_decoders.self_reported_ethnicity_ontology_term_id.decoder.1.bias', 'cls_decoders.self_reported_ethnicity_ontology_term_id.decoder.4.weight', 'cls_decoders.self_reported_ethnicity_ontology_term_id.decoder.4.bias', 'cls_decoders.self_reported_ethnicity_ontology_term_id.decoder.5.weight', 'cls_decoders.self_reported_ethnicity_ontology_term_id.decoder.5.bias', 'cls_decoders.self_reported_ethnicity_ontology_term_id.out_layer.weight', 'cls_decoders.self_reported_ethnicity_ontology_term_id.out_layer.bias', 'cls_decoders.sex_ontology_term_id.decoder.0.weight', 'cls_decoders.sex_ontology_term_id.decoder.0.bias', 'cls_decoders.sex_ontology_term_id.decoder.1.weight', 'cls_decoders.sex_ontology_term_id.decoder.1.bias', 'cls_decoders.sex_ontology_term_id.decoder.4.weight', 'cls_decoders.sex_ontology_term_id.decoder.4.bias', 'cls_decoders.sex_ontology_term_id.decoder.5.weight', 'cls_decoders.sex_ontology_term_id.decoder.5.bias', 'cls_decoders.sex_ontology_term_id.out_layer.weight', 'cls_decoders.sex_ontology_term_id.out_layer.bias', 'cls_decoders.organism_ontology_term_id.decoder.0.weight', 'cls_decoders.organism_ontology_term_id.decoder.0.bias', 'cls_decoders.organism_ontology_term_id.decoder.1.weight', 'cls_decoders.organism_ontology_term_id.decoder.1.bias', 'cls_decoders.organism_ontology_term_id.decoder.4.weight', 'cls_decoders.organism_ontology_term_id.decoder.4.bias', 'cls_decoders.organism_ontology_term_id.decoder.5.weight', 'cls_decoders.organism_ontology_term_id.decoder.5.bias', 'cls_decoders.organism_ontology_term_id.out_layer.weight', 'cls_decoders.organism_ontology_term_id.out_layer.bias', 'cls_decoders.cell_culture.decoder.0.weight', 'cls_decoders.cell_culture.decoder.0.bias', 'cls_decoders.cell_culture.decoder.1.weight', 'cls_decoders.cell_culture.decoder.1.bias', 'cls_decoders.cell_culture.decoder.4.weight', 'cls_decoders.cell_culture.decoder.4.bias', 'cls_decoders.cell_culture.decoder.5.weight', 'cls_decoders.cell_culture.decoder.5.bias', 'cls_decoders.cell_culture.out_layer.weight', 'cls_decoders.cell_culture.out_layer.bias'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m['state_dict'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "327b650f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-17T15:24:57.213837Z",
     "iopub.status.busy": "2025-09-17T15:24:57.213211Z",
     "iopub.status.idle": "2025-09-17T15:27:47.486800Z",
     "shell.execute_reply": "2025-09-17T15:27:47.485977Z"
    },
    "papermill": {
     "duration": 170.289846,
     "end_time": "2025-09-17T15:27:47.489107",
     "exception": false,
     "start_time": "2025-09-17T15:24:57.199261",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FYI: scPrint is not attached to a `Trainer`.\n"
     ]
    }
   ],
   "source": [
    "model = scPrint.load_from_checkpoint(\n",
    "    model_checkpoint_file, precpt_gene_emb=None, gene_pos_file=None, max_cont_len=None,\n",
    ")\n",
    "model = model.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb5a8bf",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCannot execute code, session has been disposed. Please try restarting the Kernel."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to connect to the remote Jupyter Server 'http://maestro-3018.maestro.pasteur.fr:8888/'. Verify the server is running and reachable."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCannot execute code, session has been disposed. Please try restarting the Kernel. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "LOC = \"/pasteur/appa/scratch/jkalfon/data/spcrint_data/\"#\"./\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6cc0e90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step_0__denoise_WUzIO6_0_0.h5ad  umap__embed_SwiTOf_0.png\n",
      "step_0__embed_apIVzL_0_0.h5ad    umap__embed_VFwP3y_0.png\n",
      "step_0__predict_part_1_0.h5ad    umap__embed_w60qGQ_0.png\n",
      "task_3_embed.h5ad                umap__impute4uGkLe_0.png\n",
      "task4_denoised.h5ad              umap__imputeHqlw09_0.png\n",
      "umap__embed_5aQRN5_0.png         umap__imputeK2f51g_0.png\n",
      "umap__embed_8AINEk_0.png         umap__imputeKpi1Xp_0.png\n",
      "umap__embed_dx2GaD_0.png         umap__imputerDKcLY_0.png\n",
      "umap__embed_Ecyc1j_0.png         umap__predict_part_0.png\n",
      "umap__embed_hHJPuQ_0.png         umap__predict_part_1.png\n",
      "umap__embed_JxjU9K_0.png\n"
     ]
    }
   ],
   "source": [
    "ls ./data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593d6235",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-17T15:27:47.516313Z",
     "iopub.status.busy": "2025-09-17T15:27:47.516015Z",
     "iopub.status.idle": "2025-09-17T15:27:48.212017Z",
     "shell.execute_reply": "2025-09-17T15:27:48.211051Z"
    },
    "papermill": {
     "duration": 0.711081,
     "end_time": "2025-09-17T15:27:48.214457",
     "exception": false,
     "start_time": "2025-09-17T15:27:47.503376",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] Unable to synchronously open file (unable to open file: name = 'data/task_3_embed.h5ad', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m da = \u001b[43msc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m./data/task_3_embed.h5ad\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/scPRINT/.venv/lib/python3.11/site-packages/legacy_api_wrap/__init__.py:82\u001b[39m, in \u001b[36mlegacy_api.<locals>.wrapper.<locals>.fn_compatible\u001b[39m\u001b[34m(*args_all, **kw)\u001b[39m\n\u001b[32m     79\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(fn)\n\u001b[32m     80\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfn_compatible\u001b[39m(*args_all: P.args, **kw: P.kwargs) -> R:\n\u001b[32m     81\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args_all) <= n_positional:\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs_all\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     84\u001b[39m     args_pos: P.args\n\u001b[32m     85\u001b[39m     args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/scPRINT/.venv/lib/python3.11/site-packages/scanpy/readwrite.py:145\u001b[39m, in \u001b[36mread\u001b[39m\u001b[34m(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, cache_compression, **kwargs)\u001b[39m\n\u001b[32m    143\u001b[39m filename = Path(filename)  \u001b[38;5;66;03m# allow passing strings\u001b[39;00m\n\u001b[32m    144\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_valid_filename(filename, ext=ext):\n\u001b[32m--> \u001b[39m\u001b[32m145\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    146\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    147\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbacked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbacked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    148\u001b[39m \u001b[43m        \u001b[49m\u001b[43msheet\u001b[49m\u001b[43m=\u001b[49m\u001b[43msheet\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    149\u001b[39m \u001b[43m        \u001b[49m\u001b[43mext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    150\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdelimiter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdelimiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfirst_column_names\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfirst_column_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    152\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbackup_url\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbackup_url\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    153\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    154\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_compression\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_compression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    155\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    156\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    157\u001b[39m \u001b[38;5;66;03m# generate filename and read to dict\u001b[39;00m\n\u001b[32m    158\u001b[39m filekey = \u001b[38;5;28mstr\u001b[39m(filename)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/scPRINT/.venv/lib/python3.11/site-packages/scanpy/readwrite.py:773\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, cache_compression, suppress_cache_warning, **kwargs)\u001b[39m\n\u001b[32m    771\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ext \u001b[38;5;129;01min\u001b[39;00m {\u001b[33m\"\u001b[39m\u001b[33mh5\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mh5ad\u001b[39m\u001b[33m\"\u001b[39m}:\n\u001b[32m    772\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m sheet \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m773\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mread_h5ad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbacked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbacked\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    774\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    775\u001b[39m         logg.debug(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mreading sheet \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msheet\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m from file \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilename\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/scPRINT/.venv/lib/python3.11/site-packages/anndata/_io/h5ad.py:239\u001b[39m, in \u001b[36mread_h5ad\u001b[39m\u001b[34m(filename, backed, as_sparse, as_sparse_fmt, chunk_size)\u001b[39m\n\u001b[32m    233\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(msg)\n\u001b[32m    235\u001b[39m rdasp = partial(\n\u001b[32m    236\u001b[39m     read_dense_as_sparse, sparse_format=as_sparse_fmt, axis_chunk=chunk_size\n\u001b[32m    237\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m239\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mh5py\u001b[49m\u001b[43m.\u001b[49m\u001b[43mFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m    241\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcallback\u001b[39m(func, elem_name: \u001b[38;5;28mstr\u001b[39m, elem, iospec):\n\u001b[32m    242\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m iospec.encoding_type == \u001b[33m\"\u001b[39m\u001b[33manndata\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m elem_name.endswith(\u001b[33m\"\u001b[39m\u001b[33m/\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/scPRINT/.venv/lib/python3.11/site-packages/h5py/_hl/files.py:564\u001b[39m, in \u001b[36mFile.__init__\u001b[39m\u001b[34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, alignment_threshold, alignment_interval, meta_block_size, **kwds)\u001b[39m\n\u001b[32m    555\u001b[39m     fapl = make_fapl(driver, libver, rdcc_nslots, rdcc_nbytes, rdcc_w0,\n\u001b[32m    556\u001b[39m                      locking, page_buf_size, min_meta_keep, min_raw_keep,\n\u001b[32m    557\u001b[39m                      alignment_threshold=alignment_threshold,\n\u001b[32m    558\u001b[39m                      alignment_interval=alignment_interval,\n\u001b[32m    559\u001b[39m                      meta_block_size=meta_block_size,\n\u001b[32m    560\u001b[39m                      **kwds)\n\u001b[32m    561\u001b[39m     fcpl = make_fcpl(track_order=track_order, fs_strategy=fs_strategy,\n\u001b[32m    562\u001b[39m                      fs_persist=fs_persist, fs_threshold=fs_threshold,\n\u001b[32m    563\u001b[39m                      fs_page_size=fs_page_size)\n\u001b[32m--> \u001b[39m\u001b[32m564\u001b[39m     fid = \u001b[43mmake_fid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muserblock_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfapl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfcpl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mswmr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mswmr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    566\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(libver, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[32m    567\u001b[39m     \u001b[38;5;28mself\u001b[39m._libver = libver\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/scPRINT/.venv/lib/python3.11/site-packages/h5py/_hl/files.py:238\u001b[39m, in \u001b[36mmake_fid\u001b[39m\u001b[34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[39m\n\u001b[32m    236\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m swmr \u001b[38;5;129;01mand\u001b[39;00m swmr_support:\n\u001b[32m    237\u001b[39m         flags |= h5f.ACC_SWMR_READ\n\u001b[32m--> \u001b[39m\u001b[32m238\u001b[39m     fid = \u001b[43mh5f\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfapl\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfapl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    239\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m mode == \u001b[33m'\u001b[39m\u001b[33mr+\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m    240\u001b[39m     fid = h5f.open(name, h5f.ACC_RDWR, fapl=fapl)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mh5py/_objects.pyx:56\u001b[39m, in \u001b[36mh5py._objects.with_phil.wrapper\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mh5py/_objects.pyx:57\u001b[39m, in \u001b[36mh5py._objects.with_phil.wrapper\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mh5py/h5f.pyx:102\u001b[39m, in \u001b[36mh5py.h5f.open\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] Unable to synchronously open file (unable to open file: name = 'data/task_3_embed.h5ad', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "da = sc.read(LOC+\"data/task_3_embed.h5ad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45447a9a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-17T15:27:48.242471Z",
     "iopub.status.busy": "2025-09-17T15:27:48.242108Z",
     "iopub.status.idle": "2025-09-17T15:27:48.321337Z",
     "shell.execute_reply": "2025-09-17T15:27:48.320450Z"
    },
    "papermill": {
     "duration": 0.094543,
     "end_time": "2025-09-17T15:27:48.323683",
     "exception": false,
     "start_time": "2025-09-17T15:27:48.229140",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "map_to_val = {n: i for i, n in enumerate(set(da.obs[\"batch\"].unique()))}\n",
    "da.obs[\"batch\"] = da.obs[\"batch\"].map(map_to_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc07e5ba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-17T15:27:48.352264Z",
     "iopub.status.busy": "2025-09-17T15:27:48.351711Z",
     "iopub.status.idle": "2025-09-17T15:28:02.377363Z",
     "shell.execute_reply": "2025-09-17T15:28:02.376478Z"
    },
    "papermill": {
     "duration": 14.041652,
     "end_time": "2025-09-17T15:28:02.379841",
     "exception": false,
     "start_time": "2025-09-17T15:27:48.338189",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data: (13600, 57186)\n",
      "Validation data: (13600, 57186)\n"
     ]
    }
   ],
   "source": [
    "# Prepare data for fine-tuning (using the cat/tiger dataset from above)\n",
    "# Split data into train/val\n",
    "n_train = int(0.5 * len(da))\n",
    "train_idx = np.random.choice(len(da), n_train, replace=False)\n",
    "val_idx = np.setdiff1d(np.arange(len(da)), train_idx)\n",
    "\n",
    "train_data = da[train_idx].copy()\n",
    "val_data = da[val_idx].copy()\n",
    "\n",
    "print(f\"Training data: {train_data.shape}\")\n",
    "print(f\"Validation data: {val_data.shape}\")\n",
    "\n",
    "mencoders = {}\n",
    "for k, v in model.label_decoders.items():\n",
    "    mencoders[k] = {va: ke for ke, va in v.items()}\n",
    "# this needs to remain its original name as it is expect like that by collator, otherwise need to send org_to_id as params\n",
    "mencoders.pop(\"organism_ontology_term_id\")\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = SimpleAnnDataset(\n",
    "    train_data,\n",
    "    obs_to_output=[\"cell_type_ontology_term_id\", \"batch\", \"organism_ontology_term_id\"],\n",
    "    get_knn_cells=model.expr_emb_style == \"metacell\",\n",
    "    encoder=mencoders,\n",
    ")\n",
    "\n",
    "val_dataset = SimpleAnnDataset(\n",
    "    val_data,\n",
    "    obs_to_output=[\"cell_type_ontology_term_id\", \"batch\", \"organism_ontology_term_id\"],\n",
    "    get_knn_cells=model.expr_emb_style == \"metacell\",\n",
    "    encoder=mencoders,\n",
    ")\n",
    "\n",
    "# Create collator\n",
    "collator = Collator(\n",
    "    organisms=model.organisms,\n",
    "    valid_genes=model.genes,\n",
    "    class_names=[\"cell_type_ontology_term_id\", \"batch\"],\n",
    "    how=\"random expr\",  # or \"all expr\" for full expression\n",
    "    max_len=2800,\n",
    "    add_zero_genes=0,\n",
    ")\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    collate_fn=collator,\n",
    "    batch_size=16,  # Adjust based on GPU memory\n",
    "    num_workers=4,\n",
    "    shuffle=True,\n",
    "    pin_memory=True,\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    collate_fn=collator,\n",
    "    batch_size=16,\n",
    "    num_workers=4,\n",
    "    shuffle=True,\n",
    "    pin_memory=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce25257b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-17T15:28:02.408190Z",
     "iopub.status.busy": "2025-09-17T15:28:02.407911Z",
     "iopub.status.idle": "2025-09-17T15:28:02.473750Z",
     "shell.execute_reply": "2025-09-17T15:28:02.472891Z"
    },
    "papermill": {
     "duration": 0.081442,
     "end_time": "2025-09-17T15:28:02.476123",
     "exception": false,
     "start_time": "2025-09-17T15:28:02.394681",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "d_model_org = 8\n",
    "d_module_cell = 256  # 128\n",
    "\n",
    "batch_cls = torch.nn.Sequential(\n",
    "    # torch.nn.Linear(d_model_org, d_model_org * 8),\n",
    "    torch.nn.Linear(d_module_cell, d_model_org * 8),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(d_model_org * 8, len(set(da.obs[\"batch\"].unique()))),\n",
    ")\n",
    "batch_cls = batch_cls.to(model.device)\n",
    "\n",
    "batch_emb = torch.nn.Embedding(len(set(da.obs[\"batch\"].unique())), d_module_cell).to(\n",
    "    model.device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5544b3a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-17T15:28:02.504874Z",
     "iopub.status.busy": "2025-09-17T15:28:02.504582Z",
     "iopub.status.idle": "2025-09-17T15:28:02.571619Z",
     "shell.execute_reply": "2025-09-17T15:28:02.570813Z"
    },
    "papermill": {
     "duration": 0.083185,
     "end_time": "2025-09-17T15:28:02.573912",
     "exception": false,
     "start_time": "2025-09-17T15:28:02.490727",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for val in model.parameters():\n",
    "    val.requires_grad = False\n",
    "    # setting all to TRUE\n",
    "\n",
    "for val in model.cell_transformer.parameters():\n",
    "    val.requires_grad = True\n",
    "for val in model.transformer.blocks[7].parameters():\n",
    "    val.requires_grad = True\n",
    "for i in model.transformer.blocks:\n",
    "    i.cross_attn.requires_grad = True\n",
    "# for val in model.compressor.parameters():\n",
    "#    val.requires_grad = True\n",
    "for val in model.cls_decoders[\"cell_type_ontology_term_id\"].parameters():\n",
    "    val.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9eb3daa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-17T15:28:02.602111Z",
     "iopub.status.busy": "2025-09-17T15:28:02.601679Z",
     "iopub.status.idle": "2025-09-17T15:28:02.695650Z",
     "shell.execute_reply": "2025-09-17T15:28:02.694763Z"
    },
    "papermill": {
     "duration": 0.109561,
     "end_time": "2025-09-17T15:28:02.697942",
     "exception": false,
     "start_time": "2025-09-17T15:28:02.588381",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def mmd_loss(X, Y):\n",
    "    \"\"\"\n",
    "    Compute Maximum Mean Discrepancy (MMD) loss between two 2D embedding matrices.\n",
    "\n",
    "    Args:\n",
    "        X: Tensor of shape (n1, emb_dim) - first set of embeddings\n",
    "        Y: Tensor of shape (n2, emb_dim) - second set of embeddings\n",
    "\n",
    "    Returns:\n",
    "        MMD loss value (negative to encourage dissimilarity)\n",
    "    \"\"\"\n",
    "\n",
    "    def rbf_kernel(x, y, sigma):\n",
    "        \"\"\"Compute RBF kernel between two sets of vectors\"\"\"\n",
    "        distance = torch.cdist(x, y, p=2) ** 2\n",
    "        return torch.exp(-distance / (2 * sigma**2))\n",
    "\n",
    "    def energy_kernel(x, y):\n",
    "        \"\"\"Compute Energy kernel between two sets of vectors\"\"\"\n",
    "        distance = torch.cdist(x, y, p=2)\n",
    "        return -distance\n",
    "\n",
    "    # Use multiple kernel bandwidths for better performance\n",
    "    sigmas = [0]  # [0.1, 1.0, 10.0]\n",
    "    mmd_loss = 0.0\n",
    "\n",
    "    for sigma in sigmas:\n",
    "        # K(X, X) - kernel matrix within first group (n1 x n1)\n",
    "        # k_xx = rbf_kernel(X, X, sigma)\n",
    "        k_xx = energy_kernel(X, X)\n",
    "        # K(Y, Y) - kernel matrix within second group (n2 x n2)\n",
    "        # k_yy = rbf_kernel(Y, Y, sigma)\n",
    "        k_yy = energy_kernel(Y, Y)\n",
    "        # K(X, Y) - kernel matrix between groups (n1 x n2)\n",
    "        # k_xy = rbf_kernel(X, Y, sigma)\n",
    "        k_xy = energy_kernel(X, Y)\n",
    "\n",
    "        # Unbiased MMD estimation\n",
    "        n1 = X.shape[0]\n",
    "        n2 = Y.shape[0]\n",
    "\n",
    "        # Remove diagonal elements for unbiased estimation of K(X,X) and K(Y,Y)\n",
    "        # For K(X,X): exclude diagonal\n",
    "        if n1 > 1:\n",
    "            mask_xx = 1 - torch.eye(n1, device=X.device)\n",
    "            k_xx_term = (k_xx * mask_xx).sum() / (n1 * (n1 - 1))\n",
    "        else:\n",
    "            k_xx_term = 0.0\n",
    "\n",
    "        # For K(Y,Y): exclude diagonal\n",
    "        if n2 > 1:\n",
    "            mask_yy = 1 - torch.eye(n2, device=Y.device)\n",
    "            k_yy_term = (k_yy * mask_yy).sum() / (n2 * (n2 - 1))\n",
    "        else:\n",
    "            k_yy_term = 0.0\n",
    "\n",
    "        # For K(X,Y): use all elements (no diagonal to exclude)\n",
    "        k_xy_term = k_xy.mean()\n",
    "\n",
    "        # MMD^2 = E[K(X,X)] + E[K(Y,Y)] - 2*E[K(X,Y)]\n",
    "        mmd_squared = k_xx_term + k_yy_term - 2 * k_xy_term\n",
    "        mmd_loss += mmd_squared\n",
    "\n",
    "    # Return negative MMD to encourage dissimilarity (higher MMD = more different)\n",
    "    return mmd_loss / len(sigmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c28ce78",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-17T15:28:02.727698Z",
     "iopub.status.busy": "2025-09-17T15:28:02.727097Z",
     "iopub.status.idle": "2025-09-17T15:28:02.828638Z",
     "shell.execute_reply": "2025-09-17T15:28:02.827760Z"
    },
    "papermill": {
     "duration": 0.118252,
     "end_time": "2025-09-17T15:28:02.831046",
     "exception": false,
     "start_time": "2025-09-17T15:28:02.712794",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def batch_corr_pass(batch):\n",
    "    gene_pos = batch[\"genes\"].to(model.device)\n",
    "    expression = batch[\"x\"].to(model.device)\n",
    "    depth = batch[\"depth\"].to(model.device)\n",
    "    class_elem = batch[\"class\"].long().to(model.device)\n",
    "    total_loss = 0\n",
    "\n",
    "    # Forward pass with automatic mixed precisio^n\n",
    "    with torch.cuda.amp.autocast():\n",
    "        # Forward pass\n",
    "        output = model.forward(\n",
    "            gene_pos,\n",
    "            expression,\n",
    "            req_depth=depth,\n",
    "            depth_mult=expression.sum(1),\n",
    "            do_class=True,\n",
    "            metacell_token=torch.zeros_like(depth),\n",
    "        )\n",
    "        ## adaptor on ct_emb\n",
    "        # ctpos = model.classes.index(\"cell_type_ontology_term_id\") + 1\n",
    "        # emb = output[\"output_cell_embs\"][:, ctpos, :]\n",
    "        #\n",
    "        # output[\"output_cell_embs\"][:, ctpos, :] = adaptor_layer(\n",
    "        #    torch.cat([emb, class_elem[:, 1].unsqueeze(1).float()], dim=1)\n",
    "        # )\n",
    "\n",
    "        batch_pos = model.classes.index(\"organism_ontology_term_id\") + 1\n",
    "        output[\"output_cell_embs\"][:, batch_pos, :] = batch_emb(class_elem[:, 1])\n",
    "\n",
    "        ## generate expr loss\n",
    "        output_gen = model._generate(\n",
    "            cell_embs=output[\"output_cell_embs\"],\n",
    "            gene_pos=gene_pos,\n",
    "            depth_mult=expression.sum(1),\n",
    "            req_depth=depth,\n",
    "        )\n",
    "        if \"zero_logits\" in output_gen:\n",
    "            loss_expr = loss.zinb(\n",
    "                theta=output_gen[\"disp\"],\n",
    "                pi=output_gen[\"zero_logits\"],\n",
    "                mu=output_gen[\"mean\"],\n",
    "                target=expression,\n",
    "            )\n",
    "            if model.zinb_and_mse:\n",
    "                loss_expr += (\n",
    "                    loss.mse(\n",
    "                        input=torch.log(output_gen[\"mean\"] + 1)\n",
    "                        * (1 - torch.sigmoid(output_gen[\"zero_logits\"])),\n",
    "                        target=torch.log(expression + 1),\n",
    "                    )\n",
    "                    / 10  # scale to make it more similar to the zinb\n",
    "                )\n",
    "        else:\n",
    "            loss_expr = loss.mse(\n",
    "                input=torch.log(output_gen[\"mean\"] + 1),\n",
    "                target=torch.log(expression + 1),\n",
    "            )\n",
    "        # Add expression loss to total\n",
    "        total_loss += loss_expr\n",
    "\n",
    "        # ct clss\n",
    "        cls_output = output.get(\"cls_output_cell_type_ontology_term_id\")\n",
    "        # ct_output = output[\"output_cell_embs\"][:, ctpos, :]\n",
    "        # cls_output = model.cls_decoders[\"cell_type_ontology_term_id\"](ct_output)\n",
    "        cls_loss = loss.hierarchical_classification(\n",
    "            pred=cls_output,\n",
    "            cl=class_elem[:, 0],\n",
    "            labels_hierarchy=model.mat_labels_hierarchy.get(\n",
    "                \"cell_type_ontology_term_id\"\n",
    "            ).to(\"cuda\"),\n",
    "        )\n",
    "\n",
    "        org_emb = output[\n",
    "            \"input_cell_embs\" if model.compressor is None else \"compressed_cell_embs\"\n",
    "        ][:, model.classes.index(\"organism_ontology_term_id\") + 1]\n",
    "        cls_loss += F.cross_entropy(\n",
    "            input=batch_cls(org_emb),\n",
    "            target=class_elem[:, 1],\n",
    "        )\n",
    "        total_loss += cls_loss\n",
    "\n",
    "        pos = model.classes.index(\"cell_type_ontology_term_id\") + 1\n",
    "        # Apply gradient reversal to the input embedding\n",
    "        selected_emb = (\n",
    "            output[\"compressed_cell_embs\"][pos]\n",
    "            if model.compressor is not None\n",
    "            else output[\"input_cell_embs\"][:, pos, :]\n",
    "        )\n",
    "        X, Y = selected_emb[class_elem[:, 1] == 1], selected_emb[class_elem[:, 1] == 0]\n",
    "\n",
    "        mmd = mmd_loss(X, Y)\n",
    "        if torch.isnan(mmd):\n",
    "            print(\"mmd nan\")\n",
    "        mmd = mmd.item() if not torch.isnan(mmd) else 0\n",
    "\n",
    "        # Add adversarial loss to total loss\n",
    "        total_loss += mmd * 3\n",
    "        # total_loss += output[\"vae_kl_loss\"] * 0.001\n",
    "    return total_loss, cls_loss, loss_expr, mmd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771be887",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-17T15:28:02.859972Z",
     "iopub.status.busy": "2025-09-17T15:28:02.859561Z",
     "iopub.status.idle": "2025-09-17T15:28:02.952098Z",
     "shell.execute_reply": "2025-09-17T15:28:02.951179Z"
    },
    "papermill": {
     "duration": 0.108652,
     "end_time": "2025-09-17T15:28:02.954535",
     "exception": false,
     "start_time": "2025-09-17T15:28:02.845883",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_72068/2033321161.py:26: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler() if torch.cuda.is_available() else None\n"
     ]
    }
   ],
   "source": [
    "# Alternative: Manual Training Loop (for more control)\n",
    "# If you prefer to have more control over the training process\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "from scprint.model import loss\n",
    "\n",
    "num_epochs = 8\n",
    "lr = 0.0002\n",
    "\n",
    "# Setup optimizer\n",
    "all_params = (\n",
    "    list(model.parameters())\n",
    "    + list(batch_cls.parameters())\n",
    "    + list(batch_emb.parameters())\n",
    ")\n",
    "optimizer = torch.optim.AdamW(\n",
    "    all_params, lr=lr, weight_decay=0.01, betas=(0.9, 0.999), eps=1e-8\n",
    ")\n",
    "\n",
    "# Setup scheduler\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode=\"min\", factor=0.2, patience=1\n",
    ")\n",
    "\n",
    "# Setup automatic mixed precision\n",
    "scaler = torch.cuda.amp.GradScaler() if torch.cuda.is_available() else None\n",
    "\n",
    "_ = model.train()\n",
    "\n",
    "for k, i in model.mat_labels_hierarchy.items():\n",
    "    model.mat_labels_hierarchy[k] = i.to(model.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06917e6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-29T09:52:20.405972Z",
     "iopub.status.busy": "2025-09-29T09:52:20.405829Z",
     "iopub.status.idle": "2025-09-29T10:08:55.187257Z",
     "shell.execute_reply": "2025-09-29T10:08:55.186662Z"
    },
    "papermill": {
     "duration": 994.793516,
     "end_time": "2025-09-29T10:08:55.193969",
     "exception": false,
     "start_time": "2025-09-29T09:52:20.400453",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/8\n",
      "Current learning rate: 2.00e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_72068/326240407.py:9: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The expanded size of the tensor (128) must match the existing size (256) at non-singleton dimension 1.  Target sizes: [1, 128].  Tensor sizes: [256]",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader):\n\u001b[32m     15\u001b[39m     optimizer.zero_grad()\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m     total_loss, cls_loss, loss_expr, mmd = \u001b[43mbatch_corr_pass\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     17\u001b[39m     \u001b[38;5;66;03m# Backward pass\u001b[39;00m\n\u001b[32m     18\u001b[39m     scaler.scale(total_loss).backward()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 28\u001b[39m, in \u001b[36mbatch_corr_pass\u001b[39m\u001b[34m(batch)\u001b[39m\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m## adaptor on ct_emb\u001b[39;00m\n\u001b[32m     20\u001b[39m \u001b[38;5;66;03m# ctpos = model.classes.index(\"cell_type_ontology_term_id\") + 1\u001b[39;00m\n\u001b[32m     21\u001b[39m \u001b[38;5;66;03m# emb = output[\"output_cell_embs\"][:, ctpos, :]\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     24\u001b[39m \u001b[38;5;66;03m#    torch.cat([emb, class_elem[:, 1].unsqueeze(1).float()], dim=1)\u001b[39;00m\n\u001b[32m     25\u001b[39m \u001b[38;5;66;03m# )\u001b[39;00m\n\u001b[32m     27\u001b[39m batch_pos = model.classes.index(\u001b[33m\"\u001b[39m\u001b[33morganism_ontology_term_id\u001b[39m\u001b[33m\"\u001b[39m) + \u001b[32m1\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m \u001b[43moutput\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43moutput_cell_embs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_pos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m = batch_emb(class_elem[:, \u001b[32m1\u001b[39m])\n\u001b[32m     30\u001b[39m \u001b[38;5;66;03m## generate expr loss\u001b[39;00m\n\u001b[32m     31\u001b[39m output_gen = model._generate(\n\u001b[32m     32\u001b[39m     cell_embs=output[\u001b[33m\"\u001b[39m\u001b[33moutput_cell_embs\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m     33\u001b[39m     gene_pos=gene_pos,\n\u001b[32m     34\u001b[39m     depth_mult=expression.sum(\u001b[32m1\u001b[39m),\n\u001b[32m     35\u001b[39m     req_depth=depth,\n\u001b[32m     36\u001b[39m )\n",
      "\u001b[31mRuntimeError\u001b[39m: The expanded size of the tensor (128) must match the existing size (256) at non-singleton dimension 1.  Target sizes: [1, 128].  Tensor sizes: [256]"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    print(f\"\\nEpoch {epoch + 1}/{num_epochs}\")\n",
    "    print(f\"Current learning rate: {optimizer.param_groups[0]['lr']:.2e}\")\n",
    "\n",
    "    # Training phase\n",
    "    train_loss = 0.0\n",
    "    train_steps = 0\n",
    "    avg_adv = 0\n",
    "    avg_expr = 0\n",
    "    avg_cls = 0\n",
    "    avg_mmd = 0\n",
    "\n",
    "    # pbar = tqdm(train_loader, desc=\"Training\")\n",
    "    for batch_idx, batch in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        total_loss, cls_loss, loss_expr, mmd = batch_corr_pass(batch)\n",
    "        # Backward pass\n",
    "        scaler.scale(total_loss).backward()\n",
    "        scaler.unscale_(optimizer)\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        train_loss += total_loss.item()\n",
    "        train_steps += 1\n",
    "        avg_cls += cls_loss.item()\n",
    "        avg_expr += loss_expr.item()\n",
    "        avg_mmd += mmd\n",
    "        # Update progress bar\n",
    "        # if batch_idx % 35 == 0:\n",
    "        # print(\n",
    "        #    f\"avg_loss {train_loss / train_steps:.4f}, avg_cls {avg_cls / train_steps:.4f}, avg_expr {avg_expr / train_steps:.4f}, avg_adv {avg_mmd/ train_steps:.4f}\"\n",
    "        # )\n",
    "        # pbar.set_postfix(\n",
    "        #    {\n",
    "        #        \"loss\": f\"{total_loss.item():.4f}\",\n",
    "        #        \"avg_loss\": f\"{train_loss / train_steps:.4f}\",\n",
    "        #        \"cls_loss\": f\"{cls_loss.item():.4f}\",\n",
    "        #        \"mmd_loss\": f\"{mmd:.4f}\",\n",
    "        #        \"expr_loss\": f\"{loss_expr.item():.4f}\",\n",
    "        #    }\n",
    "        # )\n",
    "\n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_steps = 0\n",
    "    val_loss_expr = 0.0\n",
    "    val_mmd = 0.0\n",
    "    val_cls = 0.0\n",
    "    val_loss_to_prt = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:  # tqdm(val_loader, desc=\"Validation\"):\n",
    "            loss_val, cls_loss, loss_expr, mmd = batch_corr_pass(batch)\n",
    "            val_loss_to_prt += loss_val.item()\n",
    "            val_loss += loss_val.item()\n",
    "            val_steps += 1\n",
    "            val_loss_expr += loss_expr.item()\n",
    "            val_mmd += mmd\n",
    "            val_cls += cls_loss.item()\n",
    "    try:\n",
    "        avg_val_loss = val_loss_to_prt / val_steps\n",
    "        avg_train_loss = train_loss / train_steps\n",
    "    except ZeroDivisionError:\n",
    "        print(\"Error: Division by zero occurred while calculating average losses.\")\n",
    "        avg_train_loss = 0\n",
    "    print(\n",
    "        \"cls_loss: {:.4f}, mmd_loss: {:.4f}, expr_loss: {:.4f}\".format(\n",
    "            val_cls / val_steps, val_mmd / val_steps, val_loss_expr / val_steps\n",
    "        )\n",
    "    )\n",
    "    print(f\"Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "    # Store LR before scheduler step for comparison\n",
    "    lr_before = optimizer.param_groups[0][\"lr\"]\n",
    "\n",
    "    # Update learning rate\n",
    "    scheduler.step(avg_val_loss)\n",
    "\n",
    "    # Check if LR was reduced\n",
    "    lr_after = optimizer.param_groups[0][\"lr\"]\n",
    "    if lr_after < lr_before:\n",
    "        print(\n",
    "            f\"ðŸ”» Learning rate reduced from {lr_before:.2e} to {lr_after:.2e} (factor: {lr_after / lr_before:.3f})\"\n",
    "        )\n",
    "    else:\n",
    "        print(f\"âœ… Learning rate unchanged: {lr_after:.2e}\")\n",
    "\n",
    "    # Early stopping check (simple implementation)\n",
    "    if epoch > 3 and val_loss / val_steps > 1.3 * avg_train_loss:\n",
    "        print(\"Early stopping due to overfitting\")\n",
    "        break\n",
    "\n",
    "print(\"Manual fine-tuning completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98646e5b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-29T10:08:55.205316Z",
     "iopub.status.busy": "2025-09-29T10:08:55.205148Z",
     "iopub.status.idle": "2025-09-29T10:09:00.399271Z",
     "shell.execute_reply": "2025-09-29T10:09:00.398745Z"
    },
    "papermill": {
     "duration": 5.201081,
     "end_time": "2025-09-29T10:09:00.400217",
     "exception": false,
     "start_time": "2025-09-29T10:08:55.199136",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import lightning as L\n",
    "\n",
    "checkpoint = {\n",
    "    \"epoch\": epoch,\n",
    "    \"global_step\": (1 + epoch) * batch_idx,\n",
    "    \"pytorch-lightning_version\": L.__version__,\n",
    "    \"state_dict\": model.state_dict(),\n",
    "    \"optimizer_states\": [optimizer.state_dict()],\n",
    "    \"lr_schedulers\": [scheduler.state_dict()],\n",
    "    \"hparams_name\": None,\n",
    "    \"loops\": None,\n",
    "    \"callbacks\": None,\n",
    "    \"hyper_parameters\": model.hparams,\n",
    "}\n",
    "torch.save(checkpoint, \"fit_2.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f048ab6f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-17T14:38:25.931554Z",
     "iopub.status.busy": "2025-09-17T14:38:25.930923Z",
     "iopub.status.idle": "2025-09-17T14:38:26.028879Z",
     "shell.execute_reply": "2025-09-17T14:38:26.027330Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model.load_state_dict(torch.load(\"fit_2.ckpt\")[\"state_dict\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6daa4847",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-17T14:38:26.065779Z",
     "iopub.status.busy": "2025-09-17T14:38:26.065174Z",
     "iopub.status.idle": "2025-09-17T14:38:44.231575Z",
     "shell.execute_reply": "2025-09-17T14:38:44.230393Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = scPrint.load_from_checkpoint(\n",
    "    \"fit_2.ckpt\", precpt_gene_emb=None, attention=\"normal\"\n",
    ")\n",
    "model = model.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f5c43a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-17T14:38:44.267886Z",
     "iopub.status.busy": "2025-09-17T14:38:44.267679Z",
     "iopub.status.idle": "2025-09-17T14:38:44.327038Z",
     "shell.execute_reply": "2025-09-17T14:38:44.326200Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "da.obs = da.obs.iloc[:, :-15]\n",
    "for i in [\n",
    "    \"scprint_emb\",\n",
    "    \"scprint_emb_age_group\",\n",
    "    \"scprint_emb_assay_ontology_term_id\",\n",
    "    \"scprint_emb_cell_culture\",\n",
    "    \"scprint_emb_cell_type_ontology_term_id\",\n",
    "    \"scprint_emb_disease_ontology_term_id\",\n",
    "    \"scprint_emb_organism_ontology_term_id\",\n",
    "    \"scprint_emb_other\",\n",
    "    \"scprint_emb_self_reported_ethnicity_ontology_term_id\",\n",
    "    \"scprint_emb_sex_ontology_term_id\",\n",
    "    \"scprint_emb_tissue_ontology_term_id\",\n",
    "]:\n",
    "    da.obsm.pop(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630a13f9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-17T14:38:44.361828Z",
     "iopub.status.busy": "2025-09-17T14:38:44.361452Z",
     "iopub.status.idle": "2025-09-17T14:38:44.436825Z",
     "shell.execute_reply": "2025-09-17T14:38:44.435986Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "embed = Embedder(\n",
    "    how=\"random expr\",\n",
    "    max_len=2800,\n",
    "    num_workers=8,\n",
    "    pred_embedding=[\"all\"],\n",
    "    doplot=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75bb7590",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-17T14:38:44.472931Z",
     "iopub.status.busy": "2025-09-17T14:38:44.472394Z",
     "iopub.status.idle": "2025-09-17T14:45:12.987034Z",
     "shell.execute_reply": "2025-09-17T14:45:12.981321Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_adata, metrics = embed(model, da.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56806e1d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-17T14:45:13.110599Z",
     "iopub.status.busy": "2025-09-17T14:45:13.109553Z",
     "iopub.status.idle": "2025-09-17T14:45:17.369742Z",
     "shell.execute_reply": "2025-09-17T14:45:17.368196Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "compute_classification(\n",
    "    n_adata,\n",
    "    [\"cell_type_ontology_term_id\"],\n",
    "    label_decoders=model.label_decoders,\n",
    "    labels_hierarchy=model.labels_hierarchy,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40bbeed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-17T14:45:17.484969Z",
     "iopub.status.busy": "2025-09-17T14:45:17.484342Z",
     "iopub.status.idle": "2025-09-17T14:46:11.816463Z",
     "shell.execute_reply": "2025-09-17T14:46:11.814993Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sc.pp.neighbors(n_adata, use_rep=\"scprint_emb_cell_type_ontology_term_id\")\n",
    "sc.tl.umap(n_adata)\n",
    "sc.pl.umap(\n",
    "    n_adata,\n",
    "    color=[\"conv_pred_cell_type_ontology_term_id\", \"cell_type\", \"batch\"],\n",
    "    ncols=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "887818f4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-17T14:46:11.964168Z",
     "iopub.status.busy": "2025-09-17T14:46:11.963493Z",
     "iopub.status.idle": "2025-09-17T14:46:31.623052Z",
     "shell.execute_reply": "2025-09-17T14:46:31.622259Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sc.pp.neighbors(n_adata, use_rep=\"scprint_emb\")\n",
    "sc.tl.umap(n_adata)\n",
    "sc.pl.umap(\n",
    "    n_adata,\n",
    "    color=[\"conv_pred_cell_type_ontology_term_id\", \"cell_type\", \"batch\"],\n",
    "    ncols=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58cd187",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-17T14:46:31.799300Z",
     "iopub.status.busy": "2025-09-17T14:46:31.798644Z",
     "iopub.status.idle": "2025-09-17T14:48:58.178129Z",
     "shell.execute_reply": "2025-09-17T14:48:58.176431Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "bm = Benchmarker(\n",
    "    n_adata,\n",
    "    batch_key=\"batch\",  # batch, tech, assay_ontology_term_id, donor_id\n",
    "    label_key=\"cell_type_ontology_term_id\",  # celltype\n",
    "    embedding_obsm_keys=[\"scprint_emb_cell_type_ontology_term_id\"],\n",
    "    bio_conservation_metrics=BioConservation(),\n",
    "    batch_correction_metrics=BatchCorrection(),\n",
    "    n_jobs=10,\n",
    ")\n",
    "bm.benchmark()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813cd5c9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-17T14:48:58.369818Z",
     "iopub.status.busy": "2025-09-17T14:48:58.369166Z",
     "iopub.status.idle": "2025-09-17T14:48:58.703378Z",
     "shell.execute_reply": "2025-09-17T14:48:58.701807Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# after fine tuning\n",
    "bm.plot_results_table(min_max_scale=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scPRINT (.venv)",
   "language": "python",
   "name": "scprint-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 203.438373,
   "end_time": "2025-09-17T15:28:09.167342",
   "environment_variables": {},
   "exception": null,
   "input_path": "fine_tuning_cross_species_emb_mmd.ipynb",
   "output_path": "fine_tuning_cross_species_emb_mmd.ipynb",
   "parameters": {},
   "start_time": "2025-09-17T15:24:45.728969",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
