{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ]
        }
      ],
      "source": [
        "#! lamin init --storage ./lamin-intro --schema bionty \n",
        "\n",
        "import scanpy as sc\n",
        "from scprint import scPrint\n",
        "from scdataloader import Preprocessor\n",
        "from scdataloader.utils import load_genes\n",
        "import numpy as np\n",
        "import anndata as ad\n",
        "from huggingface_hub import hf_hub_download\n",
        "\n",
        "from scprint.tasks import Denoiser, withknn\n",
        "from scprint.model.utils import downsample_profile\n",
        "from scipy.stats import spearmanr\n",
        "from anndata import AnnData\n",
        "\n",
        "import seaborn as sns\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "import torch\n",
        "torch.set_float32_matmul_precision('medium')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "#model_checkpoint_file = hf_hub_download(\n",
        "#    repo_id=\"jkobject/scPRINT\", filename=f\"v2-medium.ckpt\"\n",
        "#)\n",
        "#model_checkpoint_file = ../data/\n",
        "model_checkpoint_file = '../../../80vhz9uh_init.ckpt'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "m = torch.load(model_checkpoint_file)\n",
        "m['hyper_parameters']['label_decoders'] = {k:{u: str(w) for u,w in v.items()} for k,v in m['hyper_parameters']['label_decoders'].items()}\n",
        "m['hyper_parameters']['organisms'] = [\"NCBITaxon:10090\", \"NCBITaxon:9606\"]\n",
        "torch.save(m, model_checkpoint_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FYI: scPrint is not attached to a `Trainer`.\n"
          ]
        }
      ],
      "source": [
        "model = scPrint.load_from_checkpoint(model_checkpoint_file, use_metacell_token=True, precpt_gene_emb=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "m = torch.load(model_checkpoint_file)\n",
        "if \"prenorm\" in m['hyper_parameters']:\n",
        "    m['hyper_parameters'].pop(\"prenorm\")\n",
        "    torch.save(m, model_checkpoint_file)\n",
        "if \"label_counts\" in m['hyper_parameters']:\n",
        "    model = scPrint.load_from_checkpoint(model_checkpoint_file, precpt_gene_emb=None, classes=m['hyper_parameters']['label_counts'])\n",
        "else:\n",
        "    model = scPrint.load_from_checkpoint(model_checkpoint_file, precpt_gene_emb=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/ml4ig1/Documents code/scDataLoader/scdataloader/utils.py:372: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  organismdf = pd.concat(organismdf)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "set()"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "genes = load_genes(model.organisms)\n",
        "set(model.genes) - set(genes.index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Get indices of genes that exist in genes. index\n",
        "valid_indices = [i for i in range(len(model.genes)) if model.genes[i] in genes.index]\n",
        "# Create-new •embedding-weights tensor with only valid genes new _weights -=-model.gene_encoder[01.embeddings.weight[valid_indices]\n",
        "# Create- new-embedding layer with-correct size\n",
        "new_embeddings = torch.nn.Embedding(len(valid_indices), model.gene_encoder[0].embeddings.embedding_dim, device=model.device)\n",
        "#Copy the-weights-to-the new-embedding-layer new_embeddings.weight.data.= new_weights\n",
        "#-Replace the old •embeddings with the new one\n",
        "model.gene_encoder[0].embeddings = new_embeddings\n",
        "model.genes = [i for i in model.genes if i in genes.index]\n",
        "\n",
        "model = model.to(model.device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dropping layers:  KeysView(Layers with keys: )\n",
            "checking raw counts\n",
            "removed 0 non primary cells, 51370 renamining\n",
            "filtered out 0 cells, 51370 renamining\n",
            "Removed 82 genes not known to the ontology\n",
            "Removed 0 duplicate genes\n",
            "Added 670 genes in the ontology but not present in the dataset\n",
            "validating\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/ml4ig1/Documents code/scDataLoader/scdataloader/preprocess.py:281: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  adata, organism=adata.obs.organism_ontology_term_id[0], need_all=False\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "starting QC\n",
            "Seeing 22952 outliers (44.68% of total dataset):\n",
            "done\n",
            "AnnData object with n_obs × n_vars = 51370 × 70704\n",
            "    obs: 'biosample_id', 'donor_id', 'cell_type_ontology_term_id', 'organism_ontology_term_id', 'disease_ontology_term_id', 'tissue_ontology_term_id', 'assay_ontology_term_id', 'cell_type__custom', 'development_stage_ontology_term_id', 'sex_ontology_term_id', 'suspension_type', 'is_primary_data', 'age', 'self_reported_ethnicity_ontology_term_id', 'cell_type', 'assay', 'disease', 'organism', 'sex', 'tissue', 'self_reported_ethnicity', 'development_stage', 'cell_culture', 'nnz', 'n_genes_by_counts', 'log1p_n_genes_by_counts', 'total_counts', 'log1p_total_counts', 'pct_counts_in_top_20_genes', 'total_counts_mt', 'log1p_total_counts_mt', 'pct_counts_mt', 'total_counts_ribo', 'log1p_total_counts_ribo', 'pct_counts_ribo', 'total_counts_hb', 'log1p_total_counts_hb', 'pct_counts_hb', 'outlier', 'mt_outlier', 'n_genes'\n",
            "    var: 'feature_is_filtered', 'feature_name', 'feature_reference', 'feature_biotype', 'uid_x', 'symbol_x', 'ncbi_gene_ids', 'biotype_x', 'description', 'synonyms', 'organism_id_x', 'public_source_id', 'created_by_id', 'mt_x', 'ribo_x', 'hb_x', 'organism_x', 'n_cells_by_counts', 'mean_counts', 'log1p_mean_counts', 'pct_dropout_by_counts', 'total_counts', 'log1p_total_counts', 'uid_y', 'symbol_y', 'biotype_y', 'organism_id_y', 'mt_y', 'ribo_y', 'hb_y', 'organism_y', 'ensembl_gene_id', 'uid', 'symbol', 'biotype', 'organism_id', 'mt', 'ribo', 'hb', 'organism'\n",
            "    uns: 'unseen_genes'\n",
            "working on 2557 accepted genes\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/ml4ig1/Documents code/scDataLoader/scdataloader/utils.py:372: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  organismdf = pd.concat(organismdf)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "> \u001b[0;32m/home/ml4ig1/Documents code/scPRINT/scprint/tasks/denoise.py\u001b[0m(138)\u001b[0;36m__call__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m    136 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m    137 \u001b[0;31m        \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m--> 138 \u001b[0;31m        \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautocast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m    139 \u001b[0;31m            \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m    140 \u001b[0;31m                gene_pos, expression, depth = (\n",
            "\u001b[0m\n",
            "> \u001b[0;32m/home/ml4ig1/Documents code/scPRINT/scprint/tasks/denoise.py\u001b[0m(139)\u001b[0;36m__call__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m    137 \u001b[0;31m        \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m    138 \u001b[0;31m        \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautocast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m--> 139 \u001b[0;31m            \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m    140 \u001b[0;31m                gene_pos, expression, depth = (\n",
            "\u001b[0m\u001b[0;32m    141 \u001b[0;31m                    \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"genes\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/750 [00:00<?, ?it/s]Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fcb96baca60>\n",
            "Traceback (most recent call last):\n",
            "  File \"/home/ml4ig1/miniconda3/envs/scprnt2/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
            "    self._shutdown_workers()Exception ignored in: \n",
            "  File \"/home/ml4ig1/miniconda3/envs/scprnt2/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
            "<function _MultiProcessingDataLoaderIter.__del__ at 0x7fcb96baca60>    \n",
            "if w.is_alive():Traceback (most recent call last):\n",
            "\n",
            "  File \"/home/ml4ig1/miniconda3/envs/scprnt2/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
            "  File \"/home/ml4ig1/miniconda3/envs/scprnt2/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "        self._shutdown_workers()assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "\n",
            "  File \"/home/ml4ig1/miniconda3/envs/scprnt2/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
            "AssertionError:     can only test a child processif w.is_alive():\n",
            "\n",
            "  File \"/home/ml4ig1/miniconda3/envs/scprnt2/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fcb96baca60>\n",
            "Traceback (most recent call last):\n",
            "  File \"/home/ml4ig1/miniconda3/envs/scprnt2/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/home/ml4ig1/miniconda3/envs/scprnt2/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/home/ml4ig1/miniconda3/envs/scprnt2/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fcb96baca60>\n",
            "Traceback (most recent call last):\n",
            "  File \"/home/ml4ig1/miniconda3/envs/scprnt2/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/home/ml4ig1/miniconda3/envs/scprnt2/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/home/ml4ig1/miniconda3/envs/scprnt2/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "> \u001b[0;32m/home/ml4ig1/Documents code/scPRINT/scprint/tasks/denoise.py\u001b[0m(141)\u001b[0;36m__call__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m    139 \u001b[0;31m            \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m    140 \u001b[0;31m                gene_pos, expression, depth = (\n",
            "\u001b[0m\u001b[0;32m--> 141 \u001b[0;31m                    \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"genes\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m    142 \u001b[0;31m                    \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"x\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m    143 \u001b[0;31m                    \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"depth\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\n",
            "> \u001b[0;32m/home/ml4ig1/Documents code/scPRINT/scprint/tasks/denoise.py\u001b[0m(142)\u001b[0;36m__call__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m    140 \u001b[0;31m                gene_pos, expression, depth = (\n",
            "\u001b[0m\u001b[0;32m    141 \u001b[0;31m                    \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"genes\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m--> 142 \u001b[0;31m                    \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"x\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m    143 \u001b[0;31m                    \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"depth\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m    144 \u001b[0;31m                )\n",
            "\u001b[0m\n",
            "tensor([[21605, 21622, 21624,  ..., 43395, 43407, 44002],\n",
            "        [21605, 21622, 21624,  ..., 43395, 43407, 44002],\n",
            "        [21605, 21622, 21624,  ..., 43395, 43407, 44002],\n",
            "        ...,\n",
            "        [21605, 21622, 21624,  ..., 43395, 43407, 44002],\n",
            "        [21605, 21622, 21624,  ..., 43395, 43407, 44002],\n",
            "        [21605, 21622, 21624,  ..., 43395, 43407, 44002]], dtype=torch.int32)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 750/750 [03:08<00:00,  3.98it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "AnnData object with n_obs × n_vars = 30000 × 44741\n",
            "    obs: 'pred_cell_type_ontology_term_id', 'pred_tissue_ontology_term_id', 'pred_disease_ontology_term_id', 'pred_assay_ontology_term_id', 'pred_self_reported_ethnicity_ontology_term_id', 'pred_sex_ontology_term_id', 'pred_organism_ontology_term_id', 'conv_pred_cell_type_ontology_term_id', 'conv_pred_tissue_ontology_term_id', 'conv_pred_disease_ontology_term_id', 'conv_pred_assay_ontology_term_id', 'conv_pred_self_reported_ethnicity_ontology_term_id'\n",
            "    obsm: 'scprint_emb'\n",
            "    layers: 'scprint_mu', 'scprint_theta', 'scprint_pi'\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'reco2noisy': 0.03821803058006762,\n",
              " 'reco2full': 0.062068988001814755,\n",
              " 'noisy2full': 0.37211679148539006}"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "adata = sc.read(\"../../data/temp/gNNpgpo6gATjuxTE7CCp.h5ad\")\n",
        "max_len = 4000\n",
        "preprocessor = Preprocessor(\n",
        "    force_preprocess=True,\n",
        "    skip_validate=True,\n",
        "    #drop_non_primary=False,\n",
        "    do_postp=False\n",
        ")\n",
        "preprocessor = Preprocessor(do_postp=False)\n",
        "adata = preprocessor(adata)\n",
        "adata.layers['true'] = adata.X.copy()\n",
        "denoise = Denoiser(\n",
        "    batch_size=40,\n",
        "    max_len=max_len,\n",
        "    max_cells=30_000,\n",
        "    doplot=False,\n",
        "    num_workers=8,\n",
        "    predict_depth_mult=5,\n",
        "    downsample_expr=0.7,\n",
        ")\n",
        "metrics, idx, nadata = denoise(model, adata)\n",
        "metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "stdata = stdata[:, [\"BLANK\" not in i and \"NegControl\" not in i for i in stdata.var.index.tolist()]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, axs = plt.subplots(1, 2, figsize=(15, 4))\n",
        "\n",
        "axs[0].set_title(\"Total transcripts per cell\")\n",
        "sns.histplot(\n",
        "    stdata.obs[\"total_counts\"],\n",
        "    kde=False,\n",
        "    ax=axs[0],\n",
        ")\n",
        "\n",
        "axs[1].set_title(\"Unique transcripts per cell\")\n",
        "sns.histplot(\n",
        "    stdata.obs[\"n_genes_by_counts\"],\n",
        "    kde=False,\n",
        "    ax=axs[1],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# spec xenium \n",
        "stdata = stdata[:, [\"BLANK\" not in i and \"NegControl\" not in i for i in stdata.var.index.tolist()]]\n",
        "\n",
        "# set to 300, 1 for visium\n",
        "sc.pp.filter_cells(stdata, min_counts=50, )\n",
        "sc.pp.filter_genes(stdata, min_cells=5)\n",
        "\n",
        "stdata.layers[\"counts\"] = stdata.X.copy()\n",
        "sc.pp.normalize_total(stdata, inplace=True)\n",
        "sc.pp.log1p(stdata)\n",
        "sc.pp.pca(stdata)\n",
        "sc.pp.neighbors(stdata)\n",
        "sc.tl.umap(stdata)\n",
        "sc.tl.leiden(stdata)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sq.pl.spatial_scatter(\n",
        "    stdata,\n",
        "    library_id=\"spatial\",\n",
        "    shape=None,\n",
        "    color=[\n",
        "        \"leiden\",\n",
        "        \"total_counts\",\n",
        "    ],\n",
        "    wspace=0.4,\n",
        "    ncols=1,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "stdata = stdata[stdata.obs.leiden != \"0\", :]\n",
        "stdata = stdata.copy()\n",
        "stdata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# preprocess"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "embed = Embedder(how=\"most var\", max_len=500, add_zero_genes=0, num_workers=16, pred_embedding = [\"cell_type_ontology_term_id\"], keep_all_cls_pred=False, output_expression=\"none\", batch_size=64)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "scprnt2",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}