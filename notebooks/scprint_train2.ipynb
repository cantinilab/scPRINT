{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m→\u001b[0m connected lamindb: jkobject/scprint2\n"
     ]
    }
   ],
   "source": [
    "! lamin load jkobject/scprint2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m→\u001b[0m connected lamindb: jkobject/scprint2\n"
     ]
    }
   ],
   "source": [
    "from lightning.pytorch import Trainer, seed_everything\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint, StochasticWeightAveraging, EarlyStopping, LearningRateMonitor, LearningRateFinder\n",
    "\n",
    "seed_everything(42, workers=True)\n",
    "\n",
    "\n",
    "from scprint import scPrint\n",
    "from scprint.trainer import TrainingMode\n",
    "from scdataloader import DataModule \n",
    "import pandas as pd\n",
    "from scdataloader.utils import load_genes\n",
    "import lamindb as ln\n",
    "\n",
    "import torch\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: drop tissue & dev stage until part or is taken in account\n",
    "\n",
    "hierarchical_clss = [\n",
    "    \"cell_type_ontology_term_id\",  # 1\n",
    "    \"tissue_ontology_term_id\",\n",
    "    \"disease_ontology_term_id\",  # 2\n",
    "    \"simplified_dev_stage\",\n",
    "    \"assay_ontology_term_id\",  # 3\n",
    "    'self_reported_ethnicity_ontology_term_id',  # 4\n",
    "]\n",
    "clss_to_predict = hierarchical_clss+[\n",
    "    'sex_ontology_term_id',  # 5\n",
    "    \"organism_ontology_term_id\",  # 6\n",
    "    \"cell_culture\"\n",
    "]\n",
    "clss_to_weight = [\n",
    "    \"tissue_ontology_term_id\",\n",
    "    \"disease_ontology_term_id\",\n",
    "    \"simplified_dev_stage\",\n",
    "    \"assay_ontology_term_id\",\n",
    "    \"organism_ontology_term_id\",\n",
    "    \"clust_cell_type\",\n",
    "    # 'dataset_id',\n",
    "    # 'cell_culture',\n",
    "    #  \"heat_diff\",\n",
    "    #  \"total_counts\",\n",
    "    \"nnz\",\n",
    "    #  \"dpt_group\",\n",
    "]\n",
    "\n",
    "gene_emb = '../data/main/gene_embeddings.parquet'\n",
    "d_model = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93m!\u001b[0m no run & transform got linked, call `ln.track()` & re-run\n",
      "\u001b[93m!\u001b[0m run input wasn't tracked, call `ln.track()` and re-run\n",
      "\u001b[93m!\u001b[0m run input wasn't tracked, call `ln.track()` and re-run\n",
      "won't do any check but we recommend to have your dataset coming from local storage\n",
      "100.0% are aligned\n",
      "seeing a string: loading gene positions as biomart parquet file\n"
     ]
    }
   ],
   "source": [
    "datamodule = DataModule(\n",
    "    collection_name=\"scPRINT-V2 test\", #some, all, preprocessed dataset, all no zhang, \n",
    "    gene_embeddings=gene_emb,\n",
    "    clss_to_weight=clss_to_weight,\n",
    "    metacell_mode=True,\n",
    "    clss_to_predict=clss_to_predict,\n",
    "    hierarchical_clss=hierarchical_clss,\n",
    "    organisms=[\"NCBITaxon:9606\"],#, \"NCBITaxon:10090\"],\n",
    "    how=\"random expr\",\n",
    "    max_len=3200,\n",
    "    add_zero_genes=0,\n",
    "    # how much more you will see the most present vs less present category\n",
    "    weight_scaler=100,\n",
    "    batch_size=10,\n",
    "    num_workers=12,\n",
    "    train_oversampling_per_epoch=2,\n",
    "    validation_split=0.05,\n",
    "    do_gene_pos='../data/main/biomart_pos.parquet',\n",
    "    test_split=0.05)\n",
    "testfiles = datamodule.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = scPrint(\n",
    "    genes=datamodule.genes,\n",
    "    d_model=d_model*2,\n",
    "    nhead=2*2,\n",
    "    num_heads_kv=2,\n",
    "    nlayers=8,\n",
    "    layers_cls = [d_model],\n",
    "    classes = datamodule.classes,\n",
    "    labels_hierarchy = datamodule.labels_hierarchy,\n",
    "    dropout=0.1,\n",
    "    transformer=\"flash\",\n",
    "    precpt_gene_emb=gene_emb,\n",
    "    gene_pos_enc=datamodule.gene_pos,\n",
    "    mvc_decoder=\"inner product\",\n",
    "    label_decoders = datamodule.decoders,\n",
    "    fused_dropout_add_ln=False,\n",
    "    num_batch_labels = datamodule.num_datasets,\n",
    "    checkpointing=False,\n",
    "    prenorm=True,\n",
    "    #weight_decay=0.01,\n",
    "    #zinb=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjkobject\u001b[0m (\u001b[33mml4ig\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>../data/tensorboard/wandb/run-20241205_171025-0g3z31yt</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ml4ig/scprint_test/runs/0g3z31yt' target=\"_blank\">clean-dragon-11</a></strong> to <a href='https://wandb.ai/ml4ig/scprint_test' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ml4ig/scprint_test' target=\"_blank\">https://wandb.ai/ml4ig/scprint_test</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ml4ig/scprint_test/runs/0g3z31yt' target=\"_blank\">https://wandb.ai/ml4ig/scprint_test/runs/0g3z31yt</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n"
     ]
    }
   ],
   "source": [
    "# from lightning.pytorch.loggers import TensorBoardLogger\n",
    "from lightning.pytorch.loggers import WandbLogger\n",
    "\n",
    "wandb_logger = WandbLogger(project=\"scprint_test\",\n",
    "                           save_dir=\"../data/tensorboard\")\n",
    "wandb_logger.watch(model, log='all', log_freq=50, log_graph=True)\n",
    "\n",
    "# tlogger = TensorBoardLogger(save_dir=\"../data/tensorboard\")\n",
    "# tlogger.log_graph(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer(limit_val_batches=1)` was configured so 1 batch will be used.\n"
     ]
    }
   ],
   "source": [
    "chckp = ModelCheckpoint(monitor=\"val_loss\", save_top_k=-1)\n",
    "trainingmode = TrainingMode(\n",
    "    do_denoise=True,\n",
    "    noise=[0.6],\n",
    "    do_cce=True,\n",
    "    cce_sim=0.6,\n",
    "    do_ecs=False,\n",
    "    ecs_threshold=0.4,\n",
    "    ecs_scale=0.05,\n",
    "    class_scale=0.08,\n",
    "    do_cls=True,\n",
    "    do_mvc=False,\n",
    "    do_adv_cls=False,\n",
    "    run_full_forward=True,\n",
    "    do_next_tp=False,\n",
    "    mask_ratio=[\"TF\"],\n",
    "    warmup_duration=100,\n",
    "    fused_adam=False,\n",
    "    lr_reduce_patience=200,\n",
    ")\n",
    "trainer = Trainer(precision=\"16-mixed\", gradient_clip_val=10, max_time={\"hours\": 2}, limit_val_batches=1, callbacks=[\n",
    "                  trainingmode], accumulate_grad_batches=1, check_val_every_n_epoch=1, reload_dataloaders_every_n_epochs=1000000, \n",
    "                  #logger=wandb_logger\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import torch\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name                            | Type                         | Params | Mode\n",
      "----------------------------------------------------------------------------------------\n",
      "0 | gene_encoder                    | GeneEncoder                  | 5.9 M  | eval\n",
      "1 | expr_encoder                    | ContinuousValueEncoder       | 66.8 K | eval\n",
      "2 | pos_encoder                     | PositionalEncoding           | 0      | eval\n",
      "3 | class_encoder                   | CategoryValueEncoder         | 2.6 K  | eval\n",
      "4 | depth_encoder                   | ContinuousValueEncoder       | 66.8 K | eval\n",
      "5 | transformer                     | FlashTransformer             | 5.8 M  | eval\n",
      "6 | expr_decoder                    | ExprDecoder                  | 133 K  | eval\n",
      "7 | cls_decoders                    | ModuleDict                   | 315 K  | eval\n",
      "8 | grad_reverse_discriminator_loss | AdversarialDiscriminatorLoss | 134 K  | eval\n",
      "9 | mvc_decoder                     | MVCDecoder                   | 262 K  | eval\n",
      "----------------------------------------------------------------------------------------\n",
      "6.8 M     Trainable params\n",
      "5.9 M     Non-trainable params\n",
      "12.7 M    Total params\n",
      "50.798    Total estimated model params size (MB)\n",
      "0         Modules in train mode\n",
      "248       Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b1815e312164da4a1474116cc858bf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 2184, 4, 64]) torch.Size([10, 2184, 2, 2, 64])\n",
      "torch.Size([10, 2184, 4, 64]) torch.Size([10, 2184, 2, 2, 64])\n",
      "torch.Size([10, 2184, 4, 64]) torch.Size([10, 2184, 2, 2, 64])\n",
      "torch.Size([10, 2184, 4, 64]) torch.Size([10, 2184, 2, 2, 64])\n",
      "torch.Size([10, 2184, 4, 64]) torch.Size([10, 2184, 2, 2, 64])\n",
      "torch.Size([10, 2184, 4, 64]) torch.Size([10, 2184, 2, 2, 64])\n",
      "torch.Size([10, 2184, 4, 64]) torch.Size([10, 2184, 2, 2, 64])\n",
      "torch.Size([10, 2184, 4, 64]) torch.Size([10, 2184, 2, 2, 64])\n",
      "no nan\n",
      "torch.Size([10, 2184, 4, 64]) torch.Size([10, 2184, 2, 2, 64])\n",
      "torch.Size([10, 2184, 4, 64]) torch.Size([10, 2184, 2, 2, 64])\n",
      "torch.Size([10, 2184, 4, 64]) torch.Size([10, 2184, 2, 2, 64])\n",
      "torch.Size([10, 2184, 4, 64]) torch.Size([10, 2184, 2, 2, 64])\n",
      "torch.Size([10, 2184, 4, 64]) torch.Size([10, 2184, 2, 2, 64])\n",
      "torch.Size([10, 2184, 4, 64]) torch.Size([10, 2184, 2, 2, 64])\n",
      "torch.Size([10, 2184, 4, 64]) torch.Size([10, 2184, 2, 2, 64])\n",
      "torch.Size([10, 2184, 4, 64]) torch.Size([10, 2184, 2, 2, 64])\n",
      "no nan\n",
      "torch.Size([10, 2184, 4, 64]) torch.Size([10, 2184, 2, 2, 64])\n",
      "torch.Size([10, 2184, 4, 64]) torch.Size([10, 2184, 2, 2, 64])\n",
      "torch.Size([10, 2184, 4, 64]) torch.Size([10, 2184, 2, 2, 64])\n",
      "torch.Size([10, 2184, 4, 64]) torch.Size([10, 2184, 2, 2, 64])\n",
      "torch.Size([10, 2184, 4, 64]) torch.Size([10, 2184, 2, 2, 64])\n",
      "torch.Size([10, 2184, 4, 64]) torch.Size([10, 2184, 2, 2, 64])\n",
      "torch.Size([10, 2184, 4, 64]) torch.Size([10, 2184, 2, 2, 64])\n",
      "torch.Size([10, 2184, 4, 64]) torch.Size([10, 2184, 2, 2, 64])\n",
      "no nan\n",
      "torch.Size([10, 2184, 4, 64]) torch.Size([10, 2184, 2, 2, 64])\n",
      "torch.Size([10, 2184, 4, 64]) torch.Size([10, 2184, 2, 2, 64])\n",
      "torch.Size([10, 2184, 4, 64]) torch.Size([10, 2184, 2, 2, 64])\n",
      "torch.Size([10, 2184, 4, 64]) torch.Size([10, 2184, 2, 2, 64])\n",
      "torch.Size([10, 2184, 4, 64]) torch.Size([10, 2184, 2, 2, 64])\n",
      "torch.Size([10, 2184, 4, 64]) torch.Size([10, 2184, 2, 2, 64])\n",
      "torch.Size([10, 2184, 4, 64]) torch.Size([10, 2184, 2, 2, 64])\n",
      "torch.Size([10, 2184, 4, 64]) torch.Size([10, 2184, 2, 2, 64])\n",
      "torch.Size([10, 3211, 4, 64]) torch.Size([10, 3211, 2, 2, 64])\n",
      "torch.Size([10, 3211, 4, 64]) torch.Size([10, 3211, 2, 2, 64])\n",
      "torch.Size([10, 3211, 4, 64]) torch.Size([10, 3211, 2, 2, 64])\n",
      "torch.Size([10, 3211, 4, 64]) torch.Size([10, 3211, 2, 2, 64])\n",
      "torch.Size([10, 3211, 4, 64]) torch.Size([10, 3211, 2, 2, 64])\n",
      "torch.Size([10, 3211, 4, 64]) torch.Size([10, 3211, 2, 2, 64])\n",
      "torch.Size([10, 3211, 4, 64]) torch.Size([10, 3211, 2, 2, 64])\n",
      "torch.Size([10, 3211, 4, 64]) torch.Size([10, 3211, 2, 2, 64])\n",
      "no nan\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61e0479952e945e287073147fa708ea4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 2041, 4, 64]) torch.Size([10, 2041, 2, 2, 64])\n",
      "torch.Size([10, 2041, 4, 64]) torch.Size([10, 2041, 2, 2, 64])\n",
      "torch.Size([10, 2041, 4, 64]) torch.Size([10, 2041, 2, 2, 64])\n",
      "torch.Size([10, 2041, 4, 64]) torch.Size([10, 2041, 2, 2, 64])\n",
      "torch.Size([10, 2041, 4, 64]) torch.Size([10, 2041, 2, 2, 64])\n",
      "torch.Size([10, 2041, 4, 64]) torch.Size([10, 2041, 2, 2, 64])\n",
      "torch.Size([10, 2041, 4, 64]) torch.Size([10, 2041, 2, 2, 64])\n",
      "torch.Size([10, 2041, 4, 64]) torch.Size([10, 2041, 2, 2, 64])\n",
      "> \u001b[0;32m/home/ml4ig1/Documents code/scPRINT/scprint/model/model.py\u001b[0m(551)\u001b[0;36mforward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    549 \u001b[0;31m        \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    550 \u001b[0;31m            \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"no nan\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 551 \u001b[0;31m        \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_attention_layer\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    552 \u001b[0;31m            \u001b[0mtransformer_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqkvs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    553 \u001b[0;31m            return (\n",
      "\u001b[0m\n",
      "tensor([     0,      0, 522496, 522496, 522496, 522496, 522496, 522496, 522496,\n",
      "        522496], device='cuda:0')\n",
      "tensor([69144., 14332., 40785., 91909., 93840.,  9891., 47531., 55657., 41583.,\n",
      "         6959.], device='cuda:0')\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "*** AttributeError: 'NoneType' object has no attribute 'shape'\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model, datamodule=datamodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer(overfit_batches=1)` was configured so 1 batch will be used.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer(overfit_batches=1)` was configured so 1 batch will be used.\n"
     ]
    }
   ],
   "source": [
    "trainingmode = TrainingMode(\n",
    "    do_denoise=True,\n",
    "    noise=[0.6],\n",
    "    do_cce=True,\n",
    "    cce_sim=0.6,\n",
    "    do_ecs=False,\n",
    "    ecs_threshold=0.4,\n",
    "    ecs_scale=0.05,\n",
    "    class_scale=0.08,\n",
    "    do_cls=True,\n",
    "    do_mvc=False,\n",
    "    do_adv_cls=False,\n",
    "    run_full_forward=True,\n",
    "    do_next_tp=False,\n",
    "    mask_ratio=[\"TF\"],\n",
    "    fused_adam=False,\n",
    "    lr_reduce_monitor=None,\n",
    "    \n",
    ")\n",
    "overfit_trainer = Trainer(precision=\"16-mixed\", gradient_clip_val=10, max_time={\"hours\": 2}, limit_val_batches=1, callbacks=[\n",
    "                  trainingmode], accumulate_grad_batches=1, check_val_every_n_epoch=10_000, overfit_batches=1, \n",
    "                  reload_dataloaders_every_n_epochs=1_000_000, num_sanity_val_steps=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name                            | Type                         | Params | Mode\n",
      "----------------------------------------------------------------------------------------\n",
      "0 | gene_encoder                    | GeneEncoder                  | 5.9 M  | eval\n",
      "1 | expr_encoder                    | ContinuousValueEncoder       | 66.8 K | eval\n",
      "2 | pos_encoder                     | PositionalEncoding           | 0      | eval\n",
      "3 | class_encoder                   | CategoryValueEncoder         | 2.6 K  | eval\n",
      "4 | depth_encoder                   | ContinuousValueEncoder       | 66.8 K | eval\n",
      "5 | transformer                     | FlashTransformer             | 6.3 M  | eval\n",
      "6 | expr_decoder                    | ExprDecoder                  | 133 K  | eval\n",
      "7 | cls_decoders                    | ModuleDict                   | 315 K  | eval\n",
      "8 | grad_reverse_discriminator_loss | AdversarialDiscriminatorLoss | 134 K  | eval\n",
      "9 | mvc_decoder                     | MVCDecoder                   | 262 K  | eval\n",
      "----------------------------------------------------------------------------------------\n",
      "7.3 M     Trainable params\n",
      "5.9 M     Non-trainable params\n",
      "13.2 M    Total params\n",
      "52.903    Total estimated model params size (MB)\n",
      "0         Modules in train mode\n",
      "248       Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d16b15242d44425a70a006c976275ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4f75ece69334e5c97877b2c87dea2ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f7f05124dc0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ml4ig1/miniconda3/envs/test/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/ml4ig1/miniconda3/envs/test/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1443, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/ml4ig1/miniconda3/envs/test/lib/python3.10/multiprocessing/process.py\", line 149, in join\n",
      "    res = self._popen.wait(timeout)\n",
      "  File \"/home/ml4ig1/miniconda3/envs/test/lib/python3.10/multiprocessing/popen_fork.py\", line 40, in wait\n",
      "    if not wait([self.sentinel], timeout):\n",
      "  File \"/home/ml4ig1/miniconda3/envs/test/lib/python3.10/multiprocessing/connection.py\", line 931, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/home/ml4ig1/miniconda3/envs/test/lib/python3.10/selectors.py\", line 416, in select\n",
      "    fd_event_list = self._selector.poll(timeout)\n",
      "KeyboardInterrupt: \n",
      "Exception ignored in: <function _releaseLock at 0x7f8040368d30>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ml4ig1/miniconda3/envs/test/lib/python3.10/logging/__init__.py\", line 228, in _releaseLock\n",
      "    def _releaseLock():\n",
      "KeyboardInterrupt: \n"
     ]
    }
   ],
   "source": [
    "overfit_trainer.fit(model, datamodule=datamodule)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scprint2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
